{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-10T08:31:11.092468Z"
    }
   },
   "source": [
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna  #载入optuna优化包\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "##optuna######\n",
    "###耗费时间的过程。。。。。。。。。。。。。。。\n",
    "# Define a basic convolutional layer\n",
    "# 自定义的可学习ReLU激活函数：max(0,x)+sigma*randn(内嵌的)\n",
    "class ReLU(nn.Module):\n",
    "    def __init__(self, seqFlag, trial):\n",
    "        super(ReLU, self).__init__()\n",
    "        self.sigma = nn.Parameter(torch.tensor(trial.suggest_float(f'sigma_{seqFlag}', 0.1, 5.0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        noise = torch.randn_like(x) * self.sigma\n",
    "        return torch.maximum(x, torch.zeros_like(x)) + noise\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, trial, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = conv3x3(3, 16)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.custom1 = ReLU(1, trial)  # 自定义激活函数层\n",
    "\n",
    "        # Layer 1\n",
    "        self.layer1_conv1 = conv3x3(16, 16)\n",
    "        self.layer1_bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1_conv2 = conv3x3(16, 16)\n",
    "        self.layer1_bn2 = nn.BatchNorm2d(16)\n",
    "        self.layer1_extra_conv1 = conv3x3(16, 16)\n",
    "        self.layer1_extra_bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1_extra_conv2 = conv3x3(16, 16)\n",
    "        self.layer1_extra_bn2 = nn.BatchNorm2d(16)\n",
    "        self.gelub11 = ReLU(2, trial)\n",
    "        self.gelub12 = ReLU(3, trial)\n",
    "        self.gelub13 = ReLU(4, trial)\n",
    "        self.gelub14 = ReLU(5, trial)\n",
    "\n",
    "        # Layer 2\n",
    "        self.layer2_conv1 = conv3x3(16, 32, stride=2)\n",
    "        self.layer2_bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer2_conv2 = conv3x3(32, 32)\n",
    "        self.layer2_bn2 = nn.BatchNorm2d(32)\n",
    "        self.layer2_extra_conv1 = conv3x3(16, 32, stride=2)  # 调整residual的通道数\n",
    "        self.layer2_extra_bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer2_extra_conv2 = conv3x3(32, 32)\n",
    "        self.layer2_extra_bn2 = nn.BatchNorm2d(32)\n",
    "        self.gelub21 = ReLU(6, trial)\n",
    "        self.gelub22 = ReLU(7, trial)\n",
    "        self.gelub23 = ReLU(8, trial)\n",
    "        self.gelub24 = ReLU(9, trial)\n",
    "        self.layer2_downsample = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        # Layer 3\n",
    "        self.layer3_conv1 = conv3x3(32, 64, stride=2)\n",
    "        self.layer3_bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer3_conv2 = conv3x3(64, 64)\n",
    "        self.layer3_bn2 = nn.BatchNorm2d(64)\n",
    "        self.layer3_extra_conv1 = conv3x3(32, 64, stride=2)  # 调整residual的通道数\n",
    "        self.layer3_extra_bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer3_extra_conv2 = conv3x3(64, 64)\n",
    "        self.layer3_extra_bn2 = nn.BatchNorm2d(64)\n",
    "        self.gelub31 = ReLU(10, trial)\n",
    "        self.gelub32 = ReLU(11, trial)\n",
    "        self.gelub33 = ReLU(12, trial)\n",
    "        self.gelub34 = ReLU(13, trial)\n",
    "\n",
    "        self.layer3_downsample = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 0\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.custom1(out)\n",
    "\n",
    "        # Layer 1\n",
    "        residual = out\n",
    "        out = self.layer1_conv1(out)\n",
    "        out = self.layer1_bn1(out)\n",
    "        out = self.gelub11(out)\n",
    "        out = self.layer1_conv2(out)\n",
    "        out = self.layer1_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub12(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer1_extra_conv1(out)\n",
    "        out = self.layer1_extra_bn1(out)\n",
    "        out = self.gelub13(out)\n",
    "        out = self.layer1_extra_conv2(out)\n",
    "        out = self.layer1_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub14(out)\n",
    "\n",
    "        # Layer 2\n",
    "        residual = out\n",
    "        out = self.layer2_conv1(out)\n",
    "        out = self.layer2_bn1(out)\n",
    "        out = self.gelub21(out)\n",
    "        out = self.layer2_conv2(out)\n",
    "        out = self.layer2_bn2(out)\n",
    "        out = self.gelub22(out)\n",
    "        residual = self.layer2_downsample(residual)\n",
    "        out += residual\n",
    "        out = self.gelub22(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer2_extra_conv2(out)\n",
    "        out = self.layer2_extra_bn2(out)\n",
    "        out = self.gelub23(out)\n",
    "        out = self.layer2_extra_conv2(out)\n",
    "        out = self.layer2_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub24(out)\n",
    "\n",
    "        # Layer 3\n",
    "        residual = out\n",
    "        out = self.layer3_conv1(out)\n",
    "        out = self.layer3_bn1(out)\n",
    "        out = self.gelub31(out)\n",
    "        out = self.layer3_conv2(out)\n",
    "        out = self.layer3_bn2(out)\n",
    "        residual = self.layer3_downsample(residual)\n",
    "        out += residual\n",
    "        out = self.gelub32(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer3_extra_conv2(out)\n",
    "        out = self.layer3_extra_bn2(out)\n",
    "        out = self.gelub33(out)\n",
    "        out = self.layer3_extra_conv2(out)\n",
    "        out = self.layer3_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub34(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 80\n",
    "\n",
    "\n",
    "# 定义目标函数\n",
    "def objective(trial):\n",
    "    # 模型实例化\n",
    "    model = ResNet(trial)\n",
    "    model.to(device)\n",
    "    curr_lr = learning_rate\n",
    "    # 损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=curr_lr)  # 保持 Adam 优化器\n",
    "\n",
    "    #history = {'train_loss': [], 'valid_loss': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=curr_lr)  # 保持 Adam 优化器\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            scores, predictions = torch.max(outputs.data, 1)\n",
    "            train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        # Decay learning rate\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            curr_lr /= 3\n",
    "            update_lr(optimizer, curr_lr)\n",
    "\n",
    "        valid_loss, valid_correct = 0.0, 0\n",
    "        model.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * images.size(0)\n",
    "            scores, predictions = torch.max(outputs.data, 1)\n",
    "            valid_correct += (predictions == labels).sum().item()\n",
    "        ##不好的trial剪枝    \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        valid_loss = valid_loss / len(test_loader.sampler)\n",
    "        valid_acc = valid_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} \\t Train Loss:{:.4f} Valid Loss:{:.4f} \\t Train Acc:{:.2f} %  Valid Acc:{:.2f} %\".format(\n",
    "            epoch + 1, num_epochs,\n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            train_acc,\n",
    "            valid_acc))\n",
    "        # history['train_loss'].append(train_loss)\n",
    "        # history['valid_loss'].append(valid_loss)\n",
    "        # history['train_acc'].append(train_acc)\n",
    "        # history['valid_acc'].append(valid_acc)\n",
    "\n",
    "    return valid_acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# 运行优化过程\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "# 打印最佳参数和目标值\n",
    "print('Best trial:')\n",
    "print('  Value: ', study.best_trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-10 16:31:20,713] A new study created in memory with name: no-name-fcf57575-4f27-476d-9779-62564777625f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100 \t Train Loss:1.8438 Valid Loss:1.8759 \t Train Acc:30.18 %  Valid Acc:33.65 %\n",
      "Epoch:2/100 \t Train Loss:1.5985 Valid Loss:1.3544 \t Train Acc:40.88 %  Valid Acc:50.49 %\n",
      "Epoch:3/100 \t Train Loss:1.3589 Valid Loss:1.2935 \t Train Acc:50.47 %  Valid Acc:52.73 %\n",
      "Epoch:4/100 \t Train Loss:1.2130 Valid Loss:1.1173 \t Train Acc:56.13 %  Valid Acc:60.17 %\n",
      "Epoch:5/100 \t Train Loss:1.1069 Valid Loss:1.1277 \t Train Acc:60.34 %  Valid Acc:60.33 %\n",
      "Epoch:6/100 \t Train Loss:1.0260 Valid Loss:0.9766 \t Train Acc:63.59 %  Valid Acc:66.45 %\n",
      "Epoch:7/100 \t Train Loss:0.9577 Valid Loss:0.9873 \t Train Acc:66.25 %  Valid Acc:66.36 %\n",
      "Epoch:8/100 \t Train Loss:0.8947 Valid Loss:0.9244 \t Train Acc:68.41 %  Valid Acc:67.29 %\n",
      "Epoch:9/100 \t Train Loss:0.8474 Valid Loss:0.9144 \t Train Acc:70.20 %  Valid Acc:68.39 %\n",
      "Epoch:10/100 \t Train Loss:0.8044 Valid Loss:0.9072 \t Train Acc:72.00 %  Valid Acc:70.00 %\n",
      "Epoch:11/100 \t Train Loss:0.7603 Valid Loss:0.7689 \t Train Acc:73.44 %  Valid Acc:73.77 %\n",
      "Epoch:12/100 \t Train Loss:0.7310 Valid Loss:0.7500 \t Train Acc:74.48 %  Valid Acc:74.56 %\n",
      "Epoch:13/100 \t Train Loss:0.7019 Valid Loss:0.6970 \t Train Acc:75.69 %  Valid Acc:76.69 %\n",
      "Epoch:14/100 \t Train Loss:0.6725 Valid Loss:0.6675 \t Train Acc:76.72 %  Valid Acc:77.60 %\n",
      "Epoch:15/100 \t Train Loss:0.6490 Valid Loss:0.7163 \t Train Acc:77.39 %  Valid Acc:76.47 %\n",
      "Epoch:16/100 \t Train Loss:0.6289 Valid Loss:0.6339 \t Train Acc:78.06 %  Valid Acc:78.48 %\n",
      "Epoch:17/100 \t Train Loss:0.6143 Valid Loss:0.6518 \t Train Acc:78.75 %  Valid Acc:78.12 %\n",
      "Epoch:18/100 \t Train Loss:0.5879 Valid Loss:0.6468 \t Train Acc:79.54 %  Valid Acc:78.40 %\n",
      "Epoch:19/100 \t Train Loss:0.5795 Valid Loss:0.6538 \t Train Acc:79.97 %  Valid Acc:78.38 %\n",
      "Epoch:20/100 \t Train Loss:0.5660 Valid Loss:0.6696 \t Train Acc:80.37 %  Valid Acc:77.93 %\n",
      "Epoch:21/100 \t Train Loss:0.4722 Valid Loss:0.5545 \t Train Acc:83.53 %  Valid Acc:82.08 %\n",
      "Epoch:22/100 \t Train Loss:0.4549 Valid Loss:0.5292 \t Train Acc:84.00 %  Valid Acc:82.66 %\n",
      "Epoch:23/100 \t Train Loss:0.4425 Valid Loss:0.5605 \t Train Acc:84.40 %  Valid Acc:81.93 %\n",
      "Epoch:24/100 \t Train Loss:0.4357 Valid Loss:0.5336 \t Train Acc:84.79 %  Valid Acc:82.71 %\n",
      "Epoch:25/100 \t Train Loss:0.4227 Valid Loss:0.5362 \t Train Acc:85.46 %  Valid Acc:82.63 %\n",
      "Epoch:26/100 \t Train Loss:0.4146 Valid Loss:0.5392 \t Train Acc:85.48 %  Valid Acc:82.77 %\n",
      "Epoch:27/100 \t Train Loss:0.4113 Valid Loss:0.5376 \t Train Acc:85.75 %  Valid Acc:82.60 %\n",
      "Epoch:28/100 \t Train Loss:0.4053 Valid Loss:0.5136 \t Train Acc:85.84 %  Valid Acc:83.18 %\n",
      "Epoch:29/100 \t Train Loss:0.4007 Valid Loss:0.5471 \t Train Acc:86.12 %  Valid Acc:83.00 %\n",
      "Epoch:30/100 \t Train Loss:0.3956 Valid Loss:0.5256 \t Train Acc:86.11 %  Valid Acc:83.15 %\n",
      "Epoch:31/100 \t Train Loss:0.3877 Valid Loss:0.5267 \t Train Acc:86.43 %  Valid Acc:83.13 %\n",
      "Epoch:32/100 \t Train Loss:0.3845 Valid Loss:0.5585 \t Train Acc:86.41 %  Valid Acc:82.34 %\n",
      "Epoch:33/100 \t Train Loss:0.3812 Valid Loss:0.5446 \t Train Acc:86.70 %  Valid Acc:82.62 %\n",
      "Epoch:34/100 \t Train Loss:0.3767 Valid Loss:0.5199 \t Train Acc:86.93 %  Valid Acc:83.45 %\n",
      "Epoch:35/100 \t Train Loss:0.3724 Valid Loss:0.5276 \t Train Acc:86.91 %  Valid Acc:83.35 %\n",
      "Epoch:36/100 \t Train Loss:0.3673 Valid Loss:0.5542 \t Train Acc:87.16 %  Valid Acc:82.91 %\n",
      "Epoch:37/100 \t Train Loss:0.3652 Valid Loss:0.5273 \t Train Acc:87.22 %  Valid Acc:83.12 %\n",
      "Epoch:38/100 \t Train Loss:0.3599 Valid Loss:0.5353 \t Train Acc:87.44 %  Valid Acc:83.57 %\n",
      "Epoch:39/100 \t Train Loss:0.3562 Valid Loss:0.5055 \t Train Acc:87.38 %  Valid Acc:84.03 %\n",
      "Epoch:40/100 \t Train Loss:0.3529 Valid Loss:0.5635 \t Train Acc:87.74 %  Valid Acc:82.92 %\n",
      "Epoch:41/100 \t Train Loss:0.3147 Valid Loss:0.4977 \t Train Acc:88.91 %  Valid Acc:84.52 %\n",
      "Epoch:42/100 \t Train Loss:0.3098 Valid Loss:0.5077 \t Train Acc:89.21 %  Valid Acc:84.45 %\n",
      "Epoch:43/100 \t Train Loss:0.3060 Valid Loss:0.5038 \t Train Acc:89.24 %  Valid Acc:84.70 %\n",
      "Epoch:44/100 \t Train Loss:0.3031 Valid Loss:0.5084 \t Train Acc:89.36 %  Valid Acc:84.45 %\n",
      "Epoch:45/100 \t Train Loss:0.2978 Valid Loss:0.5075 \t Train Acc:89.54 %  Valid Acc:84.63 %\n",
      "Epoch:46/100 \t Train Loss:0.2960 Valid Loss:0.5107 \t Train Acc:89.59 %  Valid Acc:84.78 %\n",
      "Epoch:47/100 \t Train Loss:0.2988 Valid Loss:0.5280 \t Train Acc:89.53 %  Valid Acc:84.02 %\n",
      "Epoch:48/100 \t Train Loss:0.2930 Valid Loss:0.5161 \t Train Acc:89.70 %  Valid Acc:84.47 %\n",
      "Epoch:49/100 \t Train Loss:0.2949 Valid Loss:0.5156 \t Train Acc:89.51 %  Valid Acc:84.50 %\n",
      "Epoch:50/100 \t Train Loss:0.2921 Valid Loss:0.5151 \t Train Acc:89.75 %  Valid Acc:84.43 %\n",
      "Epoch:51/100 \t Train Loss:0.2888 Valid Loss:0.5111 \t Train Acc:89.87 %  Valid Acc:84.75 %\n",
      "Epoch:52/100 \t Train Loss:0.2857 Valid Loss:0.5245 \t Train Acc:89.94 %  Valid Acc:84.26 %\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "bb49b7733ce65d07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
