{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T06:23:13.071734Z",
     "start_time": "2024-09-28T04:03:15.158258Z"
    }
   },
   "source": [
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna  #载入optuna优化包\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "##optuna######\n",
    "###耗费时间的过程。。。。。。。。。。。。。。。\n",
    "# Define a basic convolutional layer\n",
    "class RayLU(nn.Module):\n",
    "    def __init__(self, trial, seqFlag):\n",
    "        super(RayLU, self).__init__()\n",
    "        self.sigma = nn.Parameter(torch.tensor(trial.suggest_float(f'sigma_{seqFlag}', 0.1, 5.0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.where(x >= 0, x, x * torch.exp(-x**2 / (2 * self.sigma**2)))\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, trial, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = conv3x3(3, 16)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.custom1 = RayLU(trial, 1)  # 自定义激活函数层\n",
    "\n",
    "        # Layer 1\n",
    "        self.layer1_conv1 = conv3x3(16, 16)\n",
    "        self.layer1_bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1_conv2 = conv3x3(16, 16)\n",
    "        self.layer1_bn2 = nn.BatchNorm2d(16)\n",
    "        self.layer1_extra_conv1 = conv3x3(16, 16)\n",
    "        self.layer1_extra_bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1_extra_conv2 = conv3x3(16, 16)\n",
    "        self.layer1_extra_bn2 = nn.BatchNorm2d(16)\n",
    "        self.gelub11 = RayLU(trial, 2)\n",
    "        self.gelub12 = RayLU(trial, 3)\n",
    "        self.gelub13 = RayLU(trial, 4)\n",
    "        self.gelub14 = RayLU(trial, 5)\n",
    "\n",
    "        # Layer 2\n",
    "        self.layer2_conv1 = conv3x3(16, 32, stride=2)\n",
    "        self.layer2_bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer2_conv2 = conv3x3(32, 32)\n",
    "        self.layer2_bn2 = nn.BatchNorm2d(32)\n",
    "        self.layer2_extra_conv1 = conv3x3(16, 32, stride=2)  # 调整residual的通道数\n",
    "        self.layer2_extra_bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer2_extra_conv2 = conv3x3(32, 32)\n",
    "        self.layer2_extra_bn2 = nn.BatchNorm2d(32)\n",
    "        self.gelub21 = RayLU(trial, 6)\n",
    "        self.gelub22 = RayLU(trial, 7)\n",
    "        self.gelub23 = RayLU(trial, 8)\n",
    "        self.gelub24 = RayLU(trial, 9)\n",
    "        self.layer2_downsample = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        # Layer 3\n",
    "        self.layer3_conv1 = conv3x3(32, 64, stride=2)\n",
    "        self.layer3_bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer3_conv2 = conv3x3(64, 64)\n",
    "        self.layer3_bn2 = nn.BatchNorm2d(64)\n",
    "        self.layer3_extra_conv1 = conv3x3(32, 64, stride=2)  # 调整residual的通道数\n",
    "        self.layer3_extra_bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer3_extra_conv2 = conv3x3(64, 64)\n",
    "        self.layer3_extra_bn2 = nn.BatchNorm2d(64)\n",
    "        self.gelub31 = RayLU(trial, 10)\n",
    "        self.gelub32 = RayLU(trial, 11)\n",
    "        self.gelub33 = RayLU(trial, 12)\n",
    "        self.gelub34 = RayLU(trial, 13)\n",
    "\n",
    "        self.layer3_downsample = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 0\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.custom1(out)\n",
    "\n",
    "        # Layer 1\n",
    "        residual = out\n",
    "        out = self.layer1_conv1(out)\n",
    "        out = self.layer1_bn1(out)\n",
    "        out = self.gelub11(out)\n",
    "        out = self.layer1_conv2(out)\n",
    "        out = self.layer1_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub12(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer1_extra_conv1(out)\n",
    "        out = self.layer1_extra_bn1(out)\n",
    "        out = self.gelub13(out)\n",
    "        out = self.layer1_extra_conv2(out)\n",
    "        out = self.layer1_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub14(out)\n",
    "\n",
    "        # Layer 2\n",
    "        residual = out\n",
    "        out = self.layer2_conv1(out)\n",
    "        out = self.layer2_bn1(out)\n",
    "        out = self.gelub21(out)\n",
    "        out = self.layer2_conv2(out)\n",
    "        out = self.layer2_bn2(out)\n",
    "        out = self.gelub22(out)\n",
    "        residual = self.layer2_downsample(residual)\n",
    "        out += residual\n",
    "        out = self.gelub22(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer2_extra_conv2(out)\n",
    "        out = self.layer2_extra_bn2(out)\n",
    "        out = self.gelub23(out)\n",
    "        out = self.layer2_extra_conv2(out)\n",
    "        out = self.layer2_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub24(out)\n",
    "\n",
    "        # Layer 3\n",
    "        residual = out\n",
    "        out = self.layer3_conv1(out)\n",
    "        out = self.layer3_bn1(out)\n",
    "        out = self.gelub31(out)\n",
    "        out = self.layer3_conv2(out)\n",
    "        out = self.layer3_bn2(out)\n",
    "        residual = self.layer3_downsample(residual)\n",
    "        out += residual\n",
    "        out = self.gelub32(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer3_extra_conv2(out)\n",
    "        out = self.layer3_extra_bn2(out)\n",
    "        out = self.gelub33(out)\n",
    "        out = self.layer3_extra_conv2(out)\n",
    "        out = self.layer3_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub34(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# 定义目标函数\n",
    "def objective(trial):\n",
    "    # 模型实例化\n",
    "    model = ResNet(trial)\n",
    "    model.to(device)\n",
    "    curr_lr = learning_rate\n",
    "    # 损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=curr_lr)  # 保持 Adam 优化器\n",
    "\n",
    "    #history = {'train_loss': [], 'valid_loss': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=curr_lr)  # 保持 Adam 优化器\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            scores, predictions = torch.max(outputs.data, 1)\n",
    "            train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        # Decay learning rate\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            curr_lr /= 3\n",
    "            update_lr(optimizer, curr_lr)\n",
    "\n",
    "        valid_loss, valid_correct = 0.0, 0\n",
    "        model.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * images.size(0)\n",
    "            scores, predictions = torch.max(outputs.data, 1)\n",
    "            valid_correct += (predictions == labels).sum().item()\n",
    "        ##不好的trial剪枝    \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        valid_loss = valid_loss / len(test_loader.sampler)\n",
    "        valid_acc = valid_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} \\t Train Loss:{:.4f} Valid Loss:{:.4f} \\t Train Acc:{:.2f} %  Valid Acc:{:.2f} %\".format(\n",
    "            epoch + 1, num_epochs,\n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            train_acc,\n",
    "            valid_acc))\n",
    "        # history['train_loss'].append(train_loss)\n",
    "        # history['valid_loss'].append(valid_loss)\n",
    "        # history['train_acc'].append(train_acc)\n",
    "        # history['valid_acc'].append(valid_acc)\n",
    "\n",
    "    return valid_acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# 运行优化过程\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# 打印最佳参数和目标值\n",
    "print('Best trial:')\n",
    "print('  Value: ', study.best_trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 12:03:17,121] A new study created in memory with name: no-name-68596a98-ff02-40dd-bc78-4c85e467d3ac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100 \t Train Loss:1.5924 Valid Loss:1.5206 \t Train Acc:40.88 %  Valid Acc:45.91 %\n",
      "Epoch:2/100 \t Train Loss:1.2400 Valid Loss:1.1888 \t Train Acc:55.58 %  Valid Acc:57.44 %\n",
      "Epoch:3/100 \t Train Loss:1.0427 Valid Loss:0.9666 \t Train Acc:62.93 %  Valid Acc:65.90 %\n",
      "Epoch:4/100 \t Train Loss:0.9365 Valid Loss:0.8835 \t Train Acc:66.62 %  Valid Acc:68.39 %\n",
      "Epoch:5/100 \t Train Loss:0.8655 Valid Loss:0.8234 \t Train Acc:69.26 %  Valid Acc:71.10 %\n",
      "Epoch:6/100 \t Train Loss:0.8081 Valid Loss:0.7862 \t Train Acc:71.50 %  Valid Acc:72.32 %\n",
      "Epoch:7/100 \t Train Loss:0.7565 Valid Loss:0.7661 \t Train Acc:73.47 %  Valid Acc:73.18 %\n",
      "Epoch:8/100 \t Train Loss:0.7003 Valid Loss:0.6973 \t Train Acc:75.40 %  Valid Acc:75.80 %\n",
      "Epoch:9/100 \t Train Loss:0.6593 Valid Loss:0.6970 \t Train Acc:76.60 %  Valid Acc:76.43 %\n",
      "Epoch:10/100 \t Train Loss:0.6254 Valid Loss:0.6772 \t Train Acc:78.04 %  Valid Acc:77.05 %\n",
      "Epoch:11/100 \t Train Loss:0.5883 Valid Loss:0.6461 \t Train Acc:79.24 %  Valid Acc:77.95 %\n",
      "Epoch:12/100 \t Train Loss:0.5703 Valid Loss:0.6262 \t Train Acc:80.19 %  Valid Acc:78.23 %\n",
      "Epoch:13/100 \t Train Loss:0.5433 Valid Loss:0.6569 \t Train Acc:81.10 %  Valid Acc:77.85 %\n",
      "Epoch:14/100 \t Train Loss:0.5272 Valid Loss:0.5896 \t Train Acc:81.69 %  Valid Acc:79.52 %\n",
      "Epoch:15/100 \t Train Loss:0.5049 Valid Loss:0.5482 \t Train Acc:82.47 %  Valid Acc:81.31 %\n",
      "Epoch:16/100 \t Train Loss:0.4908 Valid Loss:0.5660 \t Train Acc:82.96 %  Valid Acc:81.25 %\n",
      "Epoch:17/100 \t Train Loss:0.4708 Valid Loss:0.5673 \t Train Acc:83.47 %  Valid Acc:80.95 %\n",
      "Epoch:18/100 \t Train Loss:0.4608 Valid Loss:0.5063 \t Train Acc:83.84 %  Valid Acc:83.00 %\n",
      "Epoch:19/100 \t Train Loss:0.4446 Valid Loss:0.5392 \t Train Acc:84.56 %  Valid Acc:82.35 %\n",
      "Epoch:20/100 \t Train Loss:0.4388 Valid Loss:0.4781 \t Train Acc:84.81 %  Valid Acc:83.77 %\n",
      "Epoch:21/100 \t Train Loss:0.3523 Valid Loss:0.4714 \t Train Acc:87.84 %  Valid Acc:84.37 %\n",
      "Epoch:22/100 \t Train Loss:0.3329 Valid Loss:0.4626 \t Train Acc:88.44 %  Valid Acc:85.14 %\n",
      "Epoch:23/100 \t Train Loss:0.3245 Valid Loss:0.4599 \t Train Acc:88.51 %  Valid Acc:84.62 %\n",
      "Epoch:24/100 \t Train Loss:0.3213 Valid Loss:0.4458 \t Train Acc:88.63 %  Valid Acc:85.52 %\n",
      "Epoch:25/100 \t Train Loss:0.3127 Valid Loss:0.4616 \t Train Acc:88.86 %  Valid Acc:85.52 %\n",
      "Epoch:26/100 \t Train Loss:0.3058 Valid Loss:0.4631 \t Train Acc:89.21 %  Valid Acc:84.99 %\n",
      "Epoch:27/100 \t Train Loss:0.3048 Valid Loss:0.4457 \t Train Acc:89.33 %  Valid Acc:85.49 %\n",
      "Epoch:28/100 \t Train Loss:0.2950 Valid Loss:0.4545 \t Train Acc:89.68 %  Valid Acc:85.85 %\n",
      "Epoch:29/100 \t Train Loss:0.2890 Valid Loss:0.4502 \t Train Acc:89.77 %  Valid Acc:85.38 %\n",
      "Epoch:30/100 \t Train Loss:0.2896 Valid Loss:0.4779 \t Train Acc:89.79 %  Valid Acc:84.87 %\n",
      "Epoch:31/100 \t Train Loss:0.2836 Valid Loss:0.4486 \t Train Acc:89.99 %  Valid Acc:85.42 %\n",
      "Epoch:32/100 \t Train Loss:0.2802 Valid Loss:0.4643 \t Train Acc:90.13 %  Valid Acc:84.88 %\n",
      "Epoch:33/100 \t Train Loss:0.2789 Valid Loss:0.4490 \t Train Acc:90.26 %  Valid Acc:85.88 %\n",
      "Epoch:34/100 \t Train Loss:0.2710 Valid Loss:0.4428 \t Train Acc:90.42 %  Valid Acc:86.30 %\n",
      "Epoch:35/100 \t Train Loss:0.2677 Valid Loss:0.4551 \t Train Acc:90.56 %  Valid Acc:85.66 %\n",
      "Epoch:36/100 \t Train Loss:0.2666 Valid Loss:0.4579 \t Train Acc:90.56 %  Valid Acc:85.67 %\n",
      "Epoch:37/100 \t Train Loss:0.2644 Valid Loss:0.4684 \t Train Acc:90.72 %  Valid Acc:85.77 %\n",
      "Epoch:38/100 \t Train Loss:0.2587 Valid Loss:0.4545 \t Train Acc:90.79 %  Valid Acc:85.79 %\n",
      "Epoch:39/100 \t Train Loss:0.2562 Valid Loss:0.4591 \t Train Acc:90.82 %  Valid Acc:86.10 %\n",
      "Epoch:40/100 \t Train Loss:0.2517 Valid Loss:0.4651 \t Train Acc:91.02 %  Valid Acc:85.83 %\n",
      "Epoch:41/100 \t Train Loss:0.2204 Valid Loss:0.4405 \t Train Acc:92.11 %  Valid Acc:86.51 %\n",
      "Epoch:42/100 \t Train Loss:0.2140 Valid Loss:0.4422 \t Train Acc:92.46 %  Valid Acc:86.30 %\n",
      "Epoch:43/100 \t Train Loss:0.2142 Valid Loss:0.4488 \t Train Acc:92.40 %  Valid Acc:86.36 %\n",
      "Epoch:44/100 \t Train Loss:0.2108 Valid Loss:0.4459 \t Train Acc:92.64 %  Valid Acc:86.59 %\n",
      "Epoch:45/100 \t Train Loss:0.2102 Valid Loss:0.4515 \t Train Acc:92.62 %  Valid Acc:86.37 %\n",
      "Epoch:46/100 \t Train Loss:0.2073 Valid Loss:0.4523 \t Train Acc:92.60 %  Valid Acc:86.26 %\n",
      "Epoch:47/100 \t Train Loss:0.2053 Valid Loss:0.4479 \t Train Acc:92.73 %  Valid Acc:86.44 %\n",
      "Epoch:48/100 \t Train Loss:0.2037 Valid Loss:0.4508 \t Train Acc:92.71 %  Valid Acc:86.67 %\n",
      "Epoch:49/100 \t Train Loss:0.2034 Valid Loss:0.4566 \t Train Acc:92.86 %  Valid Acc:86.59 %\n",
      "Epoch:50/100 \t Train Loss:0.2013 Valid Loss:0.4553 \t Train Acc:92.90 %  Valid Acc:86.69 %\n",
      "Epoch:51/100 \t Train Loss:0.1979 Valid Loss:0.4580 \t Train Acc:92.96 %  Valid Acc:86.40 %\n",
      "Epoch:52/100 \t Train Loss:0.1994 Valid Loss:0.4514 \t Train Acc:92.84 %  Valid Acc:86.55 %\n",
      "Epoch:53/100 \t Train Loss:0.1981 Valid Loss:0.4563 \t Train Acc:92.94 %  Valid Acc:86.58 %\n",
      "Epoch:54/100 \t Train Loss:0.1968 Valid Loss:0.4638 \t Train Acc:92.99 %  Valid Acc:86.75 %\n",
      "Epoch:55/100 \t Train Loss:0.1943 Valid Loss:0.4641 \t Train Acc:93.09 %  Valid Acc:86.53 %\n",
      "Epoch:56/100 \t Train Loss:0.1894 Valid Loss:0.4728 \t Train Acc:93.30 %  Valid Acc:86.28 %\n",
      "Epoch:57/100 \t Train Loss:0.1909 Valid Loss:0.4616 \t Train Acc:93.33 %  Valid Acc:86.51 %\n",
      "Epoch:58/100 \t Train Loss:0.1940 Valid Loss:0.4711 \t Train Acc:93.16 %  Valid Acc:86.41 %\n",
      "Epoch:59/100 \t Train Loss:0.1902 Valid Loss:0.4726 \t Train Acc:93.14 %  Valid Acc:86.25 %\n",
      "Epoch:60/100 \t Train Loss:0.1889 Valid Loss:0.4742 \t Train Acc:93.20 %  Valid Acc:86.42 %\n",
      "Epoch:61/100 \t Train Loss:0.1771 Valid Loss:0.4695 \t Train Acc:93.66 %  Valid Acc:86.59 %\n",
      "Epoch:62/100 \t Train Loss:0.1752 Valid Loss:0.4636 \t Train Acc:93.92 %  Valid Acc:86.82 %\n",
      "Epoch:63/100 \t Train Loss:0.1736 Valid Loss:0.4705 \t Train Acc:93.89 %  Valid Acc:86.64 %\n",
      "Epoch:64/100 \t Train Loss:0.1742 Valid Loss:0.4656 \t Train Acc:93.85 %  Valid Acc:86.72 %\n",
      "Epoch:65/100 \t Train Loss:0.1714 Valid Loss:0.4677 \t Train Acc:93.93 %  Valid Acc:86.69 %\n",
      "Epoch:66/100 \t Train Loss:0.1716 Valid Loss:0.4673 \t Train Acc:93.90 %  Valid Acc:86.74 %\n",
      "Epoch:67/100 \t Train Loss:0.1691 Valid Loss:0.4697 \t Train Acc:93.97 %  Valid Acc:86.73 %\n",
      "Epoch:68/100 \t Train Loss:0.1709 Valid Loss:0.4665 \t Train Acc:94.00 %  Valid Acc:86.88 %\n",
      "Epoch:69/100 \t Train Loss:0.1717 Valid Loss:0.4681 \t Train Acc:93.81 %  Valid Acc:86.75 %\n",
      "Epoch:70/100 \t Train Loss:0.1728 Valid Loss:0.4659 \t Train Acc:93.89 %  Valid Acc:86.74 %\n",
      "Epoch:71/100 \t Train Loss:0.1682 Valid Loss:0.4711 \t Train Acc:94.03 %  Valid Acc:86.82 %\n",
      "Epoch:72/100 \t Train Loss:0.1709 Valid Loss:0.4760 \t Train Acc:93.94 %  Valid Acc:86.78 %\n",
      "Epoch:73/100 \t Train Loss:0.1710 Valid Loss:0.4728 \t Train Acc:93.90 %  Valid Acc:86.77 %\n",
      "Epoch:74/100 \t Train Loss:0.1679 Valid Loss:0.4721 \t Train Acc:94.04 %  Valid Acc:86.70 %\n",
      "Epoch:75/100 \t Train Loss:0.1683 Valid Loss:0.4805 \t Train Acc:93.98 %  Valid Acc:86.73 %\n",
      "Epoch:76/100 \t Train Loss:0.1641 Valid Loss:0.4714 \t Train Acc:94.14 %  Valid Acc:86.82 %\n",
      "Epoch:77/100 \t Train Loss:0.1678 Valid Loss:0.4726 \t Train Acc:94.01 %  Valid Acc:86.80 %\n",
      "Epoch:78/100 \t Train Loss:0.1661 Valid Loss:0.4753 \t Train Acc:94.09 %  Valid Acc:86.58 %\n",
      "Epoch:79/100 \t Train Loss:0.1677 Valid Loss:0.4787 \t Train Acc:94.08 %  Valid Acc:86.59 %\n",
      "Epoch:80/100 \t Train Loss:0.1623 Valid Loss:0.4777 \t Train Acc:94.25 %  Valid Acc:86.78 %\n",
      "Epoch:81/100 \t Train Loss:0.1631 Valid Loss:0.4758 \t Train Acc:94.18 %  Valid Acc:86.80 %\n",
      "Epoch:82/100 \t Train Loss:0.1590 Valid Loss:0.4759 \t Train Acc:94.35 %  Valid Acc:86.70 %\n",
      "Epoch:83/100 \t Train Loss:0.1616 Valid Loss:0.4744 \t Train Acc:94.30 %  Valid Acc:86.76 %\n",
      "Epoch:84/100 \t Train Loss:0.1590 Valid Loss:0.4756 \t Train Acc:94.28 %  Valid Acc:86.69 %\n",
      "Epoch:85/100 \t Train Loss:0.1613 Valid Loss:0.4762 \t Train Acc:94.22 %  Valid Acc:86.84 %\n",
      "Epoch:86/100 \t Train Loss:0.1583 Valid Loss:0.4763 \t Train Acc:94.37 %  Valid Acc:86.85 %\n",
      "Epoch:87/100 \t Train Loss:0.1596 Valid Loss:0.4767 \t Train Acc:94.39 %  Valid Acc:86.68 %\n",
      "Epoch:88/100 \t Train Loss:0.1608 Valid Loss:0.4759 \t Train Acc:94.35 %  Valid Acc:86.59 %\n",
      "Epoch:89/100 \t Train Loss:0.1594 Valid Loss:0.4769 \t Train Acc:94.33 %  Valid Acc:86.71 %\n",
      "Epoch:90/100 \t Train Loss:0.1588 Valid Loss:0.4778 \t Train Acc:94.28 %  Valid Acc:86.83 %\n",
      "Epoch:91/100 \t Train Loss:0.1589 Valid Loss:0.4789 \t Train Acc:94.37 %  Valid Acc:86.78 %\n",
      "Epoch:92/100 \t Train Loss:0.1563 Valid Loss:0.4779 \t Train Acc:94.43 %  Valid Acc:86.76 %\n",
      "Epoch:93/100 \t Train Loss:0.1610 Valid Loss:0.4794 \t Train Acc:94.21 %  Valid Acc:86.63 %\n",
      "Epoch:94/100 \t Train Loss:0.1578 Valid Loss:0.4785 \t Train Acc:94.46 %  Valid Acc:86.75 %\n",
      "Epoch:95/100 \t Train Loss:0.1571 Valid Loss:0.4805 \t Train Acc:94.48 %  Valid Acc:86.68 %\n",
      "Epoch:96/100 \t Train Loss:0.1570 Valid Loss:0.4826 \t Train Acc:94.47 %  Valid Acc:86.67 %\n",
      "Epoch:97/100 \t Train Loss:0.1573 Valid Loss:0.4804 \t Train Acc:94.56 %  Valid Acc:86.64 %\n",
      "Epoch:98/100 \t Train Loss:0.1618 Valid Loss:0.4799 \t Train Acc:94.29 %  Valid Acc:86.60 %\n",
      "Epoch:99/100 \t Train Loss:0.1588 Valid Loss:0.4815 \t Train Acc:94.29 %  Valid Acc:86.70 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 13:23:25,538] Trial 0 finished with value: 86.76 and parameters: {'sigma_1': 3.423476052186064, 'sigma_2': 4.098131311369579, 'sigma_3': 1.3439461442440241, 'sigma_4': 2.592789434602616, 'sigma_5': 2.4784358311579053, 'sigma_6': 4.121806497231036, 'sigma_7': 2.3422659667291836, 'sigma_8': 4.977929158208426, 'sigma_9': 2.340357248697875, 'sigma_10': 2.008432233176517, 'sigma_11': 4.112695128215287, 'sigma_12': 4.541384343668526, 'sigma_13': 3.2551058020068773}. Best is trial 0 with value: 86.76.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1571 Valid Loss:0.4801 \t Train Acc:94.44 %  Valid Acc:86.76 %\n",
      "Epoch:1/100 \t Train Loss:1.4795 Valid Loss:1.6203 \t Train Acc:45.19 %  Valid Acc:42.00 %\n",
      "Epoch:2/100 \t Train Loss:1.1960 Valid Loss:1.0485 \t Train Acc:57.00 %  Valid Acc:62.23 %\n",
      "Epoch:3/100 \t Train Loss:1.0568 Valid Loss:1.0018 \t Train Acc:62.01 %  Valid Acc:64.50 %\n",
      "Epoch:4/100 \t Train Loss:0.9667 Valid Loss:0.8914 \t Train Acc:65.35 %  Valid Acc:67.74 %\n",
      "Epoch:5/100 \t Train Loss:0.8785 Valid Loss:0.8787 \t Train Acc:68.68 %  Valid Acc:68.55 %\n",
      "Epoch:6/100 \t Train Loss:0.8111 Valid Loss:0.7748 \t Train Acc:71.33 %  Valid Acc:73.09 %\n",
      "Epoch:7/100 \t Train Loss:0.7559 Valid Loss:0.7115 \t Train Acc:73.36 %  Valid Acc:74.81 %\n",
      "Epoch:8/100 \t Train Loss:0.6977 Valid Loss:0.6798 \t Train Acc:75.56 %  Valid Acc:76.51 %\n",
      "Epoch:9/100 \t Train Loss:0.6565 Valid Loss:0.6716 \t Train Acc:76.92 %  Valid Acc:76.97 %\n",
      "Epoch:10/100 \t Train Loss:0.6248 Valid Loss:0.6360 \t Train Acc:78.09 %  Valid Acc:78.22 %\n",
      "Epoch:11/100 \t Train Loss:0.5937 Valid Loss:0.5865 \t Train Acc:79.41 %  Valid Acc:80.38 %\n",
      "Epoch:12/100 \t Train Loss:0.5694 Valid Loss:0.6091 \t Train Acc:80.19 %  Valid Acc:79.68 %\n",
      "Epoch:13/100 \t Train Loss:0.5450 Valid Loss:0.5536 \t Train Acc:81.01 %  Valid Acc:81.09 %\n",
      "Epoch:14/100 \t Train Loss:0.5257 Valid Loss:0.5982 \t Train Acc:81.69 %  Valid Acc:80.02 %\n",
      "Epoch:15/100 \t Train Loss:0.5049 Valid Loss:0.6182 \t Train Acc:82.60 %  Valid Acc:79.85 %\n",
      "Epoch:16/100 \t Train Loss:0.4877 Valid Loss:0.5566 \t Train Acc:82.97 %  Valid Acc:81.42 %\n",
      "Epoch:17/100 \t Train Loss:0.4739 Valid Loss:0.5153 \t Train Acc:83.43 %  Valid Acc:82.25 %\n",
      "Epoch:18/100 \t Train Loss:0.4608 Valid Loss:0.5392 \t Train Acc:83.88 %  Valid Acc:81.79 %\n",
      "Epoch:19/100 \t Train Loss:0.4471 Valid Loss:0.4915 \t Train Acc:84.37 %  Valid Acc:83.40 %\n",
      "Epoch:20/100 \t Train Loss:0.4399 Valid Loss:0.5011 \t Train Acc:84.81 %  Valid Acc:83.53 %\n",
      "Epoch:21/100 \t Train Loss:0.3560 Valid Loss:0.4488 \t Train Acc:87.45 %  Valid Acc:85.21 %\n",
      "Epoch:22/100 \t Train Loss:0.3356 Valid Loss:0.4493 \t Train Acc:88.24 %  Valid Acc:85.43 %\n",
      "Epoch:23/100 \t Train Loss:0.3274 Valid Loss:0.4653 \t Train Acc:88.69 %  Valid Acc:84.75 %\n",
      "Epoch:24/100 \t Train Loss:0.3193 Valid Loss:0.4676 \t Train Acc:88.77 %  Valid Acc:84.96 %\n",
      "Epoch:25/100 \t Train Loss:0.3135 Valid Loss:0.4495 \t Train Acc:88.99 %  Valid Acc:85.20 %\n",
      "Epoch:26/100 \t Train Loss:0.3067 Valid Loss:0.4546 \t Train Acc:89.28 %  Valid Acc:85.49 %\n",
      "Epoch:27/100 \t Train Loss:0.2979 Valid Loss:0.4509 \t Train Acc:89.52 %  Valid Acc:85.55 %\n",
      "Epoch:28/100 \t Train Loss:0.2962 Valid Loss:0.4423 \t Train Acc:89.69 %  Valid Acc:85.33 %\n",
      "Epoch:29/100 \t Train Loss:0.2908 Valid Loss:0.4489 \t Train Acc:89.67 %  Valid Acc:85.46 %\n",
      "Epoch:30/100 \t Train Loss:0.2896 Valid Loss:0.4458 \t Train Acc:89.82 %  Valid Acc:85.91 %\n",
      "Epoch:31/100 \t Train Loss:0.2841 Valid Loss:0.4681 \t Train Acc:89.97 %  Valid Acc:85.27 %\n",
      "Epoch:32/100 \t Train Loss:0.2790 Valid Loss:0.4489 \t Train Acc:90.22 %  Valid Acc:85.96 %\n",
      "Epoch:33/100 \t Train Loss:0.2759 Valid Loss:0.4366 \t Train Acc:90.38 %  Valid Acc:85.92 %\n",
      "Epoch:34/100 \t Train Loss:0.2706 Valid Loss:0.4571 \t Train Acc:90.50 %  Valid Acc:85.61 %\n",
      "Epoch:35/100 \t Train Loss:0.2686 Valid Loss:0.4537 \t Train Acc:90.50 %  Valid Acc:85.92 %\n",
      "Epoch:36/100 \t Train Loss:0.2653 Valid Loss:0.4528 \t Train Acc:90.52 %  Valid Acc:85.73 %\n",
      "Epoch:37/100 \t Train Loss:0.2612 Valid Loss:0.4463 \t Train Acc:90.60 %  Valid Acc:85.93 %\n",
      "Epoch:38/100 \t Train Loss:0.2609 Valid Loss:0.4589 \t Train Acc:90.86 %  Valid Acc:85.71 %\n",
      "Epoch:39/100 \t Train Loss:0.2533 Valid Loss:0.4428 \t Train Acc:91.01 %  Valid Acc:86.10 %\n",
      "Epoch:40/100 \t Train Loss:0.2542 Valid Loss:0.4664 \t Train Acc:91.05 %  Valid Acc:85.20 %\n",
      "Epoch:41/100 \t Train Loss:0.2218 Valid Loss:0.4382 \t Train Acc:92.08 %  Valid Acc:86.60 %\n",
      "Epoch:42/100 \t Train Loss:0.2132 Valid Loss:0.4484 \t Train Acc:92.37 %  Valid Acc:86.58 %\n",
      "Epoch:43/100 \t Train Loss:0.2107 Valid Loss:0.4452 \t Train Acc:92.58 %  Valid Acc:86.93 %\n",
      "Epoch:44/100 \t Train Loss:0.2088 Valid Loss:0.4471 \t Train Acc:92.64 %  Valid Acc:86.61 %\n",
      "Epoch:45/100 \t Train Loss:0.2097 Valid Loss:0.4415 \t Train Acc:92.62 %  Valid Acc:86.80 %\n",
      "Epoch:46/100 \t Train Loss:0.2046 Valid Loss:0.4511 \t Train Acc:92.74 %  Valid Acc:86.58 %\n",
      "Epoch:47/100 \t Train Loss:0.2020 Valid Loss:0.4575 \t Train Acc:92.82 %  Valid Acc:86.41 %\n",
      "Epoch:48/100 \t Train Loss:0.2026 Valid Loss:0.4481 \t Train Acc:92.89 %  Valid Acc:86.69 %\n",
      "Epoch:49/100 \t Train Loss:0.2026 Valid Loss:0.4502 \t Train Acc:92.87 %  Valid Acc:86.54 %\n",
      "Epoch:50/100 \t Train Loss:0.1977 Valid Loss:0.4531 \t Train Acc:93.10 %  Valid Acc:86.97 %\n",
      "Epoch:51/100 \t Train Loss:0.1976 Valid Loss:0.4587 \t Train Acc:92.98 %  Valid Acc:86.57 %\n",
      "Epoch:52/100 \t Train Loss:0.1941 Valid Loss:0.4628 \t Train Acc:93.20 %  Valid Acc:86.47 %\n",
      "Epoch:53/100 \t Train Loss:0.1939 Valid Loss:0.4631 \t Train Acc:93.21 %  Valid Acc:86.55 %\n",
      "Epoch:54/100 \t Train Loss:0.1913 Valid Loss:0.4531 \t Train Acc:93.27 %  Valid Acc:86.70 %\n",
      "Epoch:55/100 \t Train Loss:0.1896 Valid Loss:0.4605 \t Train Acc:93.35 %  Valid Acc:86.73 %\n",
      "Epoch:56/100 \t Train Loss:0.1882 Valid Loss:0.4597 \t Train Acc:93.36 %  Valid Acc:86.88 %\n",
      "Epoch:57/100 \t Train Loss:0.1875 Valid Loss:0.4651 \t Train Acc:93.37 %  Valid Acc:86.58 %\n",
      "Epoch:58/100 \t Train Loss:0.1847 Valid Loss:0.4657 \t Train Acc:93.45 %  Valid Acc:86.50 %\n",
      "Epoch:59/100 \t Train Loss:0.1881 Valid Loss:0.4647 \t Train Acc:93.35 %  Valid Acc:86.45 %\n",
      "Epoch:60/100 \t Train Loss:0.1853 Valid Loss:0.4653 \t Train Acc:93.46 %  Valid Acc:86.47 %\n",
      "Epoch:61/100 \t Train Loss:0.1745 Valid Loss:0.4610 \t Train Acc:93.80 %  Valid Acc:86.91 %\n",
      "Epoch:62/100 \t Train Loss:0.1728 Valid Loss:0.4662 \t Train Acc:93.80 %  Valid Acc:86.78 %\n",
      "Epoch:63/100 \t Train Loss:0.1725 Valid Loss:0.4630 \t Train Acc:93.93 %  Valid Acc:86.79 %\n",
      "Epoch:64/100 \t Train Loss:0.1688 Valid Loss:0.4643 \t Train Acc:94.13 %  Valid Acc:86.74 %\n",
      "Epoch:65/100 \t Train Loss:0.1688 Valid Loss:0.4621 \t Train Acc:94.07 %  Valid Acc:86.89 %\n",
      "Epoch:66/100 \t Train Loss:0.1683 Valid Loss:0.4670 \t Train Acc:94.18 %  Valid Acc:86.78 %\n",
      "Epoch:67/100 \t Train Loss:0.1699 Valid Loss:0.4657 \t Train Acc:94.01 %  Valid Acc:86.85 %\n",
      "Epoch:68/100 \t Train Loss:0.1676 Valid Loss:0.4676 \t Train Acc:94.06 %  Valid Acc:86.71 %\n",
      "Epoch:69/100 \t Train Loss:0.1658 Valid Loss:0.4658 \t Train Acc:94.15 %  Valid Acc:86.73 %\n",
      "Epoch:70/100 \t Train Loss:0.1654 Valid Loss:0.4698 \t Train Acc:94.11 %  Valid Acc:86.78 %\n",
      "Epoch:71/100 \t Train Loss:0.1673 Valid Loss:0.4707 \t Train Acc:94.07 %  Valid Acc:86.57 %\n",
      "Epoch:72/100 \t Train Loss:0.1668 Valid Loss:0.4676 \t Train Acc:94.09 %  Valid Acc:86.91 %\n",
      "Epoch:73/100 \t Train Loss:0.1649 Valid Loss:0.4640 \t Train Acc:94.14 %  Valid Acc:86.88 %\n",
      "Epoch:74/100 \t Train Loss:0.1637 Valid Loss:0.4663 \t Train Acc:94.18 %  Valid Acc:86.94 %\n",
      "Epoch:75/100 \t Train Loss:0.1642 Valid Loss:0.4727 \t Train Acc:94.17 %  Valid Acc:86.77 %\n",
      "Epoch:76/100 \t Train Loss:0.1633 Valid Loss:0.4799 \t Train Acc:94.14 %  Valid Acc:86.57 %\n",
      "Epoch:77/100 \t Train Loss:0.1628 Valid Loss:0.4761 \t Train Acc:94.21 %  Valid Acc:86.77 %\n",
      "Epoch:78/100 \t Train Loss:0.1627 Valid Loss:0.4736 \t Train Acc:94.27 %  Valid Acc:87.07 %\n",
      "Epoch:79/100 \t Train Loss:0.1638 Valid Loss:0.4678 \t Train Acc:94.19 %  Valid Acc:87.04 %\n",
      "Epoch:80/100 \t Train Loss:0.1619 Valid Loss:0.4723 \t Train Acc:94.18 %  Valid Acc:87.07 %\n",
      "Epoch:81/100 \t Train Loss:0.1575 Valid Loss:0.4716 \t Train Acc:94.41 %  Valid Acc:87.07 %\n",
      "Epoch:82/100 \t Train Loss:0.1573 Valid Loss:0.4763 \t Train Acc:94.38 %  Valid Acc:87.15 %\n",
      "Epoch:83/100 \t Train Loss:0.1582 Valid Loss:0.4730 \t Train Acc:94.36 %  Valid Acc:87.04 %\n",
      "Epoch:84/100 \t Train Loss:0.1573 Valid Loss:0.4763 \t Train Acc:94.39 %  Valid Acc:87.05 %\n",
      "Epoch:85/100 \t Train Loss:0.1567 Valid Loss:0.4764 \t Train Acc:94.55 %  Valid Acc:87.03 %\n",
      "Epoch:86/100 \t Train Loss:0.1556 Valid Loss:0.4769 \t Train Acc:94.59 %  Valid Acc:87.08 %\n",
      "Epoch:87/100 \t Train Loss:0.1569 Valid Loss:0.4752 \t Train Acc:94.46 %  Valid Acc:87.17 %\n",
      "Epoch:88/100 \t Train Loss:0.1527 Valid Loss:0.4754 \t Train Acc:94.64 %  Valid Acc:87.17 %\n",
      "Epoch:89/100 \t Train Loss:0.1561 Valid Loss:0.4757 \t Train Acc:94.55 %  Valid Acc:87.15 %\n",
      "Epoch:90/100 \t Train Loss:0.1573 Valid Loss:0.4764 \t Train Acc:94.38 %  Valid Acc:87.00 %\n",
      "Epoch:91/100 \t Train Loss:0.1567 Valid Loss:0.4765 \t Train Acc:94.37 %  Valid Acc:87.12 %\n",
      "Epoch:92/100 \t Train Loss:0.1561 Valid Loss:0.4771 \t Train Acc:94.55 %  Valid Acc:87.03 %\n",
      "Epoch:93/100 \t Train Loss:0.1558 Valid Loss:0.4781 \t Train Acc:94.53 %  Valid Acc:87.09 %\n",
      "Epoch:94/100 \t Train Loss:0.1548 Valid Loss:0.4779 \t Train Acc:94.49 %  Valid Acc:87.05 %\n",
      "Epoch:95/100 \t Train Loss:0.1547 Valid Loss:0.4763 \t Train Acc:94.61 %  Valid Acc:86.95 %\n",
      "Epoch:96/100 \t Train Loss:0.1549 Valid Loss:0.4772 \t Train Acc:94.57 %  Valid Acc:87.08 %\n",
      "Epoch:97/100 \t Train Loss:0.1556 Valid Loss:0.4800 \t Train Acc:94.52 %  Valid Acc:87.05 %\n",
      "Epoch:98/100 \t Train Loss:0.1551 Valid Loss:0.4798 \t Train Acc:94.56 %  Valid Acc:87.00 %\n",
      "Epoch:99/100 \t Train Loss:0.1559 Valid Loss:0.4780 \t Train Acc:94.51 %  Valid Acc:87.04 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 14:44:00,099] Trial 1 finished with value: 87.12 and parameters: {'sigma_1': 1.460078412930732, 'sigma_2': 0.2850514594273182, 'sigma_3': 4.741645683751368, 'sigma_4': 0.13794080391823532, 'sigma_5': 3.5363863499999013, 'sigma_6': 0.2707511221430693, 'sigma_7': 1.2551966642837775, 'sigma_8': 4.3336125432779, 'sigma_9': 3.18592054239998, 'sigma_10': 1.8833143561449015, 'sigma_11': 4.232682390990908, 'sigma_12': 2.087922137128098, 'sigma_13': 3.7364446487582934}. Best is trial 1 with value: 87.12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1543 Valid Loss:0.4776 \t Train Acc:94.59 %  Valid Acc:87.12 %\n",
      "Epoch:1/100 \t Train Loss:1.4340 Valid Loss:1.3840 \t Train Acc:47.21 %  Valid Acc:49.08 %\n",
      "Epoch:2/100 \t Train Loss:1.1223 Valid Loss:1.0375 \t Train Acc:59.49 %  Valid Acc:63.13 %\n",
      "Epoch:3/100 \t Train Loss:1.0105 Valid Loss:0.9477 \t Train Acc:63.65 %  Valid Acc:66.52 %\n",
      "Epoch:4/100 \t Train Loss:0.9263 Valid Loss:0.9419 \t Train Acc:66.80 %  Valid Acc:67.06 %\n",
      "Epoch:5/100 \t Train Loss:0.8648 Valid Loss:0.9078 \t Train Acc:69.00 %  Valid Acc:68.48 %\n",
      "Epoch:6/100 \t Train Loss:0.8195 Valid Loss:0.8261 \t Train Acc:70.99 %  Valid Acc:70.53 %\n",
      "Epoch:7/100 \t Train Loss:0.7595 Valid Loss:0.7383 \t Train Acc:73.15 %  Valid Acc:74.08 %\n",
      "Epoch:8/100 \t Train Loss:0.7149 Valid Loss:0.7786 \t Train Acc:74.65 %  Valid Acc:72.83 %\n",
      "Epoch:9/100 \t Train Loss:0.6769 Valid Loss:0.6798 \t Train Acc:76.15 %  Valid Acc:76.55 %\n",
      "Epoch:10/100 \t Train Loss:0.6398 Valid Loss:0.6677 \t Train Acc:77.64 %  Valid Acc:77.25 %\n",
      "Epoch:11/100 \t Train Loss:0.6100 Valid Loss:0.6522 \t Train Acc:78.83 %  Valid Acc:78.33 %\n",
      "Epoch:12/100 \t Train Loss:0.5848 Valid Loss:0.6373 \t Train Acc:79.60 %  Valid Acc:77.88 %\n",
      "Epoch:13/100 \t Train Loss:0.5580 Valid Loss:0.6055 \t Train Acc:80.66 %  Valid Acc:79.00 %\n",
      "Epoch:14/100 \t Train Loss:0.5422 Valid Loss:0.6071 \t Train Acc:81.04 %  Valid Acc:79.18 %\n",
      "Epoch:15/100 \t Train Loss:0.5199 Valid Loss:0.5598 \t Train Acc:81.94 %  Valid Acc:81.28 %\n",
      "Epoch:16/100 \t Train Loss:0.5060 Valid Loss:0.5602 \t Train Acc:82.26 %  Valid Acc:81.35 %\n",
      "Epoch:17/100 \t Train Loss:0.4912 Valid Loss:0.5583 \t Train Acc:82.83 %  Valid Acc:81.53 %\n",
      "Epoch:18/100 \t Train Loss:0.4840 Valid Loss:0.5743 \t Train Acc:83.22 %  Valid Acc:81.34 %\n",
      "Epoch:19/100 \t Train Loss:0.4702 Valid Loss:0.5141 \t Train Acc:83.63 %  Valid Acc:82.34 %\n",
      "Epoch:20/100 \t Train Loss:0.4549 Valid Loss:0.4960 \t Train Acc:84.18 %  Valid Acc:83.34 %\n",
      "Epoch:21/100 \t Train Loss:0.3747 Valid Loss:0.4762 \t Train Acc:86.83 %  Valid Acc:84.17 %\n",
      "Epoch:22/100 \t Train Loss:0.3524 Valid Loss:0.4609 \t Train Acc:87.55 %  Valid Acc:84.89 %\n",
      "Epoch:23/100 \t Train Loss:0.3434 Valid Loss:0.4585 \t Train Acc:88.05 %  Valid Acc:85.16 %\n",
      "Epoch:24/100 \t Train Loss:0.3373 Valid Loss:0.4894 \t Train Acc:88.20 %  Valid Acc:84.03 %\n",
      "Epoch:25/100 \t Train Loss:0.3320 Valid Loss:0.4576 \t Train Acc:88.39 %  Valid Acc:84.80 %\n",
      "Epoch:26/100 \t Train Loss:0.3259 Valid Loss:0.4685 \t Train Acc:88.65 %  Valid Acc:84.70 %\n",
      "Epoch:27/100 \t Train Loss:0.3188 Valid Loss:0.4715 \t Train Acc:88.94 %  Valid Acc:84.59 %\n",
      "Epoch:28/100 \t Train Loss:0.3128 Valid Loss:0.4595 \t Train Acc:89.01 %  Valid Acc:85.02 %\n",
      "Epoch:29/100 \t Train Loss:0.3097 Valid Loss:0.4556 \t Train Acc:89.21 %  Valid Acc:85.51 %\n",
      "Epoch:30/100 \t Train Loss:0.3046 Valid Loss:0.4613 \t Train Acc:89.28 %  Valid Acc:85.10 %\n",
      "Epoch:31/100 \t Train Loss:0.3040 Valid Loss:0.4430 \t Train Acc:89.29 %  Valid Acc:85.26 %\n",
      "Epoch:32/100 \t Train Loss:0.3005 Valid Loss:0.4562 \t Train Acc:89.54 %  Valid Acc:85.00 %\n",
      "Epoch:33/100 \t Train Loss:0.2951 Valid Loss:0.4492 \t Train Acc:89.56 %  Valid Acc:85.96 %\n",
      "Epoch:34/100 \t Train Loss:0.2892 Valid Loss:0.4518 \t Train Acc:89.81 %  Valid Acc:85.52 %\n",
      "Epoch:35/100 \t Train Loss:0.2853 Valid Loss:0.4463 \t Train Acc:89.84 %  Valid Acc:85.43 %\n",
      "Epoch:36/100 \t Train Loss:0.2814 Valid Loss:0.4525 \t Train Acc:90.05 %  Valid Acc:85.99 %\n",
      "Epoch:37/100 \t Train Loss:0.2782 Valid Loss:0.4598 \t Train Acc:90.23 %  Valid Acc:85.42 %\n",
      "Epoch:38/100 \t Train Loss:0.2737 Valid Loss:0.4625 \t Train Acc:90.30 %  Valid Acc:85.60 %\n",
      "Epoch:39/100 \t Train Loss:0.2733 Valid Loss:0.4669 \t Train Acc:90.48 %  Valid Acc:85.18 %\n",
      "Epoch:40/100 \t Train Loss:0.2689 Valid Loss:0.4443 \t Train Acc:90.37 %  Valid Acc:85.94 %\n",
      "Epoch:41/100 \t Train Loss:0.2374 Valid Loss:0.4389 \t Train Acc:91.58 %  Valid Acc:86.32 %\n",
      "Epoch:42/100 \t Train Loss:0.2314 Valid Loss:0.4427 \t Train Acc:91.97 %  Valid Acc:86.35 %\n",
      "Epoch:43/100 \t Train Loss:0.2303 Valid Loss:0.4412 \t Train Acc:91.87 %  Valid Acc:86.23 %\n",
      "Epoch:44/100 \t Train Loss:0.2274 Valid Loss:0.4378 \t Train Acc:91.91 %  Valid Acc:86.59 %\n",
      "Epoch:45/100 \t Train Loss:0.2239 Valid Loss:0.4426 \t Train Acc:91.95 %  Valid Acc:86.33 %\n",
      "Epoch:46/100 \t Train Loss:0.2216 Valid Loss:0.4557 \t Train Acc:92.23 %  Valid Acc:86.45 %\n",
      "Epoch:47/100 \t Train Loss:0.2194 Valid Loss:0.4373 \t Train Acc:92.24 %  Valid Acc:86.67 %\n",
      "Epoch:48/100 \t Train Loss:0.2179 Valid Loss:0.4537 \t Train Acc:92.28 %  Valid Acc:86.21 %\n",
      "Epoch:49/100 \t Train Loss:0.2180 Valid Loss:0.4464 \t Train Acc:92.11 %  Valid Acc:86.55 %\n",
      "Epoch:50/100 \t Train Loss:0.2148 Valid Loss:0.4464 \t Train Acc:92.38 %  Valid Acc:86.53 %\n",
      "Epoch:51/100 \t Train Loss:0.2104 Valid Loss:0.4560 \t Train Acc:92.56 %  Valid Acc:86.24 %\n",
      "Epoch:52/100 \t Train Loss:0.2114 Valid Loss:0.4515 \t Train Acc:92.53 %  Valid Acc:86.49 %\n",
      "Epoch:53/100 \t Train Loss:0.2111 Valid Loss:0.4571 \t Train Acc:92.45 %  Valid Acc:86.51 %\n",
      "Epoch:54/100 \t Train Loss:0.2116 Valid Loss:0.4482 \t Train Acc:92.37 %  Valid Acc:86.69 %\n",
      "Epoch:55/100 \t Train Loss:0.2063 Valid Loss:0.4446 \t Train Acc:92.66 %  Valid Acc:86.58 %\n",
      "Epoch:56/100 \t Train Loss:0.2084 Valid Loss:0.4508 \t Train Acc:92.64 %  Valid Acc:86.78 %\n",
      "Epoch:57/100 \t Train Loss:0.2042 Valid Loss:0.4624 \t Train Acc:92.78 %  Valid Acc:86.23 %\n",
      "Epoch:58/100 \t Train Loss:0.2038 Valid Loss:0.4541 \t Train Acc:92.69 %  Valid Acc:86.50 %\n",
      "Epoch:59/100 \t Train Loss:0.2062 Valid Loss:0.4631 \t Train Acc:92.71 %  Valid Acc:86.22 %\n",
      "Epoch:60/100 \t Train Loss:0.2031 Valid Loss:0.4629 \t Train Acc:92.78 %  Valid Acc:86.34 %\n",
      "Epoch:61/100 \t Train Loss:0.1928 Valid Loss:0.4557 \t Train Acc:93.17 %  Valid Acc:86.77 %\n",
      "Epoch:62/100 \t Train Loss:0.1875 Valid Loss:0.4541 \t Train Acc:93.31 %  Valid Acc:86.80 %\n",
      "Epoch:63/100 \t Train Loss:0.1906 Valid Loss:0.4521 \t Train Acc:93.29 %  Valid Acc:86.83 %\n",
      "Epoch:64/100 \t Train Loss:0.1898 Valid Loss:0.4611 \t Train Acc:93.27 %  Valid Acc:86.61 %\n",
      "Epoch:65/100 \t Train Loss:0.1890 Valid Loss:0.4526 \t Train Acc:93.31 %  Valid Acc:86.92 %\n",
      "Epoch:66/100 \t Train Loss:0.1844 Valid Loss:0.4607 \t Train Acc:93.51 %  Valid Acc:86.62 %\n",
      "Epoch:67/100 \t Train Loss:0.1861 Valid Loss:0.4546 \t Train Acc:93.42 %  Valid Acc:86.91 %\n",
      "Epoch:68/100 \t Train Loss:0.1849 Valid Loss:0.4626 \t Train Acc:93.42 %  Valid Acc:86.55 %\n",
      "Epoch:69/100 \t Train Loss:0.1847 Valid Loss:0.4574 \t Train Acc:93.53 %  Valid Acc:86.86 %\n",
      "Epoch:70/100 \t Train Loss:0.1806 Valid Loss:0.4634 \t Train Acc:93.59 %  Valid Acc:86.75 %\n",
      "Epoch:71/100 \t Train Loss:0.1816 Valid Loss:0.4618 \t Train Acc:93.64 %  Valid Acc:86.81 %\n",
      "Epoch:72/100 \t Train Loss:0.1771 Valid Loss:0.4638 \t Train Acc:93.73 %  Valid Acc:86.76 %\n",
      "Epoch:73/100 \t Train Loss:0.1808 Valid Loss:0.4693 \t Train Acc:93.62 %  Valid Acc:86.64 %\n",
      "Epoch:74/100 \t Train Loss:0.1814 Valid Loss:0.4669 \t Train Acc:93.43 %  Valid Acc:86.79 %\n",
      "Epoch:75/100 \t Train Loss:0.1813 Valid Loss:0.4674 \t Train Acc:93.51 %  Valid Acc:86.59 %\n",
      "Epoch:76/100 \t Train Loss:0.1804 Valid Loss:0.4613 \t Train Acc:93.56 %  Valid Acc:86.74 %\n",
      "Epoch:77/100 \t Train Loss:0.1818 Valid Loss:0.4648 \t Train Acc:93.63 %  Valid Acc:86.52 %\n",
      "Epoch:78/100 \t Train Loss:0.1779 Valid Loss:0.4709 \t Train Acc:93.65 %  Valid Acc:86.71 %\n",
      "Epoch:79/100 \t Train Loss:0.1792 Valid Loss:0.4684 \t Train Acc:93.75 %  Valid Acc:86.76 %\n",
      "Epoch:80/100 \t Train Loss:0.1794 Valid Loss:0.4674 \t Train Acc:93.61 %  Valid Acc:86.47 %\n",
      "Epoch:81/100 \t Train Loss:0.1751 Valid Loss:0.4664 \t Train Acc:93.69 %  Valid Acc:86.71 %\n",
      "Epoch:82/100 \t Train Loss:0.1728 Valid Loss:0.4632 \t Train Acc:93.87 %  Valid Acc:86.75 %\n",
      "Epoch:83/100 \t Train Loss:0.1751 Valid Loss:0.4638 \t Train Acc:93.75 %  Valid Acc:86.83 %\n",
      "Epoch:84/100 \t Train Loss:0.1728 Valid Loss:0.4671 \t Train Acc:93.94 %  Valid Acc:86.79 %\n",
      "Epoch:85/100 \t Train Loss:0.1735 Valid Loss:0.4670 \t Train Acc:93.92 %  Valid Acc:86.69 %\n",
      "Epoch:86/100 \t Train Loss:0.1741 Valid Loss:0.4695 \t Train Acc:93.91 %  Valid Acc:86.69 %\n",
      "Epoch:87/100 \t Train Loss:0.1715 Valid Loss:0.4694 \t Train Acc:93.84 %  Valid Acc:86.84 %\n",
      "Epoch:88/100 \t Train Loss:0.1725 Valid Loss:0.4667 \t Train Acc:93.90 %  Valid Acc:86.81 %\n",
      "Epoch:89/100 \t Train Loss:0.1706 Valid Loss:0.4695 \t Train Acc:94.03 %  Valid Acc:86.83 %\n",
      "Epoch:90/100 \t Train Loss:0.1706 Valid Loss:0.4707 \t Train Acc:93.91 %  Valid Acc:86.80 %\n",
      "Epoch:91/100 \t Train Loss:0.1725 Valid Loss:0.4662 \t Train Acc:93.81 %  Valid Acc:86.81 %\n",
      "Epoch:92/100 \t Train Loss:0.1720 Valid Loss:0.4685 \t Train Acc:93.81 %  Valid Acc:86.77 %\n",
      "Epoch:93/100 \t Train Loss:0.1722 Valid Loss:0.4720 \t Train Acc:93.94 %  Valid Acc:86.83 %\n",
      "Epoch:94/100 \t Train Loss:0.1705 Valid Loss:0.4717 \t Train Acc:93.90 %  Valid Acc:86.85 %\n",
      "Epoch:95/100 \t Train Loss:0.1736 Valid Loss:0.4689 \t Train Acc:93.92 %  Valid Acc:86.78 %\n",
      "Epoch:96/100 \t Train Loss:0.1702 Valid Loss:0.4689 \t Train Acc:94.07 %  Valid Acc:86.70 %\n",
      "Epoch:97/100 \t Train Loss:0.1702 Valid Loss:0.4711 \t Train Acc:93.95 %  Valid Acc:86.70 %\n",
      "Epoch:98/100 \t Train Loss:0.1712 Valid Loss:0.4694 \t Train Acc:93.83 %  Valid Acc:86.62 %\n",
      "Epoch:99/100 \t Train Loss:0.1714 Valid Loss:0.4687 \t Train Acc:93.92 %  Valid Acc:86.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 16:05:07,957] Trial 2 finished with value: 86.66 and parameters: {'sigma_1': 1.3447156070416522, 'sigma_2': 1.4379097826625207, 'sigma_3': 0.35941033919313503, 'sigma_4': 2.209548981916471, 'sigma_5': 3.674288462459729, 'sigma_6': 2.818344999273431, 'sigma_7': 0.8664302979982087, 'sigma_8': 0.6830547146775832, 'sigma_9': 4.673451899321812, 'sigma_10': 0.8285981569855777, 'sigma_11': 4.274502357724631, 'sigma_12': 1.4525907588423939, 'sigma_13': 0.5241027526455244}. Best is trial 1 with value: 87.12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1695 Valid Loss:0.4727 \t Train Acc:94.09 %  Valid Acc:86.66 %\n",
      "Epoch:1/100 \t Train Loss:1.5289 Valid Loss:1.8247 \t Train Acc:43.49 %  Valid Acc:37.84 %\n",
      "Epoch:2/100 \t Train Loss:1.2049 Valid Loss:1.0827 \t Train Acc:56.43 %  Valid Acc:61.06 %\n",
      "Epoch:3/100 \t Train Loss:1.0453 Valid Loss:0.9428 \t Train Acc:62.58 %  Valid Acc:65.81 %\n",
      "Epoch:4/100 \t Train Loss:0.9307 Valid Loss:0.9029 \t Train Acc:66.79 %  Valid Acc:68.39 %\n",
      "Epoch:5/100 \t Train Loss:0.8384 Valid Loss:0.8429 \t Train Acc:70.21 %  Valid Acc:70.70 %\n",
      "Epoch:6/100 \t Train Loss:0.7649 Valid Loss:0.7504 \t Train Acc:73.15 %  Valid Acc:73.65 %\n",
      "Epoch:7/100 \t Train Loss:0.7159 Valid Loss:0.7607 \t Train Acc:74.85 %  Valid Acc:74.16 %\n",
      "Epoch:8/100 \t Train Loss:0.6657 Valid Loss:0.7247 \t Train Acc:76.76 %  Valid Acc:75.32 %\n",
      "Epoch:9/100 \t Train Loss:0.6332 Valid Loss:0.6248 \t Train Acc:77.92 %  Valid Acc:78.61 %\n",
      "Epoch:10/100 \t Train Loss:0.5998 Valid Loss:0.6584 \t Train Acc:79.00 %  Valid Acc:77.98 %\n",
      "Epoch:11/100 \t Train Loss:0.5724 Valid Loss:0.6177 \t Train Acc:80.18 %  Valid Acc:79.37 %\n",
      "Epoch:12/100 \t Train Loss:0.5582 Valid Loss:0.6069 \t Train Acc:80.57 %  Valid Acc:79.37 %\n",
      "Epoch:13/100 \t Train Loss:0.5362 Valid Loss:0.5770 \t Train Acc:81.34 %  Valid Acc:80.48 %\n",
      "Epoch:14/100 \t Train Loss:0.5170 Valid Loss:0.5666 \t Train Acc:82.09 %  Valid Acc:80.95 %\n",
      "Epoch:15/100 \t Train Loss:0.5006 Valid Loss:0.5690 \t Train Acc:82.41 %  Valid Acc:81.53 %\n",
      "Epoch:16/100 \t Train Loss:0.4882 Valid Loss:0.5459 \t Train Acc:83.08 %  Valid Acc:81.90 %\n",
      "Epoch:17/100 \t Train Loss:0.4719 Valid Loss:0.5504 \t Train Acc:83.44 %  Valid Acc:81.31 %\n",
      "Epoch:18/100 \t Train Loss:0.4645 Valid Loss:0.5203 \t Train Acc:83.74 %  Valid Acc:82.69 %\n",
      "Epoch:19/100 \t Train Loss:0.4513 Valid Loss:0.5249 \t Train Acc:84.32 %  Valid Acc:82.27 %\n",
      "Epoch:20/100 \t Train Loss:0.4435 Valid Loss:0.5520 \t Train Acc:84.60 %  Valid Acc:82.02 %\n",
      "Epoch:21/100 \t Train Loss:0.3645 Valid Loss:0.4834 \t Train Acc:87.28 %  Valid Acc:84.28 %\n",
      "Epoch:22/100 \t Train Loss:0.3447 Valid Loss:0.4847 \t Train Acc:88.02 %  Valid Acc:84.28 %\n",
      "Epoch:23/100 \t Train Loss:0.3380 Valid Loss:0.4706 \t Train Acc:88.22 %  Valid Acc:84.85 %\n",
      "Epoch:24/100 \t Train Loss:0.3307 Valid Loss:0.4733 \t Train Acc:88.56 %  Valid Acc:84.76 %\n",
      "Epoch:25/100 \t Train Loss:0.3230 Valid Loss:0.4629 \t Train Acc:88.70 %  Valid Acc:85.11 %\n",
      "Epoch:26/100 \t Train Loss:0.3195 Valid Loss:0.4696 \t Train Acc:88.87 %  Valid Acc:84.73 %\n",
      "Epoch:27/100 \t Train Loss:0.3119 Valid Loss:0.4789 \t Train Acc:89.15 %  Valid Acc:84.56 %\n",
      "Epoch:28/100 \t Train Loss:0.3113 Valid Loss:0.4626 \t Train Acc:89.09 %  Valid Acc:85.35 %\n",
      "Epoch:29/100 \t Train Loss:0.3074 Valid Loss:0.4739 \t Train Acc:89.21 %  Valid Acc:84.88 %\n",
      "Epoch:30/100 \t Train Loss:0.3015 Valid Loss:0.4767 \t Train Acc:89.36 %  Valid Acc:85.43 %\n",
      "Epoch:31/100 \t Train Loss:0.2988 Valid Loss:0.4776 \t Train Acc:89.54 %  Valid Acc:85.22 %\n",
      "Epoch:32/100 \t Train Loss:0.2929 Valid Loss:0.4651 \t Train Acc:89.72 %  Valid Acc:85.18 %\n",
      "Epoch:33/100 \t Train Loss:0.2917 Valid Loss:0.4769 \t Train Acc:89.91 %  Valid Acc:84.96 %\n",
      "Epoch:34/100 \t Train Loss:0.2839 Valid Loss:0.4655 \t Train Acc:90.00 %  Valid Acc:85.05 %\n",
      "Epoch:35/100 \t Train Loss:0.2847 Valid Loss:0.4597 \t Train Acc:90.06 %  Valid Acc:85.89 %\n",
      "Epoch:36/100 \t Train Loss:0.2827 Valid Loss:0.4557 \t Train Acc:90.11 %  Valid Acc:85.43 %\n",
      "Epoch:37/100 \t Train Loss:0.2803 Valid Loss:0.4641 \t Train Acc:90.16 %  Valid Acc:85.46 %\n",
      "Epoch:38/100 \t Train Loss:0.2757 Valid Loss:0.4740 \t Train Acc:90.27 %  Valid Acc:85.20 %\n",
      "Epoch:39/100 \t Train Loss:0.2723 Valid Loss:0.4757 \t Train Acc:90.48 %  Valid Acc:85.46 %\n",
      "Epoch:40/100 \t Train Loss:0.2687 Valid Loss:0.4625 \t Train Acc:90.53 %  Valid Acc:85.71 %\n",
      "Epoch:41/100 \t Train Loss:0.2417 Valid Loss:0.4503 \t Train Acc:91.47 %  Valid Acc:86.00 %\n",
      "Epoch:42/100 \t Train Loss:0.2380 Valid Loss:0.4446 \t Train Acc:91.72 %  Valid Acc:86.56 %\n",
      "Epoch:43/100 \t Train Loss:0.2350 Valid Loss:0.4536 \t Train Acc:91.75 %  Valid Acc:86.10 %\n",
      "Epoch:44/100 \t Train Loss:0.2306 Valid Loss:0.4569 \t Train Acc:91.93 %  Valid Acc:86.24 %\n",
      "Epoch:45/100 \t Train Loss:0.2244 Valid Loss:0.4523 \t Train Acc:92.15 %  Valid Acc:86.24 %\n",
      "Epoch:46/100 \t Train Loss:0.2220 Valid Loss:0.4584 \t Train Acc:92.19 %  Valid Acc:86.34 %\n",
      "Epoch:47/100 \t Train Loss:0.2220 Valid Loss:0.4593 \t Train Acc:92.17 %  Valid Acc:86.24 %\n",
      "Epoch:48/100 \t Train Loss:0.2214 Valid Loss:0.4631 \t Train Acc:92.15 %  Valid Acc:86.07 %\n",
      "Epoch:49/100 \t Train Loss:0.2212 Valid Loss:0.4633 \t Train Acc:92.17 %  Valid Acc:86.13 %\n",
      "Epoch:50/100 \t Train Loss:0.2190 Valid Loss:0.4624 \t Train Acc:92.35 %  Valid Acc:86.23 %\n",
      "Epoch:51/100 \t Train Loss:0.2196 Valid Loss:0.4520 \t Train Acc:92.41 %  Valid Acc:86.46 %\n",
      "Epoch:52/100 \t Train Loss:0.2156 Valid Loss:0.4652 \t Train Acc:92.50 %  Valid Acc:86.21 %\n",
      "Epoch:53/100 \t Train Loss:0.2167 Valid Loss:0.4561 \t Train Acc:92.34 %  Valid Acc:86.29 %\n",
      "Epoch:54/100 \t Train Loss:0.2153 Valid Loss:0.4568 \t Train Acc:92.57 %  Valid Acc:86.60 %\n",
      "Epoch:55/100 \t Train Loss:0.2145 Valid Loss:0.4572 \t Train Acc:92.43 %  Valid Acc:86.56 %\n",
      "Epoch:56/100 \t Train Loss:0.2125 Valid Loss:0.4627 \t Train Acc:92.52 %  Valid Acc:86.45 %\n",
      "Epoch:57/100 \t Train Loss:0.2105 Valid Loss:0.4668 \t Train Acc:92.53 %  Valid Acc:86.36 %\n",
      "Epoch:58/100 \t Train Loss:0.2105 Valid Loss:0.4675 \t Train Acc:92.54 %  Valid Acc:86.35 %\n",
      "Epoch:59/100 \t Train Loss:0.2075 Valid Loss:0.4546 \t Train Acc:92.66 %  Valid Acc:86.68 %\n",
      "Epoch:60/100 \t Train Loss:0.2075 Valid Loss:0.4680 \t Train Acc:92.69 %  Valid Acc:86.28 %\n",
      "Epoch:61/100 \t Train Loss:0.1946 Valid Loss:0.4614 \t Train Acc:93.06 %  Valid Acc:86.64 %\n",
      "Epoch:62/100 \t Train Loss:0.1939 Valid Loss:0.4618 \t Train Acc:93.13 %  Valid Acc:86.34 %\n",
      "Epoch:63/100 \t Train Loss:0.1940 Valid Loss:0.4602 \t Train Acc:93.14 %  Valid Acc:86.53 %\n",
      "Epoch:64/100 \t Train Loss:0.1942 Valid Loss:0.4625 \t Train Acc:93.06 %  Valid Acc:86.61 %\n",
      "Epoch:65/100 \t Train Loss:0.1934 Valid Loss:0.4640 \t Train Acc:93.13 %  Valid Acc:86.49 %\n",
      "Epoch:66/100 \t Train Loss:0.1940 Valid Loss:0.4690 \t Train Acc:92.94 %  Valid Acc:86.44 %\n",
      "Epoch:67/100 \t Train Loss:0.1913 Valid Loss:0.4619 \t Train Acc:93.22 %  Valid Acc:86.57 %\n",
      "Epoch:68/100 \t Train Loss:0.1924 Valid Loss:0.4682 \t Train Acc:93.13 %  Valid Acc:86.38 %\n",
      "Epoch:69/100 \t Train Loss:0.1898 Valid Loss:0.4680 \t Train Acc:93.27 %  Valid Acc:86.62 %\n",
      "Epoch:70/100 \t Train Loss:0.1919 Valid Loss:0.4707 \t Train Acc:93.26 %  Valid Acc:86.36 %\n",
      "Epoch:71/100 \t Train Loss:0.1900 Valid Loss:0.4692 \t Train Acc:93.32 %  Valid Acc:86.39 %\n",
      "Epoch:72/100 \t Train Loss:0.1914 Valid Loss:0.4679 \t Train Acc:93.17 %  Valid Acc:86.57 %\n",
      "Epoch:73/100 \t Train Loss:0.1885 Valid Loss:0.4717 \t Train Acc:93.29 %  Valid Acc:86.71 %\n",
      "Epoch:74/100 \t Train Loss:0.1902 Valid Loss:0.4712 \t Train Acc:93.21 %  Valid Acc:86.44 %\n",
      "Epoch:75/100 \t Train Loss:0.1873 Valid Loss:0.4697 \t Train Acc:93.38 %  Valid Acc:86.42 %\n",
      "Epoch:76/100 \t Train Loss:0.1888 Valid Loss:0.4703 \t Train Acc:93.25 %  Valid Acc:86.37 %\n",
      "Epoch:77/100 \t Train Loss:0.1864 Valid Loss:0.4714 \t Train Acc:93.29 %  Valid Acc:86.60 %\n",
      "Epoch:78/100 \t Train Loss:0.1861 Valid Loss:0.4707 \t Train Acc:93.39 %  Valid Acc:86.43 %\n",
      "Epoch:79/100 \t Train Loss:0.1878 Valid Loss:0.4704 \t Train Acc:93.33 %  Valid Acc:86.58 %\n",
      "Epoch:80/100 \t Train Loss:0.1843 Valid Loss:0.4752 \t Train Acc:93.43 %  Valid Acc:86.49 %\n",
      "Epoch:81/100 \t Train Loss:0.1824 Valid Loss:0.4723 \t Train Acc:93.54 %  Valid Acc:86.54 %\n",
      "Epoch:82/100 \t Train Loss:0.1820 Valid Loss:0.4715 \t Train Acc:93.54 %  Valid Acc:86.63 %\n",
      "Epoch:83/100 \t Train Loss:0.1838 Valid Loss:0.4736 \t Train Acc:93.51 %  Valid Acc:86.54 %\n",
      "Epoch:84/100 \t Train Loss:0.1806 Valid Loss:0.4734 \t Train Acc:93.56 %  Valid Acc:86.51 %\n",
      "Epoch:85/100 \t Train Loss:0.1820 Valid Loss:0.4750 \t Train Acc:93.62 %  Valid Acc:86.63 %\n",
      "Epoch:86/100 \t Train Loss:0.1799 Valid Loss:0.4744 \t Train Acc:93.65 %  Valid Acc:86.45 %\n",
      "Epoch:87/100 \t Train Loss:0.1820 Valid Loss:0.4741 \t Train Acc:93.52 %  Valid Acc:86.62 %\n",
      "Epoch:88/100 \t Train Loss:0.1807 Valid Loss:0.4739 \t Train Acc:93.60 %  Valid Acc:86.51 %\n",
      "Epoch:89/100 \t Train Loss:0.1789 Valid Loss:0.4730 \t Train Acc:93.70 %  Valid Acc:86.49 %\n",
      "Epoch:90/100 \t Train Loss:0.1818 Valid Loss:0.4775 \t Train Acc:93.55 %  Valid Acc:86.61 %\n",
      "Epoch:91/100 \t Train Loss:0.1815 Valid Loss:0.4741 \t Train Acc:93.53 %  Valid Acc:86.56 %\n",
      "Epoch:92/100 \t Train Loss:0.1802 Valid Loss:0.4757 \t Train Acc:93.61 %  Valid Acc:86.55 %\n",
      "Epoch:93/100 \t Train Loss:0.1786 Valid Loss:0.4780 \t Train Acc:93.72 %  Valid Acc:86.46 %\n",
      "Epoch:94/100 \t Train Loss:0.1786 Valid Loss:0.4761 \t Train Acc:93.68 %  Valid Acc:86.56 %\n",
      "Epoch:95/100 \t Train Loss:0.1800 Valid Loss:0.4767 \t Train Acc:93.66 %  Valid Acc:86.50 %\n",
      "Epoch:96/100 \t Train Loss:0.1818 Valid Loss:0.4735 \t Train Acc:93.50 %  Valid Acc:86.56 %\n",
      "Epoch:97/100 \t Train Loss:0.1791 Valid Loss:0.4757 \t Train Acc:93.74 %  Valid Acc:86.54 %\n",
      "Epoch:98/100 \t Train Loss:0.1781 Valid Loss:0.4746 \t Train Acc:93.64 %  Valid Acc:86.53 %\n",
      "Epoch:99/100 \t Train Loss:0.1790 Valid Loss:0.4767 \t Train Acc:93.53 %  Valid Acc:86.57 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 17:26:35,242] Trial 3 finished with value: 86.50999999999999 and parameters: {'sigma_1': 4.581856856718059, 'sigma_2': 4.752382022153147, 'sigma_3': 2.539332952363392, 'sigma_4': 3.4473626527469503, 'sigma_5': 2.9704739698355835, 'sigma_6': 1.6973136363833932, 'sigma_7': 2.5462767031268982, 'sigma_8': 0.1376363777650112, 'sigma_9': 2.318275459848565, 'sigma_10': 2.582739742655172, 'sigma_11': 1.6376371158647485, 'sigma_12': 3.8674053233666585, 'sigma_13': 4.8793740113618425}. Best is trial 1 with value: 87.12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1783 Valid Loss:0.4766 \t Train Acc:93.56 %  Valid Acc:86.51 %\n",
      "Epoch:1/100 \t Train Loss:1.4919 Valid Loss:1.3779 \t Train Acc:44.76 %  Valid Acc:51.06 %\n",
      "Epoch:2/100 \t Train Loss:1.1767 Valid Loss:1.0358 \t Train Acc:57.70 %  Valid Acc:62.78 %\n",
      "Epoch:3/100 \t Train Loss:1.0530 Valid Loss:0.9537 \t Train Acc:62.11 %  Valid Acc:65.77 %\n",
      "Epoch:4/100 \t Train Loss:0.9456 Valid Loss:0.9554 \t Train Acc:66.46 %  Valid Acc:66.01 %\n",
      "Epoch:5/100 \t Train Loss:0.8718 Valid Loss:0.8284 \t Train Acc:69.23 %  Valid Acc:70.91 %\n",
      "Epoch:6/100 \t Train Loss:0.8107 Valid Loss:0.7945 \t Train Acc:71.24 %  Valid Acc:72.42 %\n",
      "Epoch:7/100 \t Train Loss:0.7498 Valid Loss:0.7311 \t Train Acc:73.82 %  Valid Acc:74.70 %\n",
      "Epoch:8/100 \t Train Loss:0.7117 Valid Loss:0.6824 \t Train Acc:75.13 %  Valid Acc:76.48 %\n",
      "Epoch:9/100 \t Train Loss:0.6740 Valid Loss:0.6908 \t Train Acc:76.56 %  Valid Acc:76.14 %\n",
      "Epoch:10/100 \t Train Loss:0.6385 Valid Loss:0.6524 \t Train Acc:77.67 %  Valid Acc:77.83 %\n",
      "Epoch:11/100 \t Train Loss:0.6112 Valid Loss:0.6414 \t Train Acc:78.50 %  Valid Acc:78.03 %\n",
      "Epoch:12/100 \t Train Loss:0.5878 Valid Loss:0.6525 \t Train Acc:79.46 %  Valid Acc:78.91 %\n",
      "Epoch:13/100 \t Train Loss:0.5658 Valid Loss:0.6611 \t Train Acc:80.40 %  Valid Acc:78.18 %\n",
      "Epoch:14/100 \t Train Loss:0.5462 Valid Loss:0.6418 \t Train Acc:81.01 %  Valid Acc:78.25 %\n",
      "Epoch:15/100 \t Train Loss:0.5272 Valid Loss:0.6098 \t Train Acc:81.61 %  Valid Acc:79.98 %\n",
      "Epoch:16/100 \t Train Loss:0.5091 Valid Loss:0.5411 \t Train Acc:82.19 %  Valid Acc:81.80 %\n",
      "Epoch:17/100 \t Train Loss:0.4979 Valid Loss:0.5587 \t Train Acc:82.59 %  Valid Acc:80.80 %\n",
      "Epoch:18/100 \t Train Loss:0.4842 Valid Loss:0.5401 \t Train Acc:83.14 %  Valid Acc:82.21 %\n",
      "Epoch:19/100 \t Train Loss:0.4692 Valid Loss:0.5601 \t Train Acc:83.58 %  Valid Acc:81.51 %\n",
      "Epoch:20/100 \t Train Loss:0.4594 Valid Loss:0.5408 \t Train Acc:84.09 %  Valid Acc:81.83 %\n",
      "Epoch:21/100 \t Train Loss:0.3760 Valid Loss:0.4802 \t Train Acc:86.90 %  Valid Acc:84.23 %\n",
      "Epoch:22/100 \t Train Loss:0.3634 Valid Loss:0.4624 \t Train Acc:87.28 %  Valid Acc:84.50 %\n",
      "Epoch:23/100 \t Train Loss:0.3467 Valid Loss:0.4809 \t Train Acc:88.02 %  Valid Acc:84.34 %\n",
      "Epoch:24/100 \t Train Loss:0.3449 Valid Loss:0.4623 \t Train Acc:87.84 %  Valid Acc:84.82 %\n",
      "Epoch:25/100 \t Train Loss:0.3361 Valid Loss:0.4623 \t Train Acc:88.31 %  Valid Acc:85.16 %\n",
      "Epoch:26/100 \t Train Loss:0.3315 Valid Loss:0.4680 \t Train Acc:88.27 %  Valid Acc:84.87 %\n",
      "Epoch:27/100 \t Train Loss:0.3254 Valid Loss:0.4768 \t Train Acc:88.68 %  Valid Acc:84.65 %\n",
      "Epoch:28/100 \t Train Loss:0.3197 Valid Loss:0.4608 \t Train Acc:88.76 %  Valid Acc:84.95 %\n",
      "Epoch:29/100 \t Train Loss:0.3166 Valid Loss:0.4766 \t Train Acc:88.78 %  Valid Acc:84.68 %\n",
      "Epoch:30/100 \t Train Loss:0.3117 Valid Loss:0.4530 \t Train Acc:89.06 %  Valid Acc:85.35 %\n",
      "Epoch:31/100 \t Train Loss:0.3082 Valid Loss:0.4472 \t Train Acc:89.10 %  Valid Acc:85.49 %\n",
      "Epoch:32/100 \t Train Loss:0.3040 Valid Loss:0.4618 \t Train Acc:89.18 %  Valid Acc:85.37 %\n",
      "Epoch:33/100 \t Train Loss:0.3019 Valid Loss:0.4509 \t Train Acc:89.43 %  Valid Acc:85.43 %\n",
      "Epoch:34/100 \t Train Loss:0.2973 Valid Loss:0.4703 \t Train Acc:89.61 %  Valid Acc:85.03 %\n",
      "Epoch:35/100 \t Train Loss:0.2914 Valid Loss:0.4607 \t Train Acc:89.70 %  Valid Acc:85.17 %\n",
      "Epoch:36/100 \t Train Loss:0.2914 Valid Loss:0.4578 \t Train Acc:89.73 %  Valid Acc:85.66 %\n",
      "Epoch:37/100 \t Train Loss:0.2889 Valid Loss:0.4623 \t Train Acc:89.84 %  Valid Acc:85.13 %\n",
      "Epoch:38/100 \t Train Loss:0.2838 Valid Loss:0.4514 \t Train Acc:89.84 %  Valid Acc:85.62 %\n",
      "Epoch:39/100 \t Train Loss:0.2793 Valid Loss:0.4788 \t Train Acc:90.14 %  Valid Acc:85.16 %\n",
      "Epoch:40/100 \t Train Loss:0.2754 Valid Loss:0.4595 \t Train Acc:90.30 %  Valid Acc:85.18 %\n",
      "Epoch:41/100 \t Train Loss:0.2445 Valid Loss:0.4570 \t Train Acc:91.39 %  Valid Acc:85.78 %\n",
      "Epoch:42/100 \t Train Loss:0.2386 Valid Loss:0.4528 \t Train Acc:91.60 %  Valid Acc:85.84 %\n",
      "Epoch:43/100 \t Train Loss:0.2358 Valid Loss:0.4475 \t Train Acc:91.70 %  Valid Acc:85.87 %\n",
      "Epoch:44/100 \t Train Loss:0.2353 Valid Loss:0.4472 \t Train Acc:91.68 %  Valid Acc:85.98 %\n",
      "Epoch:45/100 \t Train Loss:0.2326 Valid Loss:0.4546 \t Train Acc:91.85 %  Valid Acc:86.20 %\n",
      "Epoch:46/100 \t Train Loss:0.2280 Valid Loss:0.4657 \t Train Acc:92.00 %  Valid Acc:85.85 %\n",
      "Epoch:47/100 \t Train Loss:0.2307 Valid Loss:0.4581 \t Train Acc:91.84 %  Valid Acc:86.00 %\n",
      "Epoch:48/100 \t Train Loss:0.2283 Valid Loss:0.4598 \t Train Acc:91.81 %  Valid Acc:86.08 %\n",
      "Epoch:49/100 \t Train Loss:0.2246 Valid Loss:0.4504 \t Train Acc:92.05 %  Valid Acc:86.26 %\n",
      "Epoch:50/100 \t Train Loss:0.2257 Valid Loss:0.4624 \t Train Acc:92.09 %  Valid Acc:85.87 %\n",
      "Epoch:51/100 \t Train Loss:0.2201 Valid Loss:0.4585 \t Train Acc:92.26 %  Valid Acc:86.07 %\n",
      "Epoch:52/100 \t Train Loss:0.2236 Valid Loss:0.4654 \t Train Acc:92.11 %  Valid Acc:86.15 %\n",
      "Epoch:53/100 \t Train Loss:0.2210 Valid Loss:0.4644 \t Train Acc:92.15 %  Valid Acc:85.94 %\n",
      "Epoch:54/100 \t Train Loss:0.2188 Valid Loss:0.4631 \t Train Acc:92.24 %  Valid Acc:86.12 %\n",
      "Epoch:55/100 \t Train Loss:0.2149 Valid Loss:0.4652 \t Train Acc:92.37 %  Valid Acc:86.03 %\n",
      "Epoch:56/100 \t Train Loss:0.2174 Valid Loss:0.4693 \t Train Acc:92.24 %  Valid Acc:86.11 %\n",
      "Epoch:57/100 \t Train Loss:0.2144 Valid Loss:0.4628 \t Train Acc:92.28 %  Valid Acc:86.09 %\n",
      "Epoch:58/100 \t Train Loss:0.2144 Valid Loss:0.4637 \t Train Acc:92.35 %  Valid Acc:86.05 %\n",
      "Epoch:59/100 \t Train Loss:0.2125 Valid Loss:0.4621 \t Train Acc:92.33 %  Valid Acc:86.35 %\n",
      "Epoch:60/100 \t Train Loss:0.2089 Valid Loss:0.4652 \t Train Acc:92.69 %  Valid Acc:86.34 %\n",
      "Epoch:61/100 \t Train Loss:0.1990 Valid Loss:0.4650 \t Train Acc:92.94 %  Valid Acc:86.18 %\n",
      "Epoch:62/100 \t Train Loss:0.1973 Valid Loss:0.4656 \t Train Acc:93.00 %  Valid Acc:86.29 %\n",
      "Epoch:63/100 \t Train Loss:0.1970 Valid Loss:0.4601 \t Train Acc:93.11 %  Valid Acc:86.13 %\n",
      "Epoch:64/100 \t Train Loss:0.1963 Valid Loss:0.4640 \t Train Acc:93.06 %  Valid Acc:86.30 %\n",
      "Epoch:65/100 \t Train Loss:0.1921 Valid Loss:0.4670 \t Train Acc:93.21 %  Valid Acc:86.47 %\n",
      "Epoch:66/100 \t Train Loss:0.1923 Valid Loss:0.4649 \t Train Acc:93.22 %  Valid Acc:86.39 %\n",
      "Epoch:67/100 \t Train Loss:0.1936 Valid Loss:0.4663 \t Train Acc:93.14 %  Valid Acc:86.24 %\n",
      "Epoch:68/100 \t Train Loss:0.1954 Valid Loss:0.4693 \t Train Acc:93.13 %  Valid Acc:86.16 %\n",
      "Epoch:69/100 \t Train Loss:0.1913 Valid Loss:0.4670 \t Train Acc:93.27 %  Valid Acc:86.20 %\n",
      "Epoch:70/100 \t Train Loss:0.1934 Valid Loss:0.4668 \t Train Acc:93.08 %  Valid Acc:86.32 %\n",
      "Epoch:71/100 \t Train Loss:0.1935 Valid Loss:0.4652 \t Train Acc:92.99 %  Valid Acc:86.25 %\n",
      "Epoch:72/100 \t Train Loss:0.1907 Valid Loss:0.4692 \t Train Acc:93.25 %  Valid Acc:86.37 %\n",
      "Epoch:73/100 \t Train Loss:0.1891 Valid Loss:0.4702 \t Train Acc:93.24 %  Valid Acc:86.21 %\n",
      "Epoch:74/100 \t Train Loss:0.1871 Valid Loss:0.4710 \t Train Acc:93.28 %  Valid Acc:86.24 %\n",
      "Epoch:75/100 \t Train Loss:0.1897 Valid Loss:0.4703 \t Train Acc:93.36 %  Valid Acc:86.36 %\n",
      "Epoch:76/100 \t Train Loss:0.1897 Valid Loss:0.4695 \t Train Acc:93.14 %  Valid Acc:86.17 %\n",
      "Epoch:77/100 \t Train Loss:0.1906 Valid Loss:0.4709 \t Train Acc:93.16 %  Valid Acc:86.34 %\n",
      "Epoch:78/100 \t Train Loss:0.1880 Valid Loss:0.4654 \t Train Acc:93.31 %  Valid Acc:86.48 %\n",
      "Epoch:79/100 \t Train Loss:0.1852 Valid Loss:0.4704 \t Train Acc:93.46 %  Valid Acc:86.39 %\n",
      "Epoch:80/100 \t Train Loss:0.1878 Valid Loss:0.4731 \t Train Acc:93.27 %  Valid Acc:86.35 %\n",
      "Epoch:81/100 \t Train Loss:0.1839 Valid Loss:0.4699 \t Train Acc:93.46 %  Valid Acc:86.27 %\n",
      "Epoch:82/100 \t Train Loss:0.1847 Valid Loss:0.4685 \t Train Acc:93.39 %  Valid Acc:86.35 %\n",
      "Epoch:83/100 \t Train Loss:0.1799 Valid Loss:0.4714 \t Train Acc:93.63 %  Valid Acc:86.36 %\n",
      "Epoch:84/100 \t Train Loss:0.1803 Valid Loss:0.4721 \t Train Acc:93.64 %  Valid Acc:86.29 %\n",
      "Epoch:85/100 \t Train Loss:0.1834 Valid Loss:0.4729 \t Train Acc:93.47 %  Valid Acc:86.36 %\n",
      "Epoch:86/100 \t Train Loss:0.1824 Valid Loss:0.4725 \t Train Acc:93.46 %  Valid Acc:86.45 %\n",
      "Epoch:87/100 \t Train Loss:0.1801 Valid Loss:0.4702 \t Train Acc:93.67 %  Valid Acc:86.48 %\n",
      "Epoch:88/100 \t Train Loss:0.1793 Valid Loss:0.4710 \t Train Acc:93.51 %  Valid Acc:86.37 %\n",
      "Epoch:89/100 \t Train Loss:0.1846 Valid Loss:0.4689 \t Train Acc:93.40 %  Valid Acc:86.60 %\n",
      "Epoch:90/100 \t Train Loss:0.1809 Valid Loss:0.4715 \t Train Acc:93.54 %  Valid Acc:86.33 %\n",
      "Epoch:91/100 \t Train Loss:0.1851 Valid Loss:0.4692 \t Train Acc:93.31 %  Valid Acc:86.38 %\n",
      "Epoch:92/100 \t Train Loss:0.1812 Valid Loss:0.4693 \t Train Acc:93.53 %  Valid Acc:86.37 %\n",
      "Epoch:93/100 \t Train Loss:0.1819 Valid Loss:0.4720 \t Train Acc:93.58 %  Valid Acc:86.39 %\n",
      "Epoch:94/100 \t Train Loss:0.1797 Valid Loss:0.4716 \t Train Acc:93.53 %  Valid Acc:86.41 %\n",
      "Epoch:95/100 \t Train Loss:0.1814 Valid Loss:0.4723 \t Train Acc:93.67 %  Valid Acc:86.41 %\n",
      "Epoch:96/100 \t Train Loss:0.1776 Valid Loss:0.4723 \t Train Acc:93.77 %  Valid Acc:86.43 %\n",
      "Epoch:97/100 \t Train Loss:0.1777 Valid Loss:0.4722 \t Train Acc:93.71 %  Valid Acc:86.39 %\n",
      "Epoch:98/100 \t Train Loss:0.1786 Valid Loss:0.4740 \t Train Acc:93.64 %  Valid Acc:86.34 %\n",
      "Epoch:99/100 \t Train Loss:0.1804 Valid Loss:0.4752 \t Train Acc:93.67 %  Valid Acc:86.32 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 18:48:05,789] Trial 4 finished with value: 86.39 and parameters: {'sigma_1': 1.7847775057687831, 'sigma_2': 0.31839888559000784, 'sigma_3': 1.9223263120048808, 'sigma_4': 4.889108897639944, 'sigma_5': 3.5689985210236634, 'sigma_6': 4.313771486775137, 'sigma_7': 4.251414460118188, 'sigma_8': 1.6076099193326965, 'sigma_9': 2.621461654721011, 'sigma_10': 0.24318243553628094, 'sigma_11': 2.3106276814327327, 'sigma_12': 4.459998132076116, 'sigma_13': 3.986516066245128}. Best is trial 1 with value: 87.12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1799 Valid Loss:0.4744 \t Train Acc:93.61 %  Valid Acc:86.39 %\n",
      "Epoch:1/100 \t Train Loss:1.5357 Valid Loss:1.4812 \t Train Acc:43.07 %  Valid Acc:48.42 %\n",
      "Epoch:2/100 \t Train Loss:1.1695 Valid Loss:1.2110 \t Train Acc:57.93 %  Valid Acc:58.60 %\n",
      "Epoch:3/100 \t Train Loss:1.0077 Valid Loss:0.9557 \t Train Acc:63.68 %  Valid Acc:66.57 %\n",
      "Epoch:4/100 \t Train Loss:0.9129 Valid Loss:0.9369 \t Train Acc:67.47 %  Valid Acc:66.99 %\n",
      "Epoch:5/100 \t Train Loss:0.8397 Valid Loss:0.8348 \t Train Acc:70.16 %  Valid Acc:71.46 %\n",
      "Epoch:6/100 \t Train Loss:0.7676 Valid Loss:0.8174 \t Train Acc:73.01 %  Valid Acc:71.91 %\n",
      "Epoch:7/100 \t Train Loss:0.7040 Valid Loss:0.7009 \t Train Acc:75.17 %  Valid Acc:75.94 %\n",
      "Epoch:8/100 \t Train Loss:0.6556 Valid Loss:0.7042 \t Train Acc:77.32 %  Valid Acc:76.30 %\n",
      "Epoch:9/100 \t Train Loss:0.6159 Valid Loss:0.6049 \t Train Acc:78.51 %  Valid Acc:79.41 %\n",
      "Epoch:10/100 \t Train Loss:0.5881 Valid Loss:0.6416 \t Train Acc:79.67 %  Valid Acc:78.34 %\n",
      "Epoch:11/100 \t Train Loss:0.5549 Valid Loss:0.6058 \t Train Acc:80.81 %  Valid Acc:79.78 %\n",
      "Epoch:12/100 \t Train Loss:0.5289 Valid Loss:0.5856 \t Train Acc:81.76 %  Valid Acc:80.11 %\n",
      "Epoch:13/100 \t Train Loss:0.5091 Valid Loss:0.5613 \t Train Acc:82.53 %  Valid Acc:81.26 %\n",
      "Epoch:14/100 \t Train Loss:0.4917 Valid Loss:0.5701 \t Train Acc:83.10 %  Valid Acc:80.87 %\n",
      "Epoch:15/100 \t Train Loss:0.4827 Valid Loss:0.5184 \t Train Acc:83.40 %  Valid Acc:82.70 %\n",
      "Epoch:16/100 \t Train Loss:0.4639 Valid Loss:0.5433 \t Train Acc:83.91 %  Valid Acc:81.18 %\n",
      "Epoch:17/100 \t Train Loss:0.4480 Valid Loss:0.5107 \t Train Acc:84.30 %  Valid Acc:82.87 %\n",
      "Epoch:18/100 \t Train Loss:0.4382 Valid Loss:0.4991 \t Train Acc:84.74 %  Valid Acc:83.33 %\n",
      "Epoch:19/100 \t Train Loss:0.4277 Valid Loss:0.5271 \t Train Acc:85.05 %  Valid Acc:82.60 %\n",
      "Epoch:20/100 \t Train Loss:0.4147 Valid Loss:0.5073 \t Train Acc:85.55 %  Valid Acc:83.58 %\n",
      "Epoch:21/100 \t Train Loss:0.3337 Valid Loss:0.4443 \t Train Acc:88.41 %  Valid Acc:85.36 %\n",
      "Epoch:22/100 \t Train Loss:0.3167 Valid Loss:0.4380 \t Train Acc:89.05 %  Valid Acc:85.25 %\n",
      "Epoch:23/100 \t Train Loss:0.3096 Valid Loss:0.4416 \t Train Acc:89.13 %  Valid Acc:85.86 %\n",
      "Epoch:24/100 \t Train Loss:0.3037 Valid Loss:0.4220 \t Train Acc:89.35 %  Valid Acc:86.42 %\n",
      "Epoch:25/100 \t Train Loss:0.2953 Valid Loss:0.4425 \t Train Acc:89.62 %  Valid Acc:86.27 %\n",
      "Epoch:26/100 \t Train Loss:0.2920 Valid Loss:0.4241 \t Train Acc:89.83 %  Valid Acc:85.89 %\n",
      "Epoch:27/100 \t Train Loss:0.2862 Valid Loss:0.4340 \t Train Acc:89.94 %  Valid Acc:85.93 %\n",
      "Epoch:28/100 \t Train Loss:0.2806 Valid Loss:0.4223 \t Train Acc:90.11 %  Valid Acc:86.39 %\n",
      "Epoch:29/100 \t Train Loss:0.2797 Valid Loss:0.4331 \t Train Acc:90.23 %  Valid Acc:86.28 %\n",
      "Epoch:30/100 \t Train Loss:0.2697 Valid Loss:0.4322 \t Train Acc:90.57 %  Valid Acc:86.24 %\n",
      "Epoch:31/100 \t Train Loss:0.2684 Valid Loss:0.4255 \t Train Acc:90.44 %  Valid Acc:86.34 %\n",
      "Epoch:32/100 \t Train Loss:0.2662 Valid Loss:0.4454 \t Train Acc:90.61 %  Valid Acc:85.93 %\n",
      "Epoch:33/100 \t Train Loss:0.2622 Valid Loss:0.4315 \t Train Acc:90.66 %  Valid Acc:85.88 %\n",
      "Epoch:34/100 \t Train Loss:0.2598 Valid Loss:0.4308 \t Train Acc:90.90 %  Valid Acc:86.12 %\n",
      "Epoch:35/100 \t Train Loss:0.2522 Valid Loss:0.4360 \t Train Acc:91.07 %  Valid Acc:86.25 %\n",
      "Epoch:36/100 \t Train Loss:0.2511 Valid Loss:0.4392 \t Train Acc:91.15 %  Valid Acc:86.39 %\n",
      "Epoch:37/100 \t Train Loss:0.2497 Valid Loss:0.4256 \t Train Acc:91.28 %  Valid Acc:86.54 %\n",
      "Epoch:38/100 \t Train Loss:0.2486 Valid Loss:0.4470 \t Train Acc:91.27 %  Valid Acc:85.98 %\n",
      "Epoch:39/100 \t Train Loss:0.2421 Valid Loss:0.4390 \t Train Acc:91.50 %  Valid Acc:86.48 %\n",
      "Epoch:40/100 \t Train Loss:0.2394 Valid Loss:0.4459 \t Train Acc:91.48 %  Valid Acc:86.50 %\n",
      "Epoch:41/100 \t Train Loss:0.2098 Valid Loss:0.4275 \t Train Acc:92.67 %  Valid Acc:87.07 %\n",
      "Epoch:42/100 \t Train Loss:0.2041 Valid Loss:0.4348 \t Train Acc:92.73 %  Valid Acc:86.88 %\n",
      "Epoch:43/100 \t Train Loss:0.1997 Valid Loss:0.4256 \t Train Acc:92.88 %  Valid Acc:87.26 %\n",
      "Epoch:44/100 \t Train Loss:0.1988 Valid Loss:0.4293 \t Train Acc:93.00 %  Valid Acc:87.27 %\n",
      "Epoch:45/100 \t Train Loss:0.1963 Valid Loss:0.4252 \t Train Acc:93.10 %  Valid Acc:87.19 %\n",
      "Epoch:46/100 \t Train Loss:0.1964 Valid Loss:0.4341 \t Train Acc:93.10 %  Valid Acc:87.00 %\n",
      "Epoch:47/100 \t Train Loss:0.1956 Valid Loss:0.4298 \t Train Acc:93.09 %  Valid Acc:87.01 %\n",
      "Epoch:48/100 \t Train Loss:0.1932 Valid Loss:0.4361 \t Train Acc:93.13 %  Valid Acc:87.19 %\n",
      "Epoch:49/100 \t Train Loss:0.1914 Valid Loss:0.4310 \t Train Acc:93.18 %  Valid Acc:87.50 %\n",
      "Epoch:50/100 \t Train Loss:0.1879 Valid Loss:0.4391 \t Train Acc:93.29 %  Valid Acc:87.35 %\n",
      "Epoch:51/100 \t Train Loss:0.1886 Valid Loss:0.4435 \t Train Acc:93.38 %  Valid Acc:87.15 %\n",
      "Epoch:52/100 \t Train Loss:0.1848 Valid Loss:0.4429 \t Train Acc:93.43 %  Valid Acc:87.03 %\n",
      "Epoch:53/100 \t Train Loss:0.1833 Valid Loss:0.4465 \t Train Acc:93.42 %  Valid Acc:87.38 %\n",
      "Epoch:54/100 \t Train Loss:0.1816 Valid Loss:0.4380 \t Train Acc:93.57 %  Valid Acc:87.10 %\n",
      "Epoch:55/100 \t Train Loss:0.1818 Valid Loss:0.4447 \t Train Acc:93.50 %  Valid Acc:87.14 %\n",
      "Epoch:56/100 \t Train Loss:0.1772 Valid Loss:0.4484 \t Train Acc:93.63 %  Valid Acc:87.18 %\n",
      "Epoch:57/100 \t Train Loss:0.1791 Valid Loss:0.4408 \t Train Acc:93.70 %  Valid Acc:87.42 %\n",
      "Epoch:58/100 \t Train Loss:0.1809 Valid Loss:0.4402 \t Train Acc:93.56 %  Valid Acc:87.35 %\n",
      "Epoch:59/100 \t Train Loss:0.1805 Valid Loss:0.4456 \t Train Acc:93.55 %  Valid Acc:87.35 %\n",
      "Epoch:60/100 \t Train Loss:0.1778 Valid Loss:0.4481 \t Train Acc:93.69 %  Valid Acc:87.15 %\n",
      "Epoch:61/100 \t Train Loss:0.1631 Valid Loss:0.4425 \t Train Acc:94.22 %  Valid Acc:87.22 %\n",
      "Epoch:62/100 \t Train Loss:0.1618 Valid Loss:0.4444 \t Train Acc:94.21 %  Valid Acc:87.33 %\n",
      "Epoch:63/100 \t Train Loss:0.1603 Valid Loss:0.4438 \t Train Acc:94.31 %  Valid Acc:87.46 %\n",
      "Epoch:64/100 \t Train Loss:0.1623 Valid Loss:0.4381 \t Train Acc:94.30 %  Valid Acc:87.55 %\n",
      "Epoch:65/100 \t Train Loss:0.1617 Valid Loss:0.4455 \t Train Acc:94.34 %  Valid Acc:87.46 %\n",
      "Epoch:66/100 \t Train Loss:0.1584 Valid Loss:0.4528 \t Train Acc:94.39 %  Valid Acc:87.33 %\n",
      "Epoch:67/100 \t Train Loss:0.1613 Valid Loss:0.4467 \t Train Acc:94.26 %  Valid Acc:87.51 %\n",
      "Epoch:68/100 \t Train Loss:0.1593 Valid Loss:0.4484 \t Train Acc:94.31 %  Valid Acc:87.53 %\n",
      "Epoch:69/100 \t Train Loss:0.1588 Valid Loss:0.4485 \t Train Acc:94.42 %  Valid Acc:87.43 %\n",
      "Epoch:70/100 \t Train Loss:0.1598 Valid Loss:0.4462 \t Train Acc:94.33 %  Valid Acc:87.52 %\n",
      "Epoch:71/100 \t Train Loss:0.1559 Valid Loss:0.4502 \t Train Acc:94.40 %  Valid Acc:87.36 %\n",
      "Epoch:72/100 \t Train Loss:0.1563 Valid Loss:0.4522 \t Train Acc:94.49 %  Valid Acc:87.28 %\n",
      "Epoch:73/100 \t Train Loss:0.1591 Valid Loss:0.4474 \t Train Acc:94.27 %  Valid Acc:87.50 %\n",
      "Epoch:74/100 \t Train Loss:0.1566 Valid Loss:0.4540 \t Train Acc:94.39 %  Valid Acc:87.37 %\n",
      "Epoch:75/100 \t Train Loss:0.1563 Valid Loss:0.4563 \t Train Acc:94.50 %  Valid Acc:87.43 %\n",
      "Epoch:76/100 \t Train Loss:0.1579 Valid Loss:0.4524 \t Train Acc:94.30 %  Valid Acc:87.34 %\n",
      "Epoch:77/100 \t Train Loss:0.1537 Valid Loss:0.4572 \t Train Acc:94.56 %  Valid Acc:87.45 %\n",
      "Epoch:78/100 \t Train Loss:0.1566 Valid Loss:0.4651 \t Train Acc:94.53 %  Valid Acc:87.15 %\n",
      "Epoch:79/100 \t Train Loss:0.1535 Valid Loss:0.4592 \t Train Acc:94.56 %  Valid Acc:87.45 %\n",
      "Epoch:80/100 \t Train Loss:0.1553 Valid Loss:0.4614 \t Train Acc:94.37 %  Valid Acc:87.16 %\n",
      "Epoch:81/100 \t Train Loss:0.1501 Valid Loss:0.4586 \t Train Acc:94.75 %  Valid Acc:87.34 %\n",
      "Epoch:82/100 \t Train Loss:0.1490 Valid Loss:0.4592 \t Train Acc:94.71 %  Valid Acc:87.29 %\n",
      "Epoch:83/100 \t Train Loss:0.1491 Valid Loss:0.4602 \t Train Acc:94.66 %  Valid Acc:87.32 %\n",
      "Epoch:84/100 \t Train Loss:0.1510 Valid Loss:0.4594 \t Train Acc:94.68 %  Valid Acc:87.42 %\n",
      "Epoch:85/100 \t Train Loss:0.1499 Valid Loss:0.4576 \t Train Acc:94.68 %  Valid Acc:87.56 %\n",
      "Epoch:86/100 \t Train Loss:0.1510 Valid Loss:0.4600 \t Train Acc:94.56 %  Valid Acc:87.32 %\n",
      "Epoch:87/100 \t Train Loss:0.1498 Valid Loss:0.4612 \t Train Acc:94.68 %  Valid Acc:87.32 %\n",
      "Epoch:88/100 \t Train Loss:0.1498 Valid Loss:0.4608 \t Train Acc:94.65 %  Valid Acc:87.34 %\n",
      "Epoch:89/100 \t Train Loss:0.1500 Valid Loss:0.4630 \t Train Acc:94.65 %  Valid Acc:87.36 %\n",
      "Epoch:90/100 \t Train Loss:0.1483 Valid Loss:0.4625 \t Train Acc:94.71 %  Valid Acc:87.43 %\n",
      "Epoch:91/100 \t Train Loss:0.1477 Valid Loss:0.4608 \t Train Acc:94.69 %  Valid Acc:87.47 %\n",
      "Epoch:92/100 \t Train Loss:0.1481 Valid Loss:0.4600 \t Train Acc:94.67 %  Valid Acc:87.41 %\n",
      "Epoch:93/100 \t Train Loss:0.1488 Valid Loss:0.4592 \t Train Acc:94.74 %  Valid Acc:87.39 %\n",
      "Epoch:94/100 \t Train Loss:0.1495 Valid Loss:0.4616 \t Train Acc:94.68 %  Valid Acc:87.48 %\n",
      "Epoch:95/100 \t Train Loss:0.1459 Valid Loss:0.4628 \t Train Acc:94.81 %  Valid Acc:87.35 %\n",
      "Epoch:96/100 \t Train Loss:0.1477 Valid Loss:0.4660 \t Train Acc:94.70 %  Valid Acc:87.29 %\n",
      "Epoch:97/100 \t Train Loss:0.1455 Valid Loss:0.4623 \t Train Acc:94.91 %  Valid Acc:87.48 %\n",
      "Epoch:98/100 \t Train Loss:0.1479 Valid Loss:0.4641 \t Train Acc:94.71 %  Valid Acc:87.28 %\n",
      "Epoch:99/100 \t Train Loss:0.1449 Valid Loss:0.4592 \t Train Acc:94.86 %  Valid Acc:87.54 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 20:08:57,398] Trial 5 finished with value: 87.35000000000001 and parameters: {'sigma_1': 0.8891341644285307, 'sigma_2': 1.280474010311344, 'sigma_3': 4.694478666906056, 'sigma_4': 0.9017762785392068, 'sigma_5': 3.334382957924633, 'sigma_6': 4.487507589459152, 'sigma_7': 2.014190519215793, 'sigma_8': 4.479474791880304, 'sigma_9': 2.1678025593557586, 'sigma_10': 1.7809911547985093, 'sigma_11': 4.1170922048362275, 'sigma_12': 2.2172734233864566, 'sigma_13': 0.1902320583825528}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1477 Valid Loss:0.4612 \t Train Acc:94.79 %  Valid Acc:87.35 %\n",
      "Epoch:1/100 \t Train Loss:1.4196 Valid Loss:1.2360 \t Train Acc:47.81 %  Valid Acc:54.79 %\n",
      "Epoch:2/100 \t Train Loss:1.1171 Valid Loss:1.0064 \t Train Acc:59.73 %  Valid Acc:64.45 %\n",
      "Epoch:3/100 \t Train Loss:0.9824 Valid Loss:0.9376 \t Train Acc:64.57 %  Valid Acc:66.11 %\n",
      "Epoch:4/100 \t Train Loss:0.8895 Valid Loss:0.9350 \t Train Acc:68.23 %  Valid Acc:67.08 %\n",
      "Epoch:5/100 \t Train Loss:0.8158 Valid Loss:0.7674 \t Train Acc:71.30 %  Valid Acc:73.05 %\n",
      "Epoch:6/100 \t Train Loss:0.7544 Valid Loss:0.7609 \t Train Acc:73.41 %  Valid Acc:74.59 %\n",
      "Epoch:7/100 \t Train Loss:0.7086 Valid Loss:0.6964 \t Train Acc:75.16 %  Valid Acc:76.15 %\n",
      "Epoch:8/100 \t Train Loss:0.6702 Valid Loss:0.6386 \t Train Acc:76.68 %  Valid Acc:78.28 %\n",
      "Epoch:9/100 \t Train Loss:0.6347 Valid Loss:0.6106 \t Train Acc:77.85 %  Valid Acc:79.31 %\n",
      "Epoch:10/100 \t Train Loss:0.6119 Valid Loss:0.6382 \t Train Acc:78.82 %  Valid Acc:78.77 %\n",
      "Epoch:11/100 \t Train Loss:0.5793 Valid Loss:0.6179 \t Train Acc:79.84 %  Valid Acc:79.25 %\n",
      "Epoch:12/100 \t Train Loss:0.5610 Valid Loss:0.6205 \t Train Acc:80.62 %  Valid Acc:79.37 %\n",
      "Epoch:13/100 \t Train Loss:0.5412 Valid Loss:0.6161 \t Train Acc:81.39 %  Valid Acc:79.06 %\n",
      "Epoch:14/100 \t Train Loss:0.5213 Valid Loss:0.5664 \t Train Acc:81.86 %  Valid Acc:81.04 %\n",
      "Epoch:15/100 \t Train Loss:0.5068 Valid Loss:0.5652 \t Train Acc:82.46 %  Valid Acc:81.15 %\n",
      "Epoch:16/100 \t Train Loss:0.4915 Valid Loss:0.5400 \t Train Acc:83.05 %  Valid Acc:82.13 %\n",
      "Epoch:17/100 \t Train Loss:0.4775 Valid Loss:0.5455 \t Train Acc:83.52 %  Valid Acc:82.20 %\n",
      "Epoch:18/100 \t Train Loss:0.4601 Valid Loss:0.5254 \t Train Acc:84.04 %  Valid Acc:81.98 %\n",
      "Epoch:19/100 \t Train Loss:0.4473 Valid Loss:0.4891 \t Train Acc:84.57 %  Valid Acc:83.81 %\n",
      "Epoch:20/100 \t Train Loss:0.4340 Valid Loss:0.5278 \t Train Acc:84.97 %  Valid Acc:82.98 %\n",
      "Epoch:21/100 \t Train Loss:0.3612 Valid Loss:0.4533 \t Train Acc:87.44 %  Valid Acc:85.00 %\n",
      "Epoch:22/100 \t Train Loss:0.3464 Valid Loss:0.4587 \t Train Acc:87.90 %  Valid Acc:85.05 %\n",
      "Epoch:23/100 \t Train Loss:0.3361 Valid Loss:0.4570 \t Train Acc:88.14 %  Valid Acc:85.17 %\n",
      "Epoch:24/100 \t Train Loss:0.3281 Valid Loss:0.4490 \t Train Acc:88.47 %  Valid Acc:85.28 %\n",
      "Epoch:25/100 \t Train Loss:0.3211 Valid Loss:0.4523 \t Train Acc:88.75 %  Valid Acc:85.40 %\n",
      "Epoch:26/100 \t Train Loss:0.3185 Valid Loss:0.4752 \t Train Acc:89.08 %  Valid Acc:84.95 %\n",
      "Epoch:27/100 \t Train Loss:0.3105 Valid Loss:0.4571 \t Train Acc:89.16 %  Valid Acc:85.48 %\n",
      "Epoch:28/100 \t Train Loss:0.3059 Valid Loss:0.4728 \t Train Acc:89.18 %  Valid Acc:84.99 %\n",
      "Epoch:29/100 \t Train Loss:0.3030 Valid Loss:0.4592 \t Train Acc:89.46 %  Valid Acc:85.41 %\n",
      "Epoch:30/100 \t Train Loss:0.2968 Valid Loss:0.4534 \t Train Acc:89.58 %  Valid Acc:85.35 %\n",
      "Epoch:31/100 \t Train Loss:0.2888 Valid Loss:0.4630 \t Train Acc:89.83 %  Valid Acc:85.75 %\n",
      "Epoch:32/100 \t Train Loss:0.2939 Valid Loss:0.4430 \t Train Acc:89.69 %  Valid Acc:85.75 %\n",
      "Epoch:33/100 \t Train Loss:0.2901 Valid Loss:0.4453 \t Train Acc:89.62 %  Valid Acc:85.55 %\n",
      "Epoch:34/100 \t Train Loss:0.2818 Valid Loss:0.4608 \t Train Acc:90.02 %  Valid Acc:85.33 %\n",
      "Epoch:35/100 \t Train Loss:0.2804 Valid Loss:0.4606 \t Train Acc:90.15 %  Valid Acc:85.43 %\n",
      "Epoch:36/100 \t Train Loss:0.2702 Valid Loss:0.4437 \t Train Acc:90.40 %  Valid Acc:86.17 %\n",
      "Epoch:37/100 \t Train Loss:0.2734 Valid Loss:0.4408 \t Train Acc:90.42 %  Valid Acc:85.85 %\n",
      "Epoch:38/100 \t Train Loss:0.2714 Valid Loss:0.4670 \t Train Acc:90.49 %  Valid Acc:85.45 %\n",
      "Epoch:39/100 \t Train Loss:0.2659 Valid Loss:0.4609 \t Train Acc:90.58 %  Valid Acc:85.71 %\n",
      "Epoch:40/100 \t Train Loss:0.2627 Valid Loss:0.4727 \t Train Acc:90.79 %  Valid Acc:85.23 %\n",
      "Epoch:41/100 \t Train Loss:0.2336 Valid Loss:0.4496 \t Train Acc:91.68 %  Valid Acc:86.04 %\n",
      "Epoch:42/100 \t Train Loss:0.2256 Valid Loss:0.4506 \t Train Acc:91.99 %  Valid Acc:86.30 %\n",
      "Epoch:43/100 \t Train Loss:0.2235 Valid Loss:0.4401 \t Train Acc:91.98 %  Valid Acc:86.49 %\n",
      "Epoch:44/100 \t Train Loss:0.2228 Valid Loss:0.4463 \t Train Acc:92.10 %  Valid Acc:86.42 %\n",
      "Epoch:45/100 \t Train Loss:0.2181 Valid Loss:0.4509 \t Train Acc:92.39 %  Valid Acc:86.31 %\n",
      "Epoch:46/100 \t Train Loss:0.2176 Valid Loss:0.4547 \t Train Acc:92.41 %  Valid Acc:86.36 %\n",
      "Epoch:47/100 \t Train Loss:0.2160 Valid Loss:0.4537 \t Train Acc:92.40 %  Valid Acc:86.20 %\n",
      "Epoch:48/100 \t Train Loss:0.2151 Valid Loss:0.4521 \t Train Acc:92.34 %  Valid Acc:86.39 %\n",
      "Epoch:49/100 \t Train Loss:0.2128 Valid Loss:0.4534 \t Train Acc:92.43 %  Valid Acc:86.36 %\n",
      "Epoch:50/100 \t Train Loss:0.2087 Valid Loss:0.4571 \t Train Acc:92.69 %  Valid Acc:86.01 %\n",
      "Epoch:51/100 \t Train Loss:0.2069 Valid Loss:0.4612 \t Train Acc:92.70 %  Valid Acc:86.44 %\n",
      "Epoch:52/100 \t Train Loss:0.2093 Valid Loss:0.4632 \t Train Acc:92.59 %  Valid Acc:86.37 %\n",
      "Epoch:53/100 \t Train Loss:0.2078 Valid Loss:0.4626 \t Train Acc:92.45 %  Valid Acc:86.41 %\n",
      "Epoch:54/100 \t Train Loss:0.2052 Valid Loss:0.4519 \t Train Acc:92.65 %  Valid Acc:86.56 %\n",
      "Epoch:55/100 \t Train Loss:0.2055 Valid Loss:0.4603 \t Train Acc:92.69 %  Valid Acc:86.40 %\n",
      "Epoch:56/100 \t Train Loss:0.2033 Valid Loss:0.4582 \t Train Acc:92.67 %  Valid Acc:86.36 %\n",
      "Epoch:57/100 \t Train Loss:0.2011 Valid Loss:0.4643 \t Train Acc:92.90 %  Valid Acc:86.50 %\n",
      "Epoch:58/100 \t Train Loss:0.2015 Valid Loss:0.4568 \t Train Acc:92.89 %  Valid Acc:86.29 %\n",
      "Epoch:59/100 \t Train Loss:0.1997 Valid Loss:0.4629 \t Train Acc:92.98 %  Valid Acc:86.71 %\n",
      "Epoch:60/100 \t Train Loss:0.1959 Valid Loss:0.4547 \t Train Acc:93.06 %  Valid Acc:86.42 %\n",
      "Epoch:61/100 \t Train Loss:0.1882 Valid Loss:0.4618 \t Train Acc:93.33 %  Valid Acc:86.40 %\n",
      "Epoch:62/100 \t Train Loss:0.1855 Valid Loss:0.4610 \t Train Acc:93.44 %  Valid Acc:86.73 %\n",
      "Epoch:63/100 \t Train Loss:0.1812 Valid Loss:0.4649 \t Train Acc:93.52 %  Valid Acc:86.74 %\n",
      "Epoch:64/100 \t Train Loss:0.1842 Valid Loss:0.4619 \t Train Acc:93.56 %  Valid Acc:86.74 %\n",
      "Epoch:65/100 \t Train Loss:0.1855 Valid Loss:0.4629 \t Train Acc:93.38 %  Valid Acc:86.67 %\n",
      "Epoch:66/100 \t Train Loss:0.1805 Valid Loss:0.4675 \t Train Acc:93.59 %  Valid Acc:86.71 %\n",
      "Epoch:67/100 \t Train Loss:0.1827 Valid Loss:0.4603 \t Train Acc:93.48 %  Valid Acc:86.72 %\n",
      "Epoch:68/100 \t Train Loss:0.1815 Valid Loss:0.4668 \t Train Acc:93.53 %  Valid Acc:86.69 %\n",
      "Epoch:69/100 \t Train Loss:0.1819 Valid Loss:0.4677 \t Train Acc:93.65 %  Valid Acc:86.74 %\n",
      "Epoch:70/100 \t Train Loss:0.1802 Valid Loss:0.4673 \t Train Acc:93.52 %  Valid Acc:86.77 %\n",
      "Epoch:71/100 \t Train Loss:0.1803 Valid Loss:0.4627 \t Train Acc:93.67 %  Valid Acc:86.81 %\n",
      "Epoch:72/100 \t Train Loss:0.1822 Valid Loss:0.4610 \t Train Acc:93.42 %  Valid Acc:86.64 %\n",
      "Epoch:73/100 \t Train Loss:0.1764 Valid Loss:0.4681 \t Train Acc:93.61 %  Valid Acc:86.50 %\n",
      "Epoch:74/100 \t Train Loss:0.1777 Valid Loss:0.4661 \t Train Acc:93.56 %  Valid Acc:86.77 %\n",
      "Epoch:75/100 \t Train Loss:0.1752 Valid Loss:0.4659 \t Train Acc:93.78 %  Valid Acc:86.83 %\n",
      "Epoch:76/100 \t Train Loss:0.1782 Valid Loss:0.4698 \t Train Acc:93.73 %  Valid Acc:86.58 %\n",
      "Epoch:77/100 \t Train Loss:0.1760 Valid Loss:0.4710 \t Train Acc:93.81 %  Valid Acc:86.56 %\n",
      "Epoch:78/100 \t Train Loss:0.1763 Valid Loss:0.4739 \t Train Acc:93.74 %  Valid Acc:86.48 %\n",
      "Epoch:79/100 \t Train Loss:0.1750 Valid Loss:0.4700 \t Train Acc:93.73 %  Valid Acc:86.62 %\n",
      "Epoch:80/100 \t Train Loss:0.1751 Valid Loss:0.4727 \t Train Acc:93.79 %  Valid Acc:86.60 %\n",
      "Epoch:81/100 \t Train Loss:0.1729 Valid Loss:0.4716 \t Train Acc:93.87 %  Valid Acc:86.67 %\n",
      "Epoch:82/100 \t Train Loss:0.1717 Valid Loss:0.4709 \t Train Acc:93.83 %  Valid Acc:86.72 %\n",
      "Epoch:83/100 \t Train Loss:0.1721 Valid Loss:0.4721 \t Train Acc:93.84 %  Valid Acc:86.63 %\n",
      "Epoch:84/100 \t Train Loss:0.1714 Valid Loss:0.4696 \t Train Acc:93.86 %  Valid Acc:86.70 %\n",
      "Epoch:85/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:56.61 %  Valid Acc:10.00 %\n",
      "Epoch:86/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:87/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:88/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:89/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:90/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:91/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:92/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:93/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:94/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:95/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:96/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:97/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:98/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:99/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 21:29:02,748] Trial 6 finished with value: 10.0 and parameters: {'sigma_1': 3.7518045989486786, 'sigma_2': 1.2409438795455021, 'sigma_3': 3.8224729043884444, 'sigma_4': 3.9279838680443833, 'sigma_5': 1.0812486500594363, 'sigma_6': 1.1744680308891733, 'sigma_7': 0.8708390818539142, 'sigma_8': 0.10075923489935311, 'sigma_9': 2.008550275021666, 'sigma_10': 4.36453228559648, 'sigma_11': 0.6035148361387805, 'sigma_12': 3.392306949088642, 'sigma_13': 4.073060639522797}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:nan Valid Loss:nan \t Train Acc:10.00 %  Valid Acc:10.00 %\n",
      "Epoch:1/100 \t Train Loss:1.5082 Valid Loss:1.6646 \t Train Acc:44.11 %  Valid Acc:42.43 %\n",
      "Epoch:2/100 \t Train Loss:1.1679 Valid Loss:1.0595 \t Train Acc:57.95 %  Valid Acc:61.69 %\n",
      "Epoch:3/100 \t Train Loss:1.0165 Valid Loss:0.9758 \t Train Acc:63.72 %  Valid Acc:66.16 %\n",
      "Epoch:4/100 \t Train Loss:0.9070 Valid Loss:0.9054 \t Train Acc:67.76 %  Valid Acc:68.14 %\n",
      "Epoch:5/100 \t Train Loss:0.8231 Valid Loss:0.7851 \t Train Acc:70.89 %  Valid Acc:72.29 %\n",
      "Epoch:6/100 \t Train Loss:0.7540 Valid Loss:0.7053 \t Train Acc:73.61 %  Valid Acc:75.64 %\n",
      "Epoch:7/100 \t Train Loss:0.6899 Valid Loss:0.6868 \t Train Acc:75.80 %  Valid Acc:76.41 %\n",
      "Epoch:8/100 \t Train Loss:0.6482 Valid Loss:0.6274 \t Train Acc:77.23 %  Valid Acc:78.47 %\n",
      "Epoch:9/100 \t Train Loss:0.6093 Valid Loss:0.6403 \t Train Acc:78.73 %  Valid Acc:78.42 %\n",
      "Epoch:10/100 \t Train Loss:0.5783 Valid Loss:0.6721 \t Train Acc:79.78 %  Valid Acc:77.78 %\n",
      "Epoch:11/100 \t Train Loss:0.5549 Valid Loss:0.5760 \t Train Acc:80.70 %  Valid Acc:80.30 %\n",
      "Epoch:12/100 \t Train Loss:0.5333 Valid Loss:0.6302 \t Train Acc:81.52 %  Valid Acc:79.54 %\n",
      "Epoch:13/100 \t Train Loss:0.5147 Valid Loss:0.5623 \t Train Acc:81.96 %  Valid Acc:81.22 %\n",
      "Epoch:14/100 \t Train Loss:0.4941 Valid Loss:0.5825 \t Train Acc:82.83 %  Valid Acc:80.37 %\n",
      "Epoch:15/100 \t Train Loss:0.4729 Valid Loss:0.5571 \t Train Acc:83.53 %  Valid Acc:81.58 %\n",
      "Epoch:16/100 \t Train Loss:0.4601 Valid Loss:0.5294 \t Train Acc:83.97 %  Valid Acc:82.29 %\n",
      "Epoch:17/100 \t Train Loss:0.4512 Valid Loss:0.5362 \t Train Acc:84.33 %  Valid Acc:82.82 %\n",
      "Epoch:18/100 \t Train Loss:0.4364 Valid Loss:0.5485 \t Train Acc:84.92 %  Valid Acc:82.06 %\n",
      "Epoch:19/100 \t Train Loss:0.4251 Valid Loss:0.5472 \t Train Acc:85.22 %  Valid Acc:81.90 %\n",
      "Epoch:20/100 \t Train Loss:0.4175 Valid Loss:0.5252 \t Train Acc:85.38 %  Valid Acc:82.65 %\n",
      "Epoch:21/100 \t Train Loss:0.3346 Valid Loss:0.4443 \t Train Acc:88.29 %  Valid Acc:85.26 %\n",
      "Epoch:22/100 \t Train Loss:0.3223 Valid Loss:0.4453 \t Train Acc:88.67 %  Valid Acc:85.65 %\n",
      "Epoch:23/100 \t Train Loss:0.3087 Valid Loss:0.4443 \t Train Acc:89.15 %  Valid Acc:85.23 %\n",
      "Epoch:24/100 \t Train Loss:0.3017 Valid Loss:0.4527 \t Train Acc:89.38 %  Valid Acc:85.62 %\n",
      "Epoch:25/100 \t Train Loss:0.2957 Valid Loss:0.4358 \t Train Acc:89.63 %  Valid Acc:86.05 %\n",
      "Epoch:26/100 \t Train Loss:0.2896 Valid Loss:0.4476 \t Train Acc:89.92 %  Valid Acc:85.68 %\n",
      "Epoch:27/100 \t Train Loss:0.2877 Valid Loss:0.4473 \t Train Acc:89.91 %  Valid Acc:86.11 %\n",
      "Epoch:28/100 \t Train Loss:0.2816 Valid Loss:0.4349 \t Train Acc:90.16 %  Valid Acc:86.08 %\n",
      "Epoch:29/100 \t Train Loss:0.2782 Valid Loss:0.4453 \t Train Acc:90.06 %  Valid Acc:85.93 %\n",
      "Epoch:30/100 \t Train Loss:0.2743 Valid Loss:0.4409 \t Train Acc:90.39 %  Valid Acc:85.71 %\n",
      "Epoch:31/100 \t Train Loss:0.2684 Valid Loss:0.4563 \t Train Acc:90.49 %  Valid Acc:85.84 %\n",
      "Epoch:32/100 \t Train Loss:0.2646 Valid Loss:0.4462 \t Train Acc:90.72 %  Valid Acc:85.97 %\n",
      "Epoch:33/100 \t Train Loss:0.2596 Valid Loss:0.4428 \t Train Acc:90.92 %  Valid Acc:86.26 %\n",
      "Epoch:34/100 \t Train Loss:0.2584 Valid Loss:0.4427 \t Train Acc:90.87 %  Valid Acc:86.55 %\n",
      "Epoch:35/100 \t Train Loss:0.2527 Valid Loss:0.4613 \t Train Acc:91.01 %  Valid Acc:86.23 %\n",
      "Epoch:36/100 \t Train Loss:0.2520 Valid Loss:0.4532 \t Train Acc:90.95 %  Valid Acc:86.15 %\n",
      "Epoch:37/100 \t Train Loss:0.2487 Valid Loss:0.4315 \t Train Acc:91.25 %  Valid Acc:86.36 %\n",
      "Epoch:38/100 \t Train Loss:0.2479 Valid Loss:0.4557 \t Train Acc:91.16 %  Valid Acc:86.00 %\n",
      "Epoch:39/100 \t Train Loss:0.2448 Valid Loss:0.4601 \t Train Acc:91.28 %  Valid Acc:86.10 %\n",
      "Epoch:40/100 \t Train Loss:0.2370 Valid Loss:0.4606 \t Train Acc:91.49 %  Valid Acc:86.21 %\n",
      "Epoch:41/100 \t Train Loss:0.2066 Valid Loss:0.4340 \t Train Acc:92.73 %  Valid Acc:87.09 %\n",
      "Epoch:42/100 \t Train Loss:0.2029 Valid Loss:0.4411 \t Train Acc:92.85 %  Valid Acc:86.84 %\n",
      "Epoch:43/100 \t Train Loss:0.1993 Valid Loss:0.4349 \t Train Acc:92.88 %  Valid Acc:87.13 %\n",
      "Epoch:44/100 \t Train Loss:0.1957 Valid Loss:0.4408 \t Train Acc:93.09 %  Valid Acc:86.93 %\n",
      "Epoch:45/100 \t Train Loss:0.1934 Valid Loss:0.4474 \t Train Acc:93.31 %  Valid Acc:87.01 %\n",
      "Epoch:46/100 \t Train Loss:0.1942 Valid Loss:0.4501 \t Train Acc:93.06 %  Valid Acc:86.66 %\n",
      "Epoch:47/100 \t Train Loss:0.1923 Valid Loss:0.4505 \t Train Acc:93.19 %  Valid Acc:86.90 %\n",
      "Epoch:48/100 \t Train Loss:0.1886 Valid Loss:0.4513 \t Train Acc:93.26 %  Valid Acc:87.08 %\n",
      "Epoch:49/100 \t Train Loss:0.1923 Valid Loss:0.4493 \t Train Acc:93.15 %  Valid Acc:87.11 %\n",
      "Epoch:50/100 \t Train Loss:0.1872 Valid Loss:0.4511 \t Train Acc:93.37 %  Valid Acc:86.98 %\n",
      "Epoch:51/100 \t Train Loss:0.1850 Valid Loss:0.4601 \t Train Acc:93.38 %  Valid Acc:86.75 %\n",
      "Epoch:52/100 \t Train Loss:0.1840 Valid Loss:0.4434 \t Train Acc:93.38 %  Valid Acc:87.15 %\n",
      "Epoch:53/100 \t Train Loss:0.1861 Valid Loss:0.4492 \t Train Acc:93.29 %  Valid Acc:87.24 %\n",
      "Epoch:54/100 \t Train Loss:0.1812 Valid Loss:0.4550 \t Train Acc:93.50 %  Valid Acc:87.05 %\n",
      "Epoch:55/100 \t Train Loss:0.1810 Valid Loss:0.4493 \t Train Acc:93.62 %  Valid Acc:87.07 %\n",
      "Epoch:56/100 \t Train Loss:0.1791 Valid Loss:0.4604 \t Train Acc:93.60 %  Valid Acc:86.90 %\n",
      "Epoch:57/100 \t Train Loss:0.1764 Valid Loss:0.4648 \t Train Acc:93.64 %  Valid Acc:86.92 %\n",
      "Epoch:58/100 \t Train Loss:0.1747 Valid Loss:0.4584 \t Train Acc:93.66 %  Valid Acc:86.99 %\n",
      "Epoch:59/100 \t Train Loss:0.1729 Valid Loss:0.4644 \t Train Acc:93.90 %  Valid Acc:86.76 %\n",
      "Epoch:60/100 \t Train Loss:0.1725 Valid Loss:0.4635 \t Train Acc:93.90 %  Valid Acc:86.87 %\n",
      "Epoch:61/100 \t Train Loss:0.1637 Valid Loss:0.4614 \t Train Acc:94.12 %  Valid Acc:87.25 %\n",
      "Epoch:62/100 \t Train Loss:0.1633 Valid Loss:0.4642 \t Train Acc:94.11 %  Valid Acc:87.14 %\n",
      "Epoch:63/100 \t Train Loss:0.1608 Valid Loss:0.4609 \t Train Acc:94.33 %  Valid Acc:87.26 %\n",
      "Epoch:64/100 \t Train Loss:0.1576 Valid Loss:0.4634 \t Train Acc:94.40 %  Valid Acc:87.22 %\n",
      "Epoch:65/100 \t Train Loss:0.1626 Valid Loss:0.4622 \t Train Acc:94.16 %  Valid Acc:87.42 %\n",
      "Epoch:66/100 \t Train Loss:0.1582 Valid Loss:0.4605 \t Train Acc:94.37 %  Valid Acc:87.28 %\n",
      "Epoch:67/100 \t Train Loss:0.1591 Valid Loss:0.4661 \t Train Acc:94.48 %  Valid Acc:87.47 %\n",
      "Epoch:68/100 \t Train Loss:0.1604 Valid Loss:0.4618 \t Train Acc:94.34 %  Valid Acc:87.29 %\n",
      "Epoch:69/100 \t Train Loss:0.1548 Valid Loss:0.4659 \t Train Acc:94.50 %  Valid Acc:87.14 %\n",
      "Epoch:70/100 \t Train Loss:0.1556 Valid Loss:0.4698 \t Train Acc:94.39 %  Valid Acc:87.30 %\n",
      "Epoch:71/100 \t Train Loss:0.1577 Valid Loss:0.4643 \t Train Acc:94.42 %  Valid Acc:87.16 %\n",
      "Epoch:72/100 \t Train Loss:0.1551 Valid Loss:0.4708 \t Train Acc:94.48 %  Valid Acc:87.12 %\n",
      "Epoch:73/100 \t Train Loss:0.1553 Valid Loss:0.4657 \t Train Acc:94.36 %  Valid Acc:87.41 %\n",
      "Epoch:74/100 \t Train Loss:0.1534 Valid Loss:0.4722 \t Train Acc:94.53 %  Valid Acc:87.25 %\n",
      "Epoch:75/100 \t Train Loss:0.1557 Valid Loss:0.4686 \t Train Acc:94.46 %  Valid Acc:87.25 %\n",
      "Epoch:76/100 \t Train Loss:0.1536 Valid Loss:0.4773 \t Train Acc:94.51 %  Valid Acc:87.03 %\n",
      "Epoch:77/100 \t Train Loss:0.1515 Valid Loss:0.4744 \t Train Acc:94.61 %  Valid Acc:87.03 %\n",
      "Epoch:78/100 \t Train Loss:0.1524 Valid Loss:0.4748 \t Train Acc:94.52 %  Valid Acc:87.11 %\n",
      "Epoch:79/100 \t Train Loss:0.1532 Valid Loss:0.4748 \t Train Acc:94.47 %  Valid Acc:87.29 %\n",
      "Epoch:80/100 \t Train Loss:0.1505 Valid Loss:0.4815 \t Train Acc:94.75 %  Valid Acc:87.36 %\n",
      "Epoch:81/100 \t Train Loss:0.1490 Valid Loss:0.4740 \t Train Acc:94.71 %  Valid Acc:87.23 %\n",
      "Epoch:82/100 \t Train Loss:0.1502 Valid Loss:0.4723 \t Train Acc:94.69 %  Valid Acc:87.21 %\n",
      "Epoch:83/100 \t Train Loss:0.1458 Valid Loss:0.4740 \t Train Acc:94.79 %  Valid Acc:87.07 %\n",
      "Epoch:84/100 \t Train Loss:0.1443 Valid Loss:0.4753 \t Train Acc:94.81 %  Valid Acc:87.14 %\n",
      "Epoch:85/100 \t Train Loss:0.1470 Valid Loss:0.4745 \t Train Acc:94.74 %  Valid Acc:87.09 %\n",
      "Epoch:86/100 \t Train Loss:0.1457 Valid Loss:0.4718 \t Train Acc:94.68 %  Valid Acc:87.09 %\n",
      "Epoch:87/100 \t Train Loss:0.1449 Valid Loss:0.4756 \t Train Acc:94.91 %  Valid Acc:87.11 %\n",
      "Epoch:88/100 \t Train Loss:0.1446 Valid Loss:0.4751 \t Train Acc:94.89 %  Valid Acc:87.00 %\n",
      "Epoch:89/100 \t Train Loss:0.1466 Valid Loss:0.4724 \t Train Acc:94.80 %  Valid Acc:87.18 %\n",
      "Epoch:90/100 \t Train Loss:0.1465 Valid Loss:0.4760 \t Train Acc:94.83 %  Valid Acc:87.24 %\n",
      "Epoch:91/100 \t Train Loss:0.1446 Valid Loss:0.4753 \t Train Acc:94.80 %  Valid Acc:87.16 %\n",
      "Epoch:92/100 \t Train Loss:0.1439 Valid Loss:0.4764 \t Train Acc:94.87 %  Valid Acc:87.22 %\n",
      "Epoch:93/100 \t Train Loss:0.1418 Valid Loss:0.4809 \t Train Acc:94.99 %  Valid Acc:86.97 %\n",
      "Epoch:94/100 \t Train Loss:0.1446 Valid Loss:0.4795 \t Train Acc:94.77 %  Valid Acc:87.06 %\n",
      "Epoch:95/100 \t Train Loss:0.1440 Valid Loss:0.4801 \t Train Acc:94.90 %  Valid Acc:87.01 %\n",
      "Epoch:96/100 \t Train Loss:0.1424 Valid Loss:0.4812 \t Train Acc:94.93 %  Valid Acc:87.24 %\n",
      "Epoch:97/100 \t Train Loss:0.1464 Valid Loss:0.4801 \t Train Acc:94.75 %  Valid Acc:87.07 %\n",
      "Epoch:98/100 \t Train Loss:0.1440 Valid Loss:0.4830 \t Train Acc:94.79 %  Valid Acc:86.92 %\n",
      "Epoch:99/100 \t Train Loss:0.1458 Valid Loss:0.4796 \t Train Acc:94.75 %  Valid Acc:87.13 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 22:49:12,872] Trial 7 finished with value: 87.03999999999999 and parameters: {'sigma_1': 1.4587836508181475, 'sigma_2': 1.002416907402547, 'sigma_3': 2.957919729913672, 'sigma_4': 0.5431900168844337, 'sigma_5': 4.937997900408576, 'sigma_6': 2.749666720207438, 'sigma_7': 2.4869959299996927, 'sigma_8': 1.109225819945721, 'sigma_9': 3.828869432389412, 'sigma_10': 1.7146711384293567, 'sigma_11': 2.672687743252857, 'sigma_12': 3.4359058384367946, 'sigma_13': 4.808792628312248}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1450 Valid Loss:0.4803 \t Train Acc:94.70 %  Valid Acc:87.04 %\n",
      "Epoch:1/100 \t Train Loss:1.4947 Valid Loss:1.4159 \t Train Acc:44.78 %  Valid Acc:48.61 %\n",
      "Epoch:2/100 \t Train Loss:1.1355 Valid Loss:1.0979 \t Train Acc:59.46 %  Valid Acc:61.01 %\n",
      "Epoch:3/100 \t Train Loss:0.9842 Valid Loss:0.8668 \t Train Acc:65.20 %  Valid Acc:69.19 %\n",
      "Epoch:4/100 \t Train Loss:0.8960 Valid Loss:0.8547 \t Train Acc:68.38 %  Valid Acc:68.96 %\n",
      "Epoch:5/100 \t Train Loss:0.8181 Valid Loss:0.7517 \t Train Acc:71.16 %  Valid Acc:73.72 %\n",
      "Epoch:6/100 \t Train Loss:0.7632 Valid Loss:0.7277 \t Train Acc:73.15 %  Valid Acc:74.32 %\n",
      "Epoch:7/100 \t Train Loss:0.7128 Valid Loss:0.7217 \t Train Acc:74.71 %  Valid Acc:75.00 %\n",
      "Epoch:8/100 \t Train Loss:0.6711 Valid Loss:0.6748 \t Train Acc:76.55 %  Valid Acc:77.10 %\n",
      "Epoch:9/100 \t Train Loss:0.6367 Valid Loss:0.6395 \t Train Acc:77.67 %  Valid Acc:77.92 %\n",
      "Epoch:10/100 \t Train Loss:0.6042 Valid Loss:0.6900 \t Train Acc:79.05 %  Valid Acc:76.21 %\n",
      "Epoch:11/100 \t Train Loss:0.5719 Valid Loss:0.6616 \t Train Acc:79.98 %  Valid Acc:78.16 %\n",
      "Epoch:12/100 \t Train Loss:0.5477 Valid Loss:0.5812 \t Train Acc:80.84 %  Valid Acc:79.94 %\n",
      "Epoch:13/100 \t Train Loss:0.5292 Valid Loss:0.5739 \t Train Acc:81.63 %  Valid Acc:80.87 %\n",
      "Epoch:14/100 \t Train Loss:0.5129 Valid Loss:0.5472 \t Train Acc:82.08 %  Valid Acc:81.56 %\n",
      "Epoch:15/100 \t Train Loss:0.4937 Valid Loss:0.5568 \t Train Acc:82.76 %  Valid Acc:81.05 %\n",
      "Epoch:16/100 \t Train Loss:0.4817 Valid Loss:0.5782 \t Train Acc:83.22 %  Valid Acc:80.26 %\n",
      "Epoch:17/100 \t Train Loss:0.4613 Valid Loss:0.5430 \t Train Acc:83.93 %  Valid Acc:82.01 %\n",
      "Epoch:18/100 \t Train Loss:0.4501 Valid Loss:0.5295 \t Train Acc:84.37 %  Valid Acc:82.48 %\n",
      "Epoch:19/100 \t Train Loss:0.4424 Valid Loss:0.5092 \t Train Acc:84.56 %  Valid Acc:83.14 %\n",
      "Epoch:20/100 \t Train Loss:0.4277 Valid Loss:0.4943 \t Train Acc:85.17 %  Valid Acc:83.61 %\n",
      "Epoch:21/100 \t Train Loss:0.3473 Valid Loss:0.4563 \t Train Acc:87.99 %  Valid Acc:85.23 %\n",
      "Epoch:22/100 \t Train Loss:0.3280 Valid Loss:0.4574 \t Train Acc:88.58 %  Valid Acc:85.20 %\n",
      "Epoch:23/100 \t Train Loss:0.3238 Valid Loss:0.4570 \t Train Acc:88.66 %  Valid Acc:85.36 %\n",
      "Epoch:24/100 \t Train Loss:0.3138 Valid Loss:0.4563 \t Train Acc:89.06 %  Valid Acc:85.39 %\n",
      "Epoch:25/100 \t Train Loss:0.3079 Valid Loss:0.4732 \t Train Acc:89.12 %  Valid Acc:84.75 %\n",
      "Epoch:26/100 \t Train Loss:0.2997 Valid Loss:0.4638 \t Train Acc:89.64 %  Valid Acc:85.23 %\n",
      "Epoch:27/100 \t Train Loss:0.2997 Valid Loss:0.4656 \t Train Acc:89.56 %  Valid Acc:85.15 %\n",
      "Epoch:28/100 \t Train Loss:0.2952 Valid Loss:0.4625 \t Train Acc:89.67 %  Valid Acc:85.46 %\n",
      "Epoch:29/100 \t Train Loss:0.2875 Valid Loss:0.4740 \t Train Acc:89.93 %  Valid Acc:85.05 %\n",
      "Epoch:30/100 \t Train Loss:0.2865 Valid Loss:0.4447 \t Train Acc:89.92 %  Valid Acc:85.70 %\n",
      "Epoch:31/100 \t Train Loss:0.2780 Valid Loss:0.4691 \t Train Acc:90.17 %  Valid Acc:85.14 %\n",
      "Epoch:32/100 \t Train Loss:0.2796 Valid Loss:0.4536 \t Train Acc:90.13 %  Valid Acc:85.87 %\n",
      "Epoch:33/100 \t Train Loss:0.2737 Valid Loss:0.4487 \t Train Acc:90.47 %  Valid Acc:85.63 %\n",
      "Epoch:34/100 \t Train Loss:0.2671 Valid Loss:0.4780 \t Train Acc:90.55 %  Valid Acc:85.23 %\n",
      "Epoch:35/100 \t Train Loss:0.2652 Valid Loss:0.4648 \t Train Acc:90.80 %  Valid Acc:85.65 %\n",
      "Epoch:36/100 \t Train Loss:0.2602 Valid Loss:0.4551 \t Train Acc:90.84 %  Valid Acc:85.46 %\n",
      "Epoch:37/100 \t Train Loss:0.2588 Valid Loss:0.4756 \t Train Acc:90.87 %  Valid Acc:85.47 %\n",
      "Epoch:38/100 \t Train Loss:0.2544 Valid Loss:0.4499 \t Train Acc:90.94 %  Valid Acc:85.94 %\n",
      "Epoch:39/100 \t Train Loss:0.2520 Valid Loss:0.4567 \t Train Acc:91.01 %  Valid Acc:86.13 %\n",
      "Epoch:40/100 \t Train Loss:0.2498 Valid Loss:0.4441 \t Train Acc:91.05 %  Valid Acc:86.27 %\n",
      "Epoch:41/100 \t Train Loss:0.2189 Valid Loss:0.4580 \t Train Acc:92.36 %  Valid Acc:86.28 %\n",
      "Epoch:42/100 \t Train Loss:0.2133 Valid Loss:0.4455 \t Train Acc:92.54 %  Valid Acc:86.63 %\n",
      "Epoch:43/100 \t Train Loss:0.2102 Valid Loss:0.4533 \t Train Acc:92.68 %  Valid Acc:86.59 %\n",
      "Epoch:44/100 \t Train Loss:0.2063 Valid Loss:0.4510 \t Train Acc:92.63 %  Valid Acc:86.74 %\n",
      "Epoch:45/100 \t Train Loss:0.2025 Valid Loss:0.4602 \t Train Acc:92.76 %  Valid Acc:86.32 %\n",
      "Epoch:46/100 \t Train Loss:0.2045 Valid Loss:0.4530 \t Train Acc:92.74 %  Valid Acc:86.46 %\n",
      "Epoch:47/100 \t Train Loss:0.2012 Valid Loss:0.4566 \t Train Acc:92.86 %  Valid Acc:86.63 %\n",
      "Epoch:48/100 \t Train Loss:0.1993 Valid Loss:0.4608 \t Train Acc:92.94 %  Valid Acc:86.70 %\n",
      "Epoch:49/100 \t Train Loss:0.1991 Valid Loss:0.4545 \t Train Acc:92.91 %  Valid Acc:86.96 %\n",
      "Epoch:50/100 \t Train Loss:0.1939 Valid Loss:0.4573 \t Train Acc:93.09 %  Valid Acc:86.77 %\n",
      "Epoch:51/100 \t Train Loss:0.1951 Valid Loss:0.4631 \t Train Acc:93.03 %  Valid Acc:86.69 %\n",
      "Epoch:52/100 \t Train Loss:0.1938 Valid Loss:0.4656 \t Train Acc:93.25 %  Valid Acc:86.65 %\n",
      "Epoch:53/100 \t Train Loss:0.1925 Valid Loss:0.4729 \t Train Acc:93.21 %  Valid Acc:86.56 %\n",
      "Epoch:54/100 \t Train Loss:0.1943 Valid Loss:0.4595 \t Train Acc:93.03 %  Valid Acc:86.69 %\n",
      "Epoch:55/100 \t Train Loss:0.1873 Valid Loss:0.4700 \t Train Acc:93.43 %  Valid Acc:86.71 %\n",
      "Epoch:56/100 \t Train Loss:0.1905 Valid Loss:0.4672 \t Train Acc:93.25 %  Valid Acc:86.77 %\n",
      "Epoch:57/100 \t Train Loss:0.1874 Valid Loss:0.4664 \t Train Acc:93.31 %  Valid Acc:86.99 %\n",
      "Epoch:58/100 \t Train Loss:0.1829 Valid Loss:0.4717 \t Train Acc:93.56 %  Valid Acc:86.64 %\n",
      "Epoch:59/100 \t Train Loss:0.1833 Valid Loss:0.4786 \t Train Acc:93.53 %  Valid Acc:86.65 %\n",
      "Epoch:60/100 \t Train Loss:0.1824 Valid Loss:0.4676 \t Train Acc:93.51 %  Valid Acc:86.65 %\n",
      "Epoch:61/100 \t Train Loss:0.1728 Valid Loss:0.4672 \t Train Acc:93.82 %  Valid Acc:86.83 %\n",
      "Epoch:62/100 \t Train Loss:0.1692 Valid Loss:0.4711 \t Train Acc:93.99 %  Valid Acc:86.97 %\n",
      "Epoch:63/100 \t Train Loss:0.1678 Valid Loss:0.4676 \t Train Acc:94.12 %  Valid Acc:87.07 %\n",
      "Epoch:64/100 \t Train Loss:0.1713 Valid Loss:0.4694 \t Train Acc:94.00 %  Valid Acc:86.87 %\n",
      "Epoch:65/100 \t Train Loss:0.1664 Valid Loss:0.4682 \t Train Acc:94.12 %  Valid Acc:87.03 %\n",
      "Epoch:66/100 \t Train Loss:0.1699 Valid Loss:0.4740 \t Train Acc:93.97 %  Valid Acc:86.90 %\n",
      "Epoch:67/100 \t Train Loss:0.1659 Valid Loss:0.4720 \t Train Acc:94.13 %  Valid Acc:86.97 %\n",
      "Epoch:68/100 \t Train Loss:0.1689 Valid Loss:0.4692 \t Train Acc:93.95 %  Valid Acc:87.06 %\n",
      "Epoch:69/100 \t Train Loss:0.1665 Valid Loss:0.4747 \t Train Acc:94.04 %  Valid Acc:87.06 %\n",
      "Epoch:70/100 \t Train Loss:0.1652 Valid Loss:0.4688 \t Train Acc:94.05 %  Valid Acc:87.01 %\n",
      "Epoch:71/100 \t Train Loss:0.1625 Valid Loss:0.4702 \t Train Acc:94.24 %  Valid Acc:87.06 %\n",
      "Epoch:72/100 \t Train Loss:0.1642 Valid Loss:0.4734 \t Train Acc:94.13 %  Valid Acc:86.84 %\n",
      "Epoch:73/100 \t Train Loss:0.1643 Valid Loss:0.4756 \t Train Acc:94.17 %  Valid Acc:86.97 %\n",
      "Epoch:74/100 \t Train Loss:0.1643 Valid Loss:0.4823 \t Train Acc:94.18 %  Valid Acc:86.84 %\n",
      "Epoch:75/100 \t Train Loss:0.1619 Valid Loss:0.4764 \t Train Acc:94.25 %  Valid Acc:86.96 %\n",
      "Epoch:76/100 \t Train Loss:0.1621 Valid Loss:0.4782 \t Train Acc:94.23 %  Valid Acc:86.84 %\n",
      "Epoch:77/100 \t Train Loss:0.1642 Valid Loss:0.4800 \t Train Acc:94.22 %  Valid Acc:86.96 %\n",
      "Epoch:78/100 \t Train Loss:0.1620 Valid Loss:0.4771 \t Train Acc:94.24 %  Valid Acc:86.89 %\n",
      "Epoch:79/100 \t Train Loss:0.1626 Valid Loss:0.4812 \t Train Acc:94.15 %  Valid Acc:86.89 %\n",
      "Epoch:80/100 \t Train Loss:0.1598 Valid Loss:0.4813 \t Train Acc:94.25 %  Valid Acc:86.79 %\n",
      "Epoch:81/100 \t Train Loss:0.1557 Valid Loss:0.4827 \t Train Acc:94.47 %  Valid Acc:86.91 %\n",
      "Epoch:82/100 \t Train Loss:0.1587 Valid Loss:0.4789 \t Train Acc:94.26 %  Valid Acc:86.91 %\n",
      "Epoch:83/100 \t Train Loss:0.1546 Valid Loss:0.4817 \t Train Acc:94.47 %  Valid Acc:86.74 %\n",
      "Epoch:84/100 \t Train Loss:0.1553 Valid Loss:0.4841 \t Train Acc:94.44 %  Valid Acc:86.87 %\n",
      "Epoch:85/100 \t Train Loss:0.1538 Valid Loss:0.4843 \t Train Acc:94.43 %  Valid Acc:86.83 %\n",
      "Epoch:86/100 \t Train Loss:0.1567 Valid Loss:0.4811 \t Train Acc:94.39 %  Valid Acc:86.92 %\n",
      "Epoch:87/100 \t Train Loss:0.1563 Valid Loss:0.4810 \t Train Acc:94.35 %  Valid Acc:86.86 %\n",
      "Epoch:88/100 \t Train Loss:0.1544 Valid Loss:0.4812 \t Train Acc:94.53 %  Valid Acc:86.84 %\n",
      "Epoch:89/100 \t Train Loss:0.1548 Valid Loss:0.4816 \t Train Acc:94.51 %  Valid Acc:86.83 %\n",
      "Epoch:90/100 \t Train Loss:0.1537 Valid Loss:0.4843 \t Train Acc:94.56 %  Valid Acc:86.79 %\n",
      "Epoch:91/100 \t Train Loss:0.1541 Valid Loss:0.4844 \t Train Acc:94.46 %  Valid Acc:86.88 %\n",
      "Epoch:92/100 \t Train Loss:0.1535 Valid Loss:0.4844 \t Train Acc:94.56 %  Valid Acc:86.97 %\n",
      "Epoch:93/100 \t Train Loss:0.1521 Valid Loss:0.4845 \t Train Acc:94.62 %  Valid Acc:87.03 %\n",
      "Epoch:94/100 \t Train Loss:0.1538 Valid Loss:0.4824 \t Train Acc:94.59 %  Valid Acc:87.00 %\n",
      "Epoch:95/100 \t Train Loss:0.1550 Valid Loss:0.4845 \t Train Acc:94.49 %  Valid Acc:86.84 %\n",
      "Epoch:96/100 \t Train Loss:0.1540 Valid Loss:0.4846 \t Train Acc:94.49 %  Valid Acc:86.92 %\n",
      "Epoch:97/100 \t Train Loss:0.1527 Valid Loss:0.4822 \t Train Acc:94.50 %  Valid Acc:86.98 %\n",
      "Epoch:98/100 \t Train Loss:0.1503 Valid Loss:0.4825 \t Train Acc:94.71 %  Valid Acc:86.97 %\n",
      "Epoch:99/100 \t Train Loss:0.1529 Valid Loss:0.4840 \t Train Acc:94.40 %  Valid Acc:86.99 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 00:09:02,149] Trial 8 finished with value: 87.0 and parameters: {'sigma_1': 1.6715017272409696, 'sigma_2': 2.290353518303827, 'sigma_3': 0.14603268567920705, 'sigma_4': 4.159207835363518, 'sigma_5': 1.5436361700431787, 'sigma_6': 4.402258750011341, 'sigma_7': 3.544743759480845, 'sigma_8': 2.1647783108172165, 'sigma_9': 4.007883055110152, 'sigma_10': 1.7013797578102734, 'sigma_11': 0.8996646022911582, 'sigma_12': 2.256974966154796, 'sigma_13': 3.4006798787252976}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1546 Valid Loss:0.4860 \t Train Acc:94.43 %  Valid Acc:87.00 %\n",
      "Epoch:1/100 \t Train Loss:1.4951 Valid Loss:1.6530 \t Train Acc:44.72 %  Valid Acc:42.47 %\n",
      "Epoch:2/100 \t Train Loss:1.1798 Valid Loss:1.0724 \t Train Acc:57.19 %  Valid Acc:61.50 %\n",
      "Epoch:3/100 \t Train Loss:1.0507 Valid Loss:0.9834 \t Train Acc:62.53 %  Valid Acc:65.17 %\n",
      "Epoch:4/100 \t Train Loss:0.9556 Valid Loss:0.8946 \t Train Acc:66.08 %  Valid Acc:68.25 %\n",
      "Epoch:5/100 \t Train Loss:0.8744 Valid Loss:0.9190 \t Train Acc:68.92 %  Valid Acc:68.54 %\n",
      "Epoch:6/100 \t Train Loss:0.8052 Valid Loss:0.7678 \t Train Acc:71.64 %  Valid Acc:73.31 %\n",
      "Epoch:7/100 \t Train Loss:0.7512 Valid Loss:0.7403 \t Train Acc:73.72 %  Valid Acc:74.44 %\n",
      "Epoch:8/100 \t Train Loss:0.7039 Valid Loss:0.6858 \t Train Acc:75.39 %  Valid Acc:76.30 %\n",
      "Epoch:9/100 \t Train Loss:0.6687 Valid Loss:0.6559 \t Train Acc:76.50 %  Valid Acc:77.21 %\n",
      "Epoch:10/100 \t Train Loss:0.6299 Valid Loss:0.6282 \t Train Acc:78.09 %  Valid Acc:78.77 %\n",
      "Epoch:11/100 \t Train Loss:0.6006 Valid Loss:0.6573 \t Train Acc:78.92 %  Valid Acc:77.38 %\n",
      "Epoch:12/100 \t Train Loss:0.5741 Valid Loss:0.6190 \t Train Acc:80.13 %  Valid Acc:79.21 %\n",
      "Epoch:13/100 \t Train Loss:0.5522 Valid Loss:0.6074 \t Train Acc:80.56 %  Valid Acc:79.56 %\n",
      "Epoch:14/100 \t Train Loss:0.5345 Valid Loss:0.5443 \t Train Acc:81.60 %  Valid Acc:81.21 %\n",
      "Epoch:15/100 \t Train Loss:0.5185 Valid Loss:0.5904 \t Train Acc:82.06 %  Valid Acc:80.10 %\n",
      "Epoch:16/100 \t Train Loss:0.4971 Valid Loss:0.5423 \t Train Acc:82.76 %  Valid Acc:82.07 %\n",
      "Epoch:17/100 \t Train Loss:0.4844 Valid Loss:0.5603 \t Train Acc:83.13 %  Valid Acc:81.30 %\n",
      "Epoch:18/100 \t Train Loss:0.4703 Valid Loss:0.5250 \t Train Acc:83.70 %  Valid Acc:82.67 %\n",
      "Epoch:19/100 \t Train Loss:0.4567 Valid Loss:0.5149 \t Train Acc:84.07 %  Valid Acc:82.88 %\n",
      "Epoch:20/100 \t Train Loss:0.4431 Valid Loss:0.5170 \t Train Acc:84.57 %  Valid Acc:82.66 %\n",
      "Epoch:21/100 \t Train Loss:0.3636 Valid Loss:0.4538 \t Train Acc:87.20 %  Valid Acc:84.66 %\n",
      "Epoch:22/100 \t Train Loss:0.3453 Valid Loss:0.4497 \t Train Acc:87.91 %  Valid Acc:84.87 %\n",
      "Epoch:23/100 \t Train Loss:0.3370 Valid Loss:0.4639 \t Train Acc:88.16 %  Valid Acc:84.53 %\n",
      "Epoch:24/100 \t Train Loss:0.3276 Valid Loss:0.4546 \t Train Acc:88.58 %  Valid Acc:85.01 %\n",
      "Epoch:25/100 \t Train Loss:0.3229 Valid Loss:0.4557 \t Train Acc:88.68 %  Valid Acc:84.93 %\n",
      "Epoch:26/100 \t Train Loss:0.3162 Valid Loss:0.4581 \t Train Acc:88.97 %  Valid Acc:84.94 %\n",
      "Epoch:27/100 \t Train Loss:0.3138 Valid Loss:0.4508 \t Train Acc:88.85 %  Valid Acc:85.38 %\n",
      "Epoch:28/100 \t Train Loss:0.3046 Valid Loss:0.4522 \t Train Acc:89.27 %  Valid Acc:85.07 %\n",
      "Epoch:29/100 \t Train Loss:0.3035 Valid Loss:0.4509 \t Train Acc:89.37 %  Valid Acc:85.69 %\n",
      "Epoch:30/100 \t Train Loss:0.2958 Valid Loss:0.4445 \t Train Acc:89.64 %  Valid Acc:85.34 %\n",
      "Epoch:31/100 \t Train Loss:0.2922 Valid Loss:0.4722 \t Train Acc:89.69 %  Valid Acc:85.18 %\n",
      "Epoch:32/100 \t Train Loss:0.2901 Valid Loss:0.4411 \t Train Acc:89.72 %  Valid Acc:85.64 %\n",
      "Epoch:33/100 \t Train Loss:0.2849 Valid Loss:0.4542 \t Train Acc:90.06 %  Valid Acc:85.58 %\n",
      "Epoch:34/100 \t Train Loss:0.2815 Valid Loss:0.4654 \t Train Acc:89.99 %  Valid Acc:85.67 %\n",
      "Epoch:35/100 \t Train Loss:0.2814 Valid Loss:0.4608 \t Train Acc:90.12 %  Valid Acc:85.61 %\n",
      "Epoch:36/100 \t Train Loss:0.2752 Valid Loss:0.4582 \t Train Acc:90.40 %  Valid Acc:85.84 %\n",
      "Epoch:37/100 \t Train Loss:0.2732 Valid Loss:0.4592 \t Train Acc:90.47 %  Valid Acc:85.57 %\n",
      "Epoch:38/100 \t Train Loss:0.2695 Valid Loss:0.4550 \t Train Acc:90.52 %  Valid Acc:85.60 %\n",
      "Epoch:39/100 \t Train Loss:0.2632 Valid Loss:0.4675 \t Train Acc:90.72 %  Valid Acc:85.67 %\n",
      "Epoch:40/100 \t Train Loss:0.2600 Valid Loss:0.4678 \t Train Acc:90.78 %  Valid Acc:85.90 %\n",
      "Epoch:41/100 \t Train Loss:0.2281 Valid Loss:0.4486 \t Train Acc:91.94 %  Valid Acc:86.20 %\n",
      "Epoch:42/100 \t Train Loss:0.2214 Valid Loss:0.4505 \t Train Acc:92.18 %  Valid Acc:86.25 %\n",
      "Epoch:43/100 \t Train Loss:0.2215 Valid Loss:0.4536 \t Train Acc:92.11 %  Valid Acc:86.41 %\n",
      "Epoch:44/100 \t Train Loss:0.2175 Valid Loss:0.4585 \t Train Acc:92.35 %  Valid Acc:86.25 %\n",
      "Epoch:45/100 \t Train Loss:0.2152 Valid Loss:0.4572 \t Train Acc:92.30 %  Valid Acc:86.10 %\n",
      "Epoch:46/100 \t Train Loss:0.2139 Valid Loss:0.4497 \t Train Acc:92.44 %  Valid Acc:86.49 %\n",
      "Epoch:47/100 \t Train Loss:0.2120 Valid Loss:0.4617 \t Train Acc:92.38 %  Valid Acc:86.15 %\n",
      "Epoch:48/100 \t Train Loss:0.2117 Valid Loss:0.4541 \t Train Acc:92.53 %  Valid Acc:86.39 %\n",
      "Epoch:49/100 \t Train Loss:0.2132 Valid Loss:0.4624 \t Train Acc:92.53 %  Valid Acc:86.24 %\n",
      "Epoch:50/100 \t Train Loss:0.2066 Valid Loss:0.4686 \t Train Acc:92.70 %  Valid Acc:86.03 %\n",
      "Epoch:51/100 \t Train Loss:0.2076 Valid Loss:0.4650 \t Train Acc:92.68 %  Valid Acc:86.12 %\n",
      "Epoch:52/100 \t Train Loss:0.2057 Valid Loss:0.4644 \t Train Acc:92.72 %  Valid Acc:86.40 %\n",
      "Epoch:53/100 \t Train Loss:0.2023 Valid Loss:0.4666 \t Train Acc:92.93 %  Valid Acc:86.32 %\n",
      "Epoch:54/100 \t Train Loss:0.2016 Valid Loss:0.4592 \t Train Acc:92.78 %  Valid Acc:86.50 %\n",
      "Epoch:55/100 \t Train Loss:0.1991 Valid Loss:0.4640 \t Train Acc:92.81 %  Valid Acc:86.23 %\n",
      "Epoch:56/100 \t Train Loss:0.1996 Valid Loss:0.4599 \t Train Acc:92.95 %  Valid Acc:86.24 %\n",
      "Epoch:57/100 \t Train Loss:0.1965 Valid Loss:0.4754 \t Train Acc:93.02 %  Valid Acc:86.32 %\n",
      "Epoch:58/100 \t Train Loss:0.1965 Valid Loss:0.4693 \t Train Acc:93.13 %  Valid Acc:86.57 %\n",
      "Epoch:59/100 \t Train Loss:0.1937 Valid Loss:0.4636 \t Train Acc:93.04 %  Valid Acc:86.56 %\n",
      "Epoch:60/100 \t Train Loss:0.1946 Valid Loss:0.4742 \t Train Acc:92.96 %  Valid Acc:86.46 %\n",
      "Epoch:61/100 \t Train Loss:0.1838 Valid Loss:0.4713 \t Train Acc:93.49 %  Valid Acc:86.52 %\n",
      "Epoch:62/100 \t Train Loss:0.1829 Valid Loss:0.4728 \t Train Acc:93.59 %  Valid Acc:86.57 %\n",
      "Epoch:63/100 \t Train Loss:0.1803 Valid Loss:0.4728 \t Train Acc:93.71 %  Valid Acc:86.40 %\n",
      "Epoch:64/100 \t Train Loss:0.1796 Valid Loss:0.4715 \t Train Acc:93.66 %  Valid Acc:86.46 %\n",
      "Epoch:65/100 \t Train Loss:0.1804 Valid Loss:0.4714 \t Train Acc:93.66 %  Valid Acc:86.76 %\n",
      "Epoch:66/100 \t Train Loss:0.1777 Valid Loss:0.4736 \t Train Acc:93.74 %  Valid Acc:86.62 %\n",
      "Epoch:67/100 \t Train Loss:0.1791 Valid Loss:0.4722 \t Train Acc:93.70 %  Valid Acc:86.58 %\n",
      "Epoch:68/100 \t Train Loss:0.1795 Valid Loss:0.4741 \t Train Acc:93.66 %  Valid Acc:86.54 %\n",
      "Epoch:69/100 \t Train Loss:0.1741 Valid Loss:0.4731 \t Train Acc:93.91 %  Valid Acc:86.68 %\n",
      "Epoch:70/100 \t Train Loss:0.1777 Valid Loss:0.4735 \t Train Acc:93.76 %  Valid Acc:86.68 %\n",
      "Epoch:71/100 \t Train Loss:0.1730 Valid Loss:0.4783 \t Train Acc:93.89 %  Valid Acc:86.67 %\n",
      "Epoch:72/100 \t Train Loss:0.1729 Valid Loss:0.4756 \t Train Acc:93.85 %  Valid Acc:86.57 %\n",
      "Epoch:73/100 \t Train Loss:0.1754 Valid Loss:0.4830 \t Train Acc:93.83 %  Valid Acc:86.35 %\n",
      "Epoch:74/100 \t Train Loss:0.1761 Valid Loss:0.4812 \t Train Acc:93.68 %  Valid Acc:86.45 %\n",
      "Epoch:75/100 \t Train Loss:0.1734 Valid Loss:0.4837 \t Train Acc:93.88 %  Valid Acc:86.57 %\n",
      "Epoch:76/100 \t Train Loss:0.1739 Valid Loss:0.4780 \t Train Acc:93.90 %  Valid Acc:86.67 %\n",
      "Epoch:77/100 \t Train Loss:0.1724 Valid Loss:0.4833 \t Train Acc:93.99 %  Valid Acc:86.59 %\n",
      "Epoch:78/100 \t Train Loss:0.1718 Valid Loss:0.4792 \t Train Acc:93.82 %  Valid Acc:86.50 %\n",
      "Epoch:79/100 \t Train Loss:0.1691 Valid Loss:0.4819 \t Train Acc:93.95 %  Valid Acc:86.62 %\n",
      "Epoch:80/100 \t Train Loss:0.1724 Valid Loss:0.4854 \t Train Acc:93.93 %  Valid Acc:86.50 %\n",
      "Epoch:81/100 \t Train Loss:0.1693 Valid Loss:0.4805 \t Train Acc:94.07 %  Valid Acc:86.70 %\n",
      "Epoch:82/100 \t Train Loss:0.1675 Valid Loss:0.4796 \t Train Acc:94.06 %  Valid Acc:86.62 %\n",
      "Epoch:83/100 \t Train Loss:0.1671 Valid Loss:0.4805 \t Train Acc:94.04 %  Valid Acc:86.46 %\n",
      "Epoch:84/100 \t Train Loss:0.1700 Valid Loss:0.4829 \t Train Acc:93.89 %  Valid Acc:86.58 %\n",
      "Epoch:85/100 \t Train Loss:0.1672 Valid Loss:0.4822 \t Train Acc:94.11 %  Valid Acc:86.47 %\n",
      "Epoch:86/100 \t Train Loss:0.1657 Valid Loss:0.4820 \t Train Acc:94.13 %  Valid Acc:86.57 %\n",
      "Epoch:87/100 \t Train Loss:0.1631 Valid Loss:0.4833 \t Train Acc:94.13 %  Valid Acc:86.57 %\n",
      "Epoch:88/100 \t Train Loss:0.1651 Valid Loss:0.4842 \t Train Acc:94.12 %  Valid Acc:86.43 %\n",
      "Epoch:89/100 \t Train Loss:0.1653 Valid Loss:0.4848 \t Train Acc:94.23 %  Valid Acc:86.54 %\n",
      "Epoch:90/100 \t Train Loss:0.1622 Valid Loss:0.4849 \t Train Acc:94.27 %  Valid Acc:86.51 %\n",
      "Epoch:91/100 \t Train Loss:0.1659 Valid Loss:0.4861 \t Train Acc:94.22 %  Valid Acc:86.53 %\n",
      "Epoch:92/100 \t Train Loss:0.1639 Valid Loss:0.4862 \t Train Acc:94.12 %  Valid Acc:86.47 %\n",
      "Epoch:93/100 \t Train Loss:0.1625 Valid Loss:0.4862 \t Train Acc:94.16 %  Valid Acc:86.55 %\n",
      "Epoch:94/100 \t Train Loss:0.1644 Valid Loss:0.4838 \t Train Acc:94.23 %  Valid Acc:86.49 %\n",
      "Epoch:95/100 \t Train Loss:0.1611 Valid Loss:0.4872 \t Train Acc:94.30 %  Valid Acc:86.47 %\n",
      "Epoch:96/100 \t Train Loss:0.1638 Valid Loss:0.4885 \t Train Acc:94.21 %  Valid Acc:86.56 %\n",
      "Epoch:97/100 \t Train Loss:0.1632 Valid Loss:0.4886 \t Train Acc:94.13 %  Valid Acc:86.59 %\n",
      "Epoch:98/100 \t Train Loss:0.1650 Valid Loss:0.4864 \t Train Acc:94.16 %  Valid Acc:86.50 %\n",
      "Epoch:99/100 \t Train Loss:0.1625 Valid Loss:0.4874 \t Train Acc:94.24 %  Valid Acc:86.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 01:28:46,081] Trial 9 finished with value: 86.5 and parameters: {'sigma_1': 4.22565595078747, 'sigma_2': 2.4999033931354413, 'sigma_3': 2.5455165517976117, 'sigma_4': 2.176238206435269, 'sigma_5': 0.9554349423855967, 'sigma_6': 4.159570239458707, 'sigma_7': 0.6452512446748805, 'sigma_8': 4.931202454624929, 'sigma_9': 2.0568610413059423, 'sigma_10': 3.5955421364279814, 'sigma_11': 2.4013644220993804, 'sigma_12': 4.1331462048500835, 'sigma_13': 3.240889859738038}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1630 Valid Loss:0.4887 \t Train Acc:94.20 %  Valid Acc:86.50 %\n",
      "Epoch:1/100 \t Train Loss:1.5232 Valid Loss:1.8242 \t Train Acc:43.66 %  Valid Acc:39.72 %\n",
      "Epoch:2/100 \t Train Loss:1.2717 Valid Loss:1.1910 \t Train Acc:54.16 %  Valid Acc:59.34 %\n",
      "Epoch:3/100 \t Train Loss:1.1292 Valid Loss:1.0414 \t Train Acc:59.76 %  Valid Acc:62.49 %\n",
      "Epoch:4/100 \t Train Loss:1.0329 Valid Loss:1.0759 \t Train Acc:63.48 %  Valid Acc:63.26 %\n",
      "Epoch:5/100 \t Train Loss:0.9571 Valid Loss:0.8745 \t Train Acc:66.30 %  Valid Acc:69.58 %\n",
      "Epoch:6/100 \t Train Loss:0.9023 Valid Loss:0.8822 \t Train Acc:68.22 %  Valid Acc:68.81 %\n",
      "Epoch:7/100 \t Train Loss:0.8389 Valid Loss:0.8727 \t Train Acc:70.52 %  Valid Acc:69.91 %\n",
      "Epoch:8/100 \t Train Loss:0.7790 Valid Loss:0.7743 \t Train Acc:72.87 %  Valid Acc:73.57 %\n",
      "Epoch:9/100 \t Train Loss:0.7323 Valid Loss:0.7152 \t Train Acc:74.29 %  Valid Acc:75.62 %\n",
      "Epoch:10/100 \t Train Loss:0.6857 Valid Loss:0.7405 \t Train Acc:76.15 %  Valid Acc:74.91 %\n",
      "Epoch:11/100 \t Train Loss:0.6506 Valid Loss:0.6832 \t Train Acc:77.21 %  Valid Acc:77.18 %\n",
      "Epoch:12/100 \t Train Loss:0.6190 Valid Loss:0.6465 \t Train Acc:78.66 %  Valid Acc:78.17 %\n",
      "Epoch:13/100 \t Train Loss:0.5890 Valid Loss:0.6470 \t Train Acc:79.48 %  Valid Acc:78.26 %\n",
      "Epoch:14/100 \t Train Loss:0.5676 Valid Loss:0.5998 \t Train Acc:80.32 %  Valid Acc:79.69 %\n",
      "Epoch:15/100 \t Train Loss:0.5519 Valid Loss:0.5588 \t Train Acc:80.86 %  Valid Acc:81.16 %\n",
      "Epoch:16/100 \t Train Loss:0.5262 Valid Loss:0.5591 \t Train Acc:82.04 %  Valid Acc:81.29 %\n",
      "Epoch:17/100 \t Train Loss:0.5133 Valid Loss:0.5363 \t Train Acc:82.23 %  Valid Acc:82.23 %\n",
      "Epoch:18/100 \t Train Loss:0.4940 Valid Loss:0.5372 \t Train Acc:82.97 %  Valid Acc:82.26 %\n",
      "Epoch:19/100 \t Train Loss:0.4804 Valid Loss:0.5677 \t Train Acc:83.33 %  Valid Acc:81.93 %\n",
      "Epoch:20/100 \t Train Loss:0.4684 Valid Loss:0.5734 \t Train Acc:83.71 %  Valid Acc:81.29 %\n",
      "Epoch:21/100 \t Train Loss:0.3814 Valid Loss:0.4733 \t Train Acc:86.75 %  Valid Acc:84.63 %\n",
      "Epoch:22/100 \t Train Loss:0.3663 Valid Loss:0.4686 \t Train Acc:87.30 %  Valid Acc:84.54 %\n",
      "Epoch:23/100 \t Train Loss:0.3548 Valid Loss:0.4615 \t Train Acc:87.59 %  Valid Acc:84.90 %\n",
      "Epoch:24/100 \t Train Loss:0.3455 Valid Loss:0.4717 \t Train Acc:87.94 %  Valid Acc:84.72 %\n",
      "Epoch:25/100 \t Train Loss:0.3415 Valid Loss:0.4545 \t Train Acc:87.93 %  Valid Acc:85.16 %\n",
      "Epoch:26/100 \t Train Loss:0.3339 Valid Loss:0.4632 \t Train Acc:88.32 %  Valid Acc:84.94 %\n",
      "Epoch:27/100 \t Train Loss:0.3322 Valid Loss:0.4663 \t Train Acc:88.38 %  Valid Acc:84.98 %\n",
      "Epoch:28/100 \t Train Loss:0.3245 Valid Loss:0.4543 \t Train Acc:88.57 %  Valid Acc:85.35 %\n",
      "Epoch:29/100 \t Train Loss:0.3201 Valid Loss:0.4566 \t Train Acc:88.69 %  Valid Acc:85.46 %\n",
      "Epoch:30/100 \t Train Loss:0.3123 Valid Loss:0.4577 \t Train Acc:89.06 %  Valid Acc:85.60 %\n",
      "Epoch:31/100 \t Train Loss:0.3094 Valid Loss:0.4678 \t Train Acc:89.15 %  Valid Acc:85.21 %\n",
      "Epoch:32/100 \t Train Loss:0.3041 Valid Loss:0.4695 \t Train Acc:89.32 %  Valid Acc:85.27 %\n",
      "Epoch:33/100 \t Train Loss:0.3006 Valid Loss:0.4549 \t Train Acc:89.47 %  Valid Acc:85.80 %\n",
      "Epoch:34/100 \t Train Loss:0.2971 Valid Loss:0.4435 \t Train Acc:89.59 %  Valid Acc:86.15 %\n",
      "Epoch:35/100 \t Train Loss:0.2899 Valid Loss:0.4563 \t Train Acc:89.79 %  Valid Acc:85.79 %\n",
      "Epoch:36/100 \t Train Loss:0.2934 Valid Loss:0.4549 \t Train Acc:89.81 %  Valid Acc:85.66 %\n",
      "Epoch:37/100 \t Train Loss:0.2844 Valid Loss:0.4518 \t Train Acc:89.95 %  Valid Acc:85.78 %\n",
      "Epoch:38/100 \t Train Loss:0.2817 Valid Loss:0.4587 \t Train Acc:90.17 %  Valid Acc:86.03 %\n",
      "Epoch:39/100 \t Train Loss:0.2753 Valid Loss:0.4873 \t Train Acc:90.33 %  Valid Acc:85.40 %\n",
      "Epoch:40/100 \t Train Loss:0.2749 Valid Loss:0.4666 \t Train Acc:90.31 %  Valid Acc:85.76 %\n",
      "Epoch:41/100 \t Train Loss:0.2416 Valid Loss:0.4442 \t Train Acc:91.53 %  Valid Acc:86.55 %\n",
      "Epoch:42/100 \t Train Loss:0.2369 Valid Loss:0.4461 \t Train Acc:91.74 %  Valid Acc:86.75 %\n",
      "Epoch:43/100 \t Train Loss:0.2353 Valid Loss:0.4434 \t Train Acc:91.75 %  Valid Acc:86.53 %\n",
      "Epoch:44/100 \t Train Loss:0.2299 Valid Loss:0.4525 \t Train Acc:91.94 %  Valid Acc:86.74 %\n",
      "Epoch:45/100 \t Train Loss:0.2255 Valid Loss:0.4488 \t Train Acc:91.98 %  Valid Acc:86.65 %\n",
      "Epoch:46/100 \t Train Loss:0.2277 Valid Loss:0.4575 \t Train Acc:92.05 %  Valid Acc:86.25 %\n",
      "Epoch:47/100 \t Train Loss:0.2228 Valid Loss:0.4557 \t Train Acc:92.15 %  Valid Acc:86.44 %\n",
      "Epoch:48/100 \t Train Loss:0.2214 Valid Loss:0.4487 \t Train Acc:92.17 %  Valid Acc:86.58 %\n",
      "Epoch:49/100 \t Train Loss:0.2195 Valid Loss:0.4498 \t Train Acc:92.13 %  Valid Acc:86.75 %\n",
      "Epoch:50/100 \t Train Loss:0.2203 Valid Loss:0.4505 \t Train Acc:92.15 %  Valid Acc:86.53 %\n",
      "Epoch:51/100 \t Train Loss:0.2193 Valid Loss:0.4535 \t Train Acc:92.27 %  Valid Acc:86.65 %\n",
      "Epoch:52/100 \t Train Loss:0.2169 Valid Loss:0.4543 \t Train Acc:92.42 %  Valid Acc:86.72 %\n",
      "Epoch:53/100 \t Train Loss:0.2149 Valid Loss:0.4481 \t Train Acc:92.37 %  Valid Acc:86.75 %\n",
      "Epoch:54/100 \t Train Loss:0.2163 Valid Loss:0.4573 \t Train Acc:92.32 %  Valid Acc:86.76 %\n",
      "Epoch:55/100 \t Train Loss:0.2120 Valid Loss:0.4505 \t Train Acc:92.47 %  Valid Acc:86.83 %\n",
      "Epoch:56/100 \t Train Loss:0.2139 Valid Loss:0.4499 \t Train Acc:92.46 %  Valid Acc:86.76 %\n",
      "Epoch:57/100 \t Train Loss:0.2118 Valid Loss:0.4549 \t Train Acc:92.47 %  Valid Acc:86.59 %\n",
      "Epoch:58/100 \t Train Loss:0.2094 Valid Loss:0.4580 \t Train Acc:92.70 %  Valid Acc:86.59 %\n",
      "Epoch:59/100 \t Train Loss:0.2068 Valid Loss:0.4522 \t Train Acc:92.67 %  Valid Acc:86.72 %\n",
      "Epoch:60/100 \t Train Loss:0.2074 Valid Loss:0.4582 \t Train Acc:92.68 %  Valid Acc:86.78 %\n",
      "Epoch:61/100 \t Train Loss:0.1969 Valid Loss:0.4572 \t Train Acc:92.96 %  Valid Acc:86.82 %\n",
      "Epoch:62/100 \t Train Loss:0.1893 Valid Loss:0.4513 \t Train Acc:93.38 %  Valid Acc:87.03 %\n",
      "Epoch:63/100 \t Train Loss:0.1887 Valid Loss:0.4510 \t Train Acc:93.36 %  Valid Acc:87.00 %\n",
      "Epoch:64/100 \t Train Loss:0.1911 Valid Loss:0.4513 \t Train Acc:93.26 %  Valid Acc:86.79 %\n",
      "Epoch:65/100 \t Train Loss:0.1899 Valid Loss:0.4579 \t Train Acc:93.34 %  Valid Acc:86.78 %\n",
      "Epoch:66/100 \t Train Loss:0.1893 Valid Loss:0.4540 \t Train Acc:93.43 %  Valid Acc:87.04 %\n",
      "Epoch:67/100 \t Train Loss:0.1895 Valid Loss:0.4550 \t Train Acc:93.25 %  Valid Acc:87.16 %\n",
      "Epoch:68/100 \t Train Loss:0.1854 Valid Loss:0.4528 \t Train Acc:93.43 %  Valid Acc:87.16 %\n",
      "Epoch:69/100 \t Train Loss:0.1859 Valid Loss:0.4569 \t Train Acc:93.41 %  Valid Acc:87.01 %\n",
      "Epoch:70/100 \t Train Loss:0.1870 Valid Loss:0.4501 \t Train Acc:93.46 %  Valid Acc:87.04 %\n",
      "Epoch:71/100 \t Train Loss:0.1861 Valid Loss:0.4596 \t Train Acc:93.45 %  Valid Acc:87.02 %\n",
      "Epoch:72/100 \t Train Loss:0.1862 Valid Loss:0.4610 \t Train Acc:93.42 %  Valid Acc:86.98 %\n",
      "Epoch:73/100 \t Train Loss:0.1852 Valid Loss:0.4591 \t Train Acc:93.45 %  Valid Acc:87.12 %\n",
      "Epoch:74/100 \t Train Loss:0.1856 Valid Loss:0.4587 \t Train Acc:93.46 %  Valid Acc:86.96 %\n",
      "Epoch:75/100 \t Train Loss:0.1883 Valid Loss:0.4535 \t Train Acc:93.34 %  Valid Acc:86.88 %\n",
      "Epoch:76/100 \t Train Loss:0.1828 Valid Loss:0.4585 \t Train Acc:93.55 %  Valid Acc:87.10 %\n",
      "Epoch:77/100 \t Train Loss:0.1839 Valid Loss:0.4590 \t Train Acc:93.55 %  Valid Acc:86.95 %\n",
      "Epoch:78/100 \t Train Loss:0.1809 Valid Loss:0.4614 \t Train Acc:93.63 %  Valid Acc:87.16 %\n",
      "Epoch:79/100 \t Train Loss:0.1813 Valid Loss:0.4592 \t Train Acc:93.63 %  Valid Acc:86.96 %\n",
      "Epoch:80/100 \t Train Loss:0.1817 Valid Loss:0.4608 \t Train Acc:93.59 %  Valid Acc:86.75 %\n",
      "Epoch:81/100 \t Train Loss:0.1775 Valid Loss:0.4584 \t Train Acc:93.77 %  Valid Acc:86.90 %\n",
      "Epoch:82/100 \t Train Loss:0.1763 Valid Loss:0.4570 \t Train Acc:93.81 %  Valid Acc:86.96 %\n",
      "Epoch:83/100 \t Train Loss:0.1772 Valid Loss:0.4613 \t Train Acc:93.76 %  Valid Acc:86.70 %\n",
      "Epoch:84/100 \t Train Loss:0.1752 Valid Loss:0.4593 \t Train Acc:93.83 %  Valid Acc:87.03 %\n",
      "Epoch:85/100 \t Train Loss:0.1772 Valid Loss:0.4625 \t Train Acc:93.79 %  Valid Acc:86.88 %\n",
      "Epoch:86/100 \t Train Loss:0.1761 Valid Loss:0.4617 \t Train Acc:93.67 %  Valid Acc:86.87 %\n",
      "Epoch:87/100 \t Train Loss:0.1751 Valid Loss:0.4651 \t Train Acc:93.85 %  Valid Acc:86.77 %\n",
      "Epoch:88/100 \t Train Loss:0.1745 Valid Loss:0.4657 \t Train Acc:93.76 %  Valid Acc:86.86 %\n",
      "Epoch:89/100 \t Train Loss:0.1776 Valid Loss:0.4629 \t Train Acc:93.66 %  Valid Acc:86.98 %\n",
      "Epoch:90/100 \t Train Loss:0.1789 Valid Loss:0.4612 \t Train Acc:93.63 %  Valid Acc:86.99 %\n",
      "Epoch:91/100 \t Train Loss:0.1746 Valid Loss:0.4643 \t Train Acc:93.93 %  Valid Acc:86.84 %\n",
      "Epoch:92/100 \t Train Loss:0.1749 Valid Loss:0.4645 \t Train Acc:93.77 %  Valid Acc:86.85 %\n",
      "Epoch:93/100 \t Train Loss:0.1757 Valid Loss:0.4636 \t Train Acc:93.85 %  Valid Acc:87.12 %\n",
      "Epoch:94/100 \t Train Loss:0.1757 Valid Loss:0.4636 \t Train Acc:93.74 %  Valid Acc:86.91 %\n",
      "Epoch:95/100 \t Train Loss:0.1712 Valid Loss:0.4637 \t Train Acc:93.93 %  Valid Acc:86.96 %\n",
      "Epoch:96/100 \t Train Loss:0.1741 Valid Loss:0.4660 \t Train Acc:93.82 %  Valid Acc:86.72 %\n",
      "Epoch:97/100 \t Train Loss:0.1743 Valid Loss:0.4669 \t Train Acc:93.83 %  Valid Acc:86.71 %\n",
      "Epoch:98/100 \t Train Loss:0.1735 Valid Loss:0.4660 \t Train Acc:93.90 %  Valid Acc:86.91 %\n",
      "Epoch:99/100 \t Train Loss:0.1742 Valid Loss:0.4651 \t Train Acc:93.83 %  Valid Acc:86.96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 02:48:33,779] Trial 10 finished with value: 86.97 and parameters: {'sigma_1': 0.10754174896682223, 'sigma_2': 3.4804878551667167, 'sigma_3': 4.829826554360956, 'sigma_4': 1.0477192242102458, 'sigma_5': 4.839545942157102, 'sigma_6': 3.4108209572518637, 'sigma_7': 1.714934236387204, 'sigma_8': 3.4772880105979844, 'sigma_9': 0.11434744187053658, 'sigma_10': 3.013075176454797, 'sigma_11': 4.973529975707915, 'sigma_12': 0.2753829696202015, 'sigma_13': 0.2597250026854613}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1724 Valid Loss:0.4677 \t Train Acc:93.90 %  Valid Acc:86.97 %\n",
      "Epoch:1/100 \t Train Loss:1.4752 Valid Loss:1.5345 \t Train Acc:45.76 %  Valid Acc:46.02 %\n",
      "Epoch:2/100 \t Train Loss:1.1533 Valid Loss:1.1236 \t Train Acc:58.47 %  Valid Acc:61.16 %\n",
      "Epoch:3/100 \t Train Loss:1.0330 Valid Loss:0.9961 \t Train Acc:63.17 %  Valid Acc:65.09 %\n",
      "Epoch:4/100 \t Train Loss:0.9352 Valid Loss:0.8618 \t Train Acc:66.37 %  Valid Acc:69.89 %\n",
      "Epoch:5/100 \t Train Loss:0.8424 Valid Loss:0.8102 \t Train Acc:70.03 %  Valid Acc:71.68 %\n",
      "Epoch:6/100 \t Train Loss:0.7799 Valid Loss:0.7653 \t Train Acc:72.48 %  Valid Acc:72.85 %\n",
      "Epoch:7/100 \t Train Loss:0.7343 Valid Loss:0.7176 \t Train Acc:74.34 %  Valid Acc:75.45 %\n",
      "Epoch:8/100 \t Train Loss:0.6905 Valid Loss:0.7009 \t Train Acc:75.77 %  Valid Acc:75.98 %\n",
      "Epoch:9/100 \t Train Loss:0.6587 Valid Loss:0.6570 \t Train Acc:77.03 %  Valid Acc:77.20 %\n",
      "Epoch:10/100 \t Train Loss:0.6216 Valid Loss:0.6399 \t Train Acc:78.20 %  Valid Acc:78.25 %\n",
      "Epoch:11/100 \t Train Loss:0.5938 Valid Loss:0.6541 \t Train Acc:79.33 %  Valid Acc:77.93 %\n",
      "Epoch:12/100 \t Train Loss:0.5703 Valid Loss:0.5982 \t Train Acc:80.09 %  Valid Acc:79.37 %\n",
      "Epoch:13/100 \t Train Loss:0.5452 Valid Loss:0.5669 \t Train Acc:80.96 %  Valid Acc:81.05 %\n",
      "Epoch:14/100 \t Train Loss:0.5290 Valid Loss:0.5799 \t Train Acc:81.45 %  Valid Acc:80.40 %\n",
      "Epoch:15/100 \t Train Loss:0.5131 Valid Loss:0.5904 \t Train Acc:82.14 %  Valid Acc:80.71 %\n",
      "Epoch:16/100 \t Train Loss:0.4932 Valid Loss:0.5604 \t Train Acc:82.86 %  Valid Acc:80.99 %\n",
      "Epoch:17/100 \t Train Loss:0.4786 Valid Loss:0.5338 \t Train Acc:83.24 %  Valid Acc:82.05 %\n",
      "Epoch:18/100 \t Train Loss:0.4652 Valid Loss:0.5170 \t Train Acc:83.86 %  Valid Acc:82.49 %\n",
      "Epoch:19/100 \t Train Loss:0.4529 Valid Loss:0.5330 \t Train Acc:84.31 %  Valid Acc:82.34 %\n",
      "Epoch:20/100 \t Train Loss:0.4438 Valid Loss:0.5075 \t Train Acc:84.49 %  Valid Acc:83.16 %\n",
      "Epoch:21/100 \t Train Loss:0.3625 Valid Loss:0.4504 \t Train Acc:87.32 %  Valid Acc:84.97 %\n",
      "Epoch:22/100 \t Train Loss:0.3466 Valid Loss:0.4510 \t Train Acc:87.94 %  Valid Acc:84.83 %\n",
      "Epoch:23/100 \t Train Loss:0.3319 Valid Loss:0.4642 \t Train Acc:88.45 %  Valid Acc:84.81 %\n",
      "Epoch:24/100 \t Train Loss:0.3244 Valid Loss:0.4402 \t Train Acc:88.58 %  Valid Acc:85.49 %\n",
      "Epoch:25/100 \t Train Loss:0.3180 Valid Loss:0.4720 \t Train Acc:88.99 %  Valid Acc:84.77 %\n",
      "Epoch:26/100 \t Train Loss:0.3106 Valid Loss:0.4473 \t Train Acc:89.18 %  Valid Acc:85.57 %\n",
      "Epoch:27/100 \t Train Loss:0.3056 Valid Loss:0.4627 \t Train Acc:89.40 %  Valid Acc:85.39 %\n",
      "Epoch:28/100 \t Train Loss:0.3026 Valid Loss:0.4325 \t Train Acc:89.39 %  Valid Acc:85.49 %\n",
      "Epoch:29/100 \t Train Loss:0.3013 Valid Loss:0.4494 \t Train Acc:89.25 %  Valid Acc:85.27 %\n",
      "Epoch:30/100 \t Train Loss:0.2925 Valid Loss:0.4574 \t Train Acc:89.68 %  Valid Acc:85.41 %\n",
      "Epoch:31/100 \t Train Loss:0.2898 Valid Loss:0.4447 \t Train Acc:89.84 %  Valid Acc:85.64 %\n",
      "Epoch:32/100 \t Train Loss:0.2841 Valid Loss:0.4496 \t Train Acc:89.90 %  Valid Acc:85.37 %\n",
      "Epoch:33/100 \t Train Loss:0.2798 Valid Loss:0.4623 \t Train Acc:90.13 %  Valid Acc:85.74 %\n",
      "Epoch:34/100 \t Train Loss:0.2722 Valid Loss:0.4539 \t Train Acc:90.36 %  Valid Acc:85.64 %\n",
      "Epoch:35/100 \t Train Loss:0.2714 Valid Loss:0.4413 \t Train Acc:90.34 %  Valid Acc:86.16 %\n",
      "Epoch:36/100 \t Train Loss:0.2704 Valid Loss:0.4396 \t Train Acc:90.35 %  Valid Acc:86.09 %\n",
      "Epoch:37/100 \t Train Loss:0.2644 Valid Loss:0.4636 \t Train Acc:90.69 %  Valid Acc:85.46 %\n",
      "Epoch:38/100 \t Train Loss:0.2612 Valid Loss:0.4365 \t Train Acc:90.72 %  Valid Acc:86.20 %\n",
      "Epoch:39/100 \t Train Loss:0.2601 Valid Loss:0.4395 \t Train Acc:90.97 %  Valid Acc:85.86 %\n",
      "Epoch:40/100 \t Train Loss:0.2539 Valid Loss:0.4486 \t Train Acc:91.01 %  Valid Acc:86.29 %\n",
      "Epoch:41/100 \t Train Loss:0.2276 Valid Loss:0.4468 \t Train Acc:91.96 %  Valid Acc:86.48 %\n",
      "Epoch:42/100 \t Train Loss:0.2178 Valid Loss:0.4369 \t Train Acc:92.40 %  Valid Acc:86.78 %\n",
      "Epoch:43/100 \t Train Loss:0.2161 Valid Loss:0.4458 \t Train Acc:92.28 %  Valid Acc:86.47 %\n",
      "Epoch:44/100 \t Train Loss:0.2106 Valid Loss:0.4473 \t Train Acc:92.53 %  Valid Acc:86.67 %\n",
      "Epoch:45/100 \t Train Loss:0.2090 Valid Loss:0.4403 \t Train Acc:92.65 %  Valid Acc:86.68 %\n",
      "Epoch:46/100 \t Train Loss:0.2081 Valid Loss:0.4478 \t Train Acc:92.55 %  Valid Acc:86.76 %\n",
      "Epoch:47/100 \t Train Loss:0.2049 Valid Loss:0.4416 \t Train Acc:92.80 %  Valid Acc:86.60 %\n",
      "Epoch:48/100 \t Train Loss:0.2044 Valid Loss:0.4529 \t Train Acc:92.81 %  Valid Acc:86.48 %\n",
      "Epoch:49/100 \t Train Loss:0.2020 Valid Loss:0.4469 \t Train Acc:92.89 %  Valid Acc:86.60 %\n",
      "Epoch:50/100 \t Train Loss:0.2018 Valid Loss:0.4467 \t Train Acc:92.87 %  Valid Acc:86.81 %\n",
      "Epoch:51/100 \t Train Loss:0.1997 Valid Loss:0.4558 \t Train Acc:92.84 %  Valid Acc:86.51 %\n",
      "Epoch:52/100 \t Train Loss:0.1975 Valid Loss:0.4494 \t Train Acc:92.89 %  Valid Acc:86.50 %\n",
      "Epoch:53/100 \t Train Loss:0.1966 Valid Loss:0.4473 \t Train Acc:93.02 %  Valid Acc:86.92 %\n",
      "Epoch:54/100 \t Train Loss:0.1933 Valid Loss:0.4524 \t Train Acc:93.17 %  Valid Acc:86.95 %\n",
      "Epoch:55/100 \t Train Loss:0.1959 Valid Loss:0.4411 \t Train Acc:93.01 %  Valid Acc:87.12 %\n",
      "Epoch:56/100 \t Train Loss:0.1941 Valid Loss:0.4469 \t Train Acc:93.07 %  Valid Acc:86.74 %\n",
      "Epoch:57/100 \t Train Loss:0.1937 Valid Loss:0.4528 \t Train Acc:93.09 %  Valid Acc:86.83 %\n",
      "Epoch:58/100 \t Train Loss:0.1908 Valid Loss:0.4510 \t Train Acc:93.26 %  Valid Acc:86.77 %\n",
      "Epoch:59/100 \t Train Loss:0.1903 Valid Loss:0.4453 \t Train Acc:93.20 %  Valid Acc:86.82 %\n",
      "Epoch:60/100 \t Train Loss:0.1912 Valid Loss:0.4576 \t Train Acc:93.15 %  Valid Acc:86.66 %\n",
      "Epoch:61/100 \t Train Loss:0.1762 Valid Loss:0.4544 \t Train Acc:93.81 %  Valid Acc:86.92 %\n",
      "Epoch:62/100 \t Train Loss:0.1738 Valid Loss:0.4557 \t Train Acc:93.93 %  Valid Acc:86.88 %\n",
      "Epoch:63/100 \t Train Loss:0.1763 Valid Loss:0.4503 \t Train Acc:93.77 %  Valid Acc:86.93 %\n",
      "Epoch:64/100 \t Train Loss:0.1735 Valid Loss:0.4593 \t Train Acc:93.83 %  Valid Acc:86.96 %\n",
      "Epoch:65/100 \t Train Loss:0.1724 Valid Loss:0.4584 \t Train Acc:93.93 %  Valid Acc:86.88 %\n",
      "Epoch:66/100 \t Train Loss:0.1737 Valid Loss:0.4565 \t Train Acc:93.89 %  Valid Acc:87.02 %\n",
      "Epoch:67/100 \t Train Loss:0.1704 Valid Loss:0.4610 \t Train Acc:93.94 %  Valid Acc:87.03 %\n",
      "Epoch:68/100 \t Train Loss:0.1701 Valid Loss:0.4631 \t Train Acc:94.04 %  Valid Acc:86.81 %\n",
      "Epoch:69/100 \t Train Loss:0.1695 Valid Loss:0.4693 \t Train Acc:94.09 %  Valid Acc:86.75 %\n",
      "Epoch:70/100 \t Train Loss:0.1704 Valid Loss:0.4657 \t Train Acc:94.00 %  Valid Acc:86.79 %\n",
      "Epoch:71/100 \t Train Loss:0.1685 Valid Loss:0.4642 \t Train Acc:94.04 %  Valid Acc:86.96 %\n",
      "Epoch:72/100 \t Train Loss:0.1679 Valid Loss:0.4629 \t Train Acc:94.14 %  Valid Acc:86.87 %\n",
      "Epoch:73/100 \t Train Loss:0.1676 Valid Loss:0.4626 \t Train Acc:94.15 %  Valid Acc:86.96 %\n",
      "Epoch:74/100 \t Train Loss:0.1693 Valid Loss:0.4670 \t Train Acc:93.97 %  Valid Acc:86.93 %\n",
      "Epoch:75/100 \t Train Loss:0.1655 Valid Loss:0.4675 \t Train Acc:94.20 %  Valid Acc:86.80 %\n",
      "Epoch:76/100 \t Train Loss:0.1663 Valid Loss:0.4677 \t Train Acc:94.13 %  Valid Acc:87.00 %\n",
      "Epoch:77/100 \t Train Loss:0.1670 Valid Loss:0.4658 \t Train Acc:94.09 %  Valid Acc:86.98 %\n",
      "Epoch:78/100 \t Train Loss:0.1643 Valid Loss:0.4689 \t Train Acc:94.19 %  Valid Acc:87.01 %\n",
      "Epoch:79/100 \t Train Loss:0.1645 Valid Loss:0.4673 \t Train Acc:94.17 %  Valid Acc:86.88 %\n",
      "Epoch:80/100 \t Train Loss:0.1671 Valid Loss:0.4641 \t Train Acc:94.07 %  Valid Acc:86.86 %\n",
      "Epoch:81/100 \t Train Loss:0.1604 Valid Loss:0.4653 \t Train Acc:94.35 %  Valid Acc:86.81 %\n",
      "Epoch:82/100 \t Train Loss:0.1621 Valid Loss:0.4654 \t Train Acc:94.29 %  Valid Acc:86.85 %\n",
      "Epoch:83/100 \t Train Loss:0.1626 Valid Loss:0.4684 \t Train Acc:94.27 %  Valid Acc:86.89 %\n",
      "Epoch:84/100 \t Train Loss:0.1572 Valid Loss:0.4691 \t Train Acc:94.47 %  Valid Acc:86.89 %\n",
      "Epoch:85/100 \t Train Loss:0.1607 Valid Loss:0.4661 \t Train Acc:94.34 %  Valid Acc:86.95 %\n",
      "Epoch:86/100 \t Train Loss:0.1579 Valid Loss:0.4696 \t Train Acc:94.43 %  Valid Acc:86.86 %\n",
      "Epoch:87/100 \t Train Loss:0.1584 Valid Loss:0.4683 \t Train Acc:94.29 %  Valid Acc:86.89 %\n",
      "Epoch:88/100 \t Train Loss:0.1582 Valid Loss:0.4682 \t Train Acc:94.38 %  Valid Acc:86.90 %\n",
      "Epoch:89/100 \t Train Loss:0.1559 Valid Loss:0.4718 \t Train Acc:94.51 %  Valid Acc:86.87 %\n",
      "Epoch:90/100 \t Train Loss:0.1574 Valid Loss:0.4699 \t Train Acc:94.43 %  Valid Acc:86.74 %\n",
      "Epoch:91/100 \t Train Loss:0.1568 Valid Loss:0.4699 \t Train Acc:94.48 %  Valid Acc:86.75 %\n",
      "Epoch:92/100 \t Train Loss:0.1571 Valid Loss:0.4704 \t Train Acc:94.38 %  Valid Acc:86.80 %\n",
      "Epoch:93/100 \t Train Loss:0.1579 Valid Loss:0.4715 \t Train Acc:94.42 %  Valid Acc:86.96 %\n",
      "Epoch:94/100 \t Train Loss:0.1579 Valid Loss:0.4716 \t Train Acc:94.44 %  Valid Acc:86.84 %\n",
      "Epoch:95/100 \t Train Loss:0.1560 Valid Loss:0.4719 \t Train Acc:94.58 %  Valid Acc:86.86 %\n",
      "Epoch:96/100 \t Train Loss:0.1586 Valid Loss:0.4724 \t Train Acc:94.37 %  Valid Acc:86.81 %\n",
      "Epoch:97/100 \t Train Loss:0.1579 Valid Loss:0.4718 \t Train Acc:94.43 %  Valid Acc:86.79 %\n",
      "Epoch:98/100 \t Train Loss:0.1556 Valid Loss:0.4730 \t Train Acc:94.47 %  Valid Acc:86.83 %\n",
      "Epoch:99/100 \t Train Loss:0.1571 Valid Loss:0.4723 \t Train Acc:94.44 %  Valid Acc:86.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 04:08:34,136] Trial 11 finished with value: 86.86 and parameters: {'sigma_1': 0.27388842055938856, 'sigma_2': 0.1519871740631049, 'sigma_3': 4.944184946101624, 'sigma_4': 0.37863275756226267, 'sigma_5': 3.8877633657711472, 'sigma_6': 0.3811367013011917, 'sigma_7': 1.6838497573358109, 'sigma_8': 3.696678001336503, 'sigma_9': 0.9805643942456987, 'sigma_10': 1.062167524794611, 'sigma_11': 3.5660801221024783, 'sigma_12': 2.164360014259923, 'sigma_13': 1.6026960275276965}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1587 Valid Loss:0.4712 \t Train Acc:94.42 %  Valid Acc:86.86 %\n",
      "Epoch:1/100 \t Train Loss:1.4678 Valid Loss:1.2527 \t Train Acc:46.06 %  Valid Acc:54.75 %\n",
      "Epoch:2/100 \t Train Loss:1.2058 Valid Loss:1.0722 \t Train Acc:56.45 %  Valid Acc:61.94 %\n",
      "Epoch:3/100 \t Train Loss:1.0742 Valid Loss:1.0181 \t Train Acc:61.39 %  Valid Acc:63.83 %\n",
      "Epoch:4/100 \t Train Loss:0.9881 Valid Loss:0.9395 \t Train Acc:64.54 %  Valid Acc:66.63 %\n",
      "Epoch:5/100 \t Train Loss:0.9066 Valid Loss:0.9200 \t Train Acc:67.80 %  Valid Acc:67.98 %\n",
      "Epoch:6/100 \t Train Loss:0.8316 Valid Loss:0.8175 \t Train Acc:70.19 %  Valid Acc:71.25 %\n",
      "Epoch:7/100 \t Train Loss:0.7677 Valid Loss:0.7367 \t Train Acc:72.88 %  Valid Acc:74.01 %\n",
      "Epoch:8/100 \t Train Loss:0.7214 Valid Loss:0.7632 \t Train Acc:74.59 %  Valid Acc:74.01 %\n",
      "Epoch:9/100 \t Train Loss:0.6784 Valid Loss:0.6723 \t Train Acc:76.17 %  Valid Acc:77.24 %\n",
      "Epoch:10/100 \t Train Loss:0.6433 Valid Loss:0.6711 \t Train Acc:77.66 %  Valid Acc:77.44 %\n",
      "Epoch:11/100 \t Train Loss:0.6111 Valid Loss:0.6226 \t Train Acc:78.68 %  Valid Acc:78.49 %\n",
      "Epoch:12/100 \t Train Loss:0.5851 Valid Loss:0.6063 \t Train Acc:79.56 %  Valid Acc:79.50 %\n",
      "Epoch:13/100 \t Train Loss:0.5581 Valid Loss:0.6025 \t Train Acc:80.77 %  Valid Acc:79.51 %\n",
      "Epoch:14/100 \t Train Loss:0.5415 Valid Loss:0.5771 \t Train Acc:81.06 %  Valid Acc:80.34 %\n",
      "Epoch:15/100 \t Train Loss:0.5269 Valid Loss:0.5583 \t Train Acc:81.49 %  Valid Acc:81.13 %\n",
      "Epoch:16/100 \t Train Loss:0.5090 Valid Loss:0.5598 \t Train Acc:82.31 %  Valid Acc:81.21 %\n",
      "Epoch:17/100 \t Train Loss:0.4885 Valid Loss:0.5335 \t Train Acc:83.05 %  Valid Acc:81.72 %\n",
      "Epoch:18/100 \t Train Loss:0.4798 Valid Loss:0.5108 \t Train Acc:83.26 %  Valid Acc:82.05 %\n",
      "Epoch:19/100 \t Train Loss:0.4622 Valid Loss:0.5673 \t Train Acc:83.90 %  Valid Acc:81.46 %\n",
      "Epoch:20/100 \t Train Loss:0.4538 Valid Loss:0.5297 \t Train Acc:84.13 %  Valid Acc:82.77 %\n",
      "Epoch:21/100 \t Train Loss:0.3699 Valid Loss:0.4616 \t Train Acc:87.01 %  Valid Acc:84.73 %\n",
      "Epoch:22/100 \t Train Loss:0.3562 Valid Loss:0.4543 \t Train Acc:87.66 %  Valid Acc:84.87 %\n",
      "Epoch:23/100 \t Train Loss:0.3441 Valid Loss:0.4579 \t Train Acc:87.90 %  Valid Acc:84.76 %\n",
      "Epoch:24/100 \t Train Loss:0.3381 Valid Loss:0.4587 \t Train Acc:88.11 %  Valid Acc:84.93 %\n",
      "Epoch:25/100 \t Train Loss:0.3295 Valid Loss:0.4623 \t Train Acc:88.55 %  Valid Acc:85.11 %\n",
      "Epoch:26/100 \t Train Loss:0.3279 Valid Loss:0.4510 \t Train Acc:88.39 %  Valid Acc:85.60 %\n",
      "Epoch:27/100 \t Train Loss:0.3201 Valid Loss:0.4612 \t Train Acc:88.86 %  Valid Acc:85.10 %\n",
      "Epoch:28/100 \t Train Loss:0.3113 Valid Loss:0.4613 \t Train Acc:89.14 %  Valid Acc:85.22 %\n",
      "Epoch:29/100 \t Train Loss:0.3113 Valid Loss:0.4635 \t Train Acc:89.03 %  Valid Acc:85.34 %\n",
      "Epoch:30/100 \t Train Loss:0.3088 Valid Loss:0.4631 \t Train Acc:89.13 %  Valid Acc:84.92 %\n",
      "Epoch:31/100 \t Train Loss:0.3004 Valid Loss:0.4408 \t Train Acc:89.37 %  Valid Acc:85.80 %\n",
      "Epoch:32/100 \t Train Loss:0.2967 Valid Loss:0.4503 \t Train Acc:89.67 %  Valid Acc:85.49 %\n",
      "Epoch:33/100 \t Train Loss:0.2957 Valid Loss:0.4531 \t Train Acc:89.53 %  Valid Acc:85.56 %\n",
      "Epoch:34/100 \t Train Loss:0.2919 Valid Loss:0.4493 \t Train Acc:89.63 %  Valid Acc:85.59 %\n",
      "Epoch:35/100 \t Train Loss:0.2851 Valid Loss:0.4661 \t Train Acc:89.97 %  Valid Acc:85.41 %\n",
      "Epoch:36/100 \t Train Loss:0.2832 Valid Loss:0.4537 \t Train Acc:90.03 %  Valid Acc:85.82 %\n",
      "Epoch:37/100 \t Train Loss:0.2829 Valid Loss:0.4563 \t Train Acc:89.84 %  Valid Acc:85.69 %\n",
      "Epoch:38/100 \t Train Loss:0.2761 Valid Loss:0.4496 \t Train Acc:90.19 %  Valid Acc:86.02 %\n",
      "Epoch:39/100 \t Train Loss:0.2742 Valid Loss:0.4507 \t Train Acc:90.37 %  Valid Acc:85.95 %\n",
      "Epoch:40/100 \t Train Loss:0.2708 Valid Loss:0.4562 \t Train Acc:90.28 %  Valid Acc:85.88 %\n",
      "Epoch:41/100 \t Train Loss:0.2408 Valid Loss:0.4438 \t Train Acc:91.58 %  Valid Acc:86.25 %\n",
      "Epoch:42/100 \t Train Loss:0.2323 Valid Loss:0.4450 \t Train Acc:91.79 %  Valid Acc:86.63 %\n",
      "Epoch:43/100 \t Train Loss:0.2303 Valid Loss:0.4502 \t Train Acc:91.88 %  Valid Acc:86.52 %\n",
      "Epoch:44/100 \t Train Loss:0.2291 Valid Loss:0.4489 \t Train Acc:91.84 %  Valid Acc:86.77 %\n",
      "Epoch:45/100 \t Train Loss:0.2239 Valid Loss:0.4511 \t Train Acc:92.07 %  Valid Acc:86.43 %\n",
      "Epoch:46/100 \t Train Loss:0.2236 Valid Loss:0.4412 \t Train Acc:92.02 %  Valid Acc:87.01 %\n",
      "Epoch:47/100 \t Train Loss:0.2216 Valid Loss:0.4581 \t Train Acc:92.26 %  Valid Acc:86.29 %\n",
      "Epoch:48/100 \t Train Loss:0.2193 Valid Loss:0.4515 \t Train Acc:92.27 %  Valid Acc:86.95 %\n",
      "Epoch:49/100 \t Train Loss:0.2188 Valid Loss:0.4556 \t Train Acc:92.26 %  Valid Acc:86.53 %\n",
      "Epoch:50/100 \t Train Loss:0.2160 Valid Loss:0.4578 \t Train Acc:92.26 %  Valid Acc:86.51 %\n",
      "Epoch:51/100 \t Train Loss:0.2183 Valid Loss:0.4556 \t Train Acc:92.25 %  Valid Acc:86.50 %\n",
      "Epoch:52/100 \t Train Loss:0.2151 Valid Loss:0.4541 \t Train Acc:92.50 %  Valid Acc:86.60 %\n",
      "Epoch:53/100 \t Train Loss:0.2152 Valid Loss:0.4537 \t Train Acc:92.40 %  Valid Acc:86.62 %\n",
      "Epoch:54/100 \t Train Loss:0.2118 Valid Loss:0.4547 \t Train Acc:92.54 %  Valid Acc:86.66 %\n",
      "Epoch:55/100 \t Train Loss:0.2128 Valid Loss:0.4548 \t Train Acc:92.43 %  Valid Acc:86.76 %\n",
      "Epoch:56/100 \t Train Loss:0.2092 Valid Loss:0.4617 \t Train Acc:92.50 %  Valid Acc:86.66 %\n",
      "Epoch:57/100 \t Train Loss:0.2080 Valid Loss:0.4652 \t Train Acc:92.65 %  Valid Acc:86.39 %\n",
      "Epoch:58/100 \t Train Loss:0.2077 Valid Loss:0.4664 \t Train Acc:92.69 %  Valid Acc:86.60 %\n",
      "Epoch:59/100 \t Train Loss:0.2055 Valid Loss:0.4618 \t Train Acc:92.73 %  Valid Acc:86.57 %\n",
      "Epoch:60/100 \t Train Loss:0.2037 Valid Loss:0.4542 \t Train Acc:92.84 %  Valid Acc:86.70 %\n",
      "Epoch:61/100 \t Train Loss:0.1928 Valid Loss:0.4542 \t Train Acc:93.19 %  Valid Acc:86.88 %\n",
      "Epoch:62/100 \t Train Loss:0.1913 Valid Loss:0.4579 \t Train Acc:93.25 %  Valid Acc:86.96 %\n",
      "Epoch:63/100 \t Train Loss:0.1916 Valid Loss:0.4596 \t Train Acc:93.21 %  Valid Acc:87.10 %\n",
      "Epoch:64/100 \t Train Loss:0.1871 Valid Loss:0.4611 \t Train Acc:93.39 %  Valid Acc:86.95 %\n",
      "Epoch:65/100 \t Train Loss:0.1900 Valid Loss:0.4572 \t Train Acc:93.13 %  Valid Acc:86.98 %\n",
      "Epoch:66/100 \t Train Loss:0.1898 Valid Loss:0.4593 \t Train Acc:93.10 %  Valid Acc:86.94 %\n",
      "Epoch:67/100 \t Train Loss:0.1885 Valid Loss:0.4580 \t Train Acc:93.32 %  Valid Acc:87.04 %\n",
      "Epoch:68/100 \t Train Loss:0.1870 Valid Loss:0.4599 \t Train Acc:93.42 %  Valid Acc:86.93 %\n",
      "Epoch:69/100 \t Train Loss:0.1868 Valid Loss:0.4665 \t Train Acc:93.39 %  Valid Acc:86.75 %\n",
      "Epoch:70/100 \t Train Loss:0.1858 Valid Loss:0.4659 \t Train Acc:93.40 %  Valid Acc:86.84 %\n",
      "Epoch:71/100 \t Train Loss:0.1837 Valid Loss:0.4652 \t Train Acc:93.40 %  Valid Acc:86.98 %\n",
      "Epoch:72/100 \t Train Loss:0.1850 Valid Loss:0.4622 \t Train Acc:93.43 %  Valid Acc:87.01 %\n",
      "Epoch:73/100 \t Train Loss:0.1846 Valid Loss:0.4633 \t Train Acc:93.44 %  Valid Acc:87.01 %\n",
      "Epoch:74/100 \t Train Loss:0.1863 Valid Loss:0.4679 \t Train Acc:93.36 %  Valid Acc:86.98 %\n",
      "Epoch:75/100 \t Train Loss:0.1841 Valid Loss:0.4639 \t Train Acc:93.50 %  Valid Acc:87.05 %\n",
      "Epoch:76/100 \t Train Loss:0.1805 Valid Loss:0.4718 \t Train Acc:93.72 %  Valid Acc:86.91 %\n",
      "Epoch:77/100 \t Train Loss:0.1831 Valid Loss:0.4719 \t Train Acc:93.58 %  Valid Acc:86.79 %\n",
      "Epoch:78/100 \t Train Loss:0.1816 Valid Loss:0.4709 \t Train Acc:93.54 %  Valid Acc:86.82 %\n",
      "Epoch:79/100 \t Train Loss:0.1825 Valid Loss:0.4696 \t Train Acc:93.54 %  Valid Acc:86.90 %\n",
      "Epoch:80/100 \t Train Loss:0.1821 Valid Loss:0.4714 \t Train Acc:93.60 %  Valid Acc:86.97 %\n",
      "Epoch:81/100 \t Train Loss:0.1766 Valid Loss:0.4711 \t Train Acc:93.71 %  Valid Acc:86.97 %\n",
      "Epoch:82/100 \t Train Loss:0.1777 Valid Loss:0.4692 \t Train Acc:93.58 %  Valid Acc:86.90 %\n",
      "Epoch:83/100 \t Train Loss:0.1759 Valid Loss:0.4703 \t Train Acc:93.72 %  Valid Acc:87.03 %\n",
      "Epoch:84/100 \t Train Loss:0.1777 Valid Loss:0.4712 \t Train Acc:93.68 %  Valid Acc:86.98 %\n",
      "Epoch:85/100 \t Train Loss:0.1758 Valid Loss:0.4728 \t Train Acc:93.78 %  Valid Acc:87.02 %\n",
      "Epoch:86/100 \t Train Loss:0.1748 Valid Loss:0.4717 \t Train Acc:93.80 %  Valid Acc:86.91 %\n",
      "Epoch:87/100 \t Train Loss:0.1754 Valid Loss:0.4724 \t Train Acc:93.71 %  Valid Acc:86.93 %\n",
      "Epoch:88/100 \t Train Loss:0.1736 Valid Loss:0.4725 \t Train Acc:93.84 %  Valid Acc:87.03 %\n",
      "Epoch:89/100 \t Train Loss:0.1744 Valid Loss:0.4740 \t Train Acc:93.87 %  Valid Acc:87.00 %\n",
      "Epoch:90/100 \t Train Loss:0.1773 Valid Loss:0.4716 \t Train Acc:93.78 %  Valid Acc:87.01 %\n",
      "Epoch:91/100 \t Train Loss:0.1740 Valid Loss:0.4742 \t Train Acc:93.89 %  Valid Acc:86.92 %\n",
      "Epoch:92/100 \t Train Loss:0.1767 Valid Loss:0.4720 \t Train Acc:93.73 %  Valid Acc:87.05 %\n",
      "Epoch:93/100 \t Train Loss:0.1731 Valid Loss:0.4740 \t Train Acc:93.84 %  Valid Acc:86.97 %\n",
      "Epoch:94/100 \t Train Loss:0.1727 Valid Loss:0.4748 \t Train Acc:93.91 %  Valid Acc:87.03 %\n",
      "Epoch:95/100 \t Train Loss:0.1705 Valid Loss:0.4760 \t Train Acc:93.98 %  Valid Acc:86.98 %\n",
      "Epoch:96/100 \t Train Loss:0.1737 Valid Loss:0.4763 \t Train Acc:93.82 %  Valid Acc:86.92 %\n",
      "Epoch:97/100 \t Train Loss:0.1749 Valid Loss:0.4761 \t Train Acc:93.82 %  Valid Acc:87.03 %\n",
      "Epoch:98/100 \t Train Loss:0.1728 Valid Loss:0.4770 \t Train Acc:93.95 %  Valid Acc:86.96 %\n",
      "Epoch:99/100 \t Train Loss:0.1713 Valid Loss:0.4778 \t Train Acc:94.01 %  Valid Acc:86.92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 05:28:25,667] Trial 12 finished with value: 87.05000000000001 and parameters: {'sigma_1': 0.8383226645311572, 'sigma_2': 1.9454581115604253, 'sigma_3': 3.864009497737176, 'sigma_4': 1.2707155285857872, 'sigma_5': 2.4604574130094385, 'sigma_6': 0.18211203647842256, 'sigma_7': 0.12755052573941716, 'sigma_8': 3.8260252972459066, 'sigma_9': 3.2651795320789843, 'sigma_10': 3.2408769400222033, 'sigma_11': 3.594316521204685, 'sigma_12': 1.2846473844907573, 'sigma_13': 1.9464845496243162}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1737 Valid Loss:0.4746 \t Train Acc:93.90 %  Valid Acc:87.05 %\n",
      "Epoch:1/100 \t Train Loss:1.5387 Valid Loss:1.3867 \t Train Acc:43.12 %  Valid Acc:50.65 %\n",
      "Epoch:2/100 \t Train Loss:1.1639 Valid Loss:1.0073 \t Train Acc:58.20 %  Valid Acc:63.06 %\n",
      "Epoch:3/100 \t Train Loss:1.0148 Valid Loss:0.9921 \t Train Acc:63.75 %  Valid Acc:63.65 %\n",
      "Epoch:4/100 \t Train Loss:0.9201 Valid Loss:0.8979 \t Train Acc:67.20 %  Valid Acc:68.31 %\n",
      "Epoch:5/100 \t Train Loss:0.8383 Valid Loss:0.8018 \t Train Acc:70.25 %  Valid Acc:71.27 %\n",
      "Epoch:6/100 \t Train Loss:0.7720 Valid Loss:0.7559 \t Train Acc:72.75 %  Valid Acc:73.11 %\n",
      "Epoch:7/100 \t Train Loss:0.7146 Valid Loss:0.7005 \t Train Acc:74.88 %  Valid Acc:75.85 %\n",
      "Epoch:8/100 \t Train Loss:0.6774 Valid Loss:0.6740 \t Train Acc:76.24 %  Valid Acc:77.08 %\n",
      "Epoch:9/100 \t Train Loss:0.6443 Valid Loss:0.6341 \t Train Acc:77.49 %  Valid Acc:77.87 %\n",
      "Epoch:10/100 \t Train Loss:0.6132 Valid Loss:0.6338 \t Train Acc:78.63 %  Valid Acc:77.73 %\n",
      "Epoch:11/100 \t Train Loss:0.5884 Valid Loss:0.5916 \t Train Acc:79.61 %  Valid Acc:79.71 %\n",
      "Epoch:12/100 \t Train Loss:0.5569 Valid Loss:0.5801 \t Train Acc:80.67 %  Valid Acc:80.48 %\n",
      "Epoch:13/100 \t Train Loss:0.5365 Valid Loss:0.5626 \t Train Acc:81.35 %  Valid Acc:81.00 %\n",
      "Epoch:14/100 \t Train Loss:0.5203 Valid Loss:0.5501 \t Train Acc:81.95 %  Valid Acc:81.30 %\n",
      "Epoch:15/100 \t Train Loss:0.5012 Valid Loss:0.5487 \t Train Acc:82.72 %  Valid Acc:81.28 %\n",
      "Epoch:16/100 \t Train Loss:0.4841 Valid Loss:0.5561 \t Train Acc:83.21 %  Valid Acc:81.63 %\n",
      "Epoch:17/100 \t Train Loss:0.4731 Valid Loss:0.5215 \t Train Acc:83.56 %  Valid Acc:82.55 %\n",
      "Epoch:18/100 \t Train Loss:0.4639 Valid Loss:0.5279 \t Train Acc:84.01 %  Valid Acc:82.63 %\n",
      "Epoch:19/100 \t Train Loss:0.4424 Valid Loss:0.5912 \t Train Acc:84.53 %  Valid Acc:80.89 %\n",
      "Epoch:20/100 \t Train Loss:0.4414 Valid Loss:0.5385 \t Train Acc:84.73 %  Valid Acc:81.96 %\n",
      "Epoch:21/100 \t Train Loss:0.3546 Valid Loss:0.4437 \t Train Acc:87.71 %  Valid Acc:85.57 %\n",
      "Epoch:22/100 \t Train Loss:0.3351 Valid Loss:0.4445 \t Train Acc:88.30 %  Valid Acc:85.73 %\n",
      "Epoch:23/100 \t Train Loss:0.3267 Valid Loss:0.4425 \t Train Acc:88.76 %  Valid Acc:85.55 %\n",
      "Epoch:24/100 \t Train Loss:0.3182 Valid Loss:0.4500 \t Train Acc:88.94 %  Valid Acc:85.61 %\n",
      "Epoch:25/100 \t Train Loss:0.3120 Valid Loss:0.4311 \t Train Acc:89.13 %  Valid Acc:86.26 %\n",
      "Epoch:26/100 \t Train Loss:0.3080 Valid Loss:0.4251 \t Train Acc:89.17 %  Valid Acc:86.21 %\n",
      "Epoch:27/100 \t Train Loss:0.3003 Valid Loss:0.4608 \t Train Acc:89.43 %  Valid Acc:85.27 %\n",
      "Epoch:28/100 \t Train Loss:0.3001 Valid Loss:0.4407 \t Train Acc:89.54 %  Valid Acc:85.91 %\n",
      "Epoch:29/100 \t Train Loss:0.2930 Valid Loss:0.4341 \t Train Acc:89.70 %  Valid Acc:86.08 %\n",
      "Epoch:30/100 \t Train Loss:0.2868 Valid Loss:0.4551 \t Train Acc:89.88 %  Valid Acc:85.49 %\n",
      "Epoch:31/100 \t Train Loss:0.2850 Valid Loss:0.4362 \t Train Acc:89.92 %  Valid Acc:86.19 %\n",
      "Epoch:32/100 \t Train Loss:0.2806 Valid Loss:0.4366 \t Train Acc:90.14 %  Valid Acc:86.35 %\n",
      "Epoch:33/100 \t Train Loss:0.2746 Valid Loss:0.4459 \t Train Acc:90.36 %  Valid Acc:86.30 %\n",
      "Epoch:34/100 \t Train Loss:0.2754 Valid Loss:0.4436 \t Train Acc:90.31 %  Valid Acc:85.88 %\n",
      "Epoch:35/100 \t Train Loss:0.2703 Valid Loss:0.4433 \t Train Acc:90.48 %  Valid Acc:86.17 %\n",
      "Epoch:36/100 \t Train Loss:0.2679 Valid Loss:0.4287 \t Train Acc:90.50 %  Valid Acc:86.49 %\n",
      "Epoch:37/100 \t Train Loss:0.2617 Valid Loss:0.4682 \t Train Acc:90.93 %  Valid Acc:85.68 %\n",
      "Epoch:38/100 \t Train Loss:0.2600 Valid Loss:0.4528 \t Train Acc:90.84 %  Valid Acc:86.15 %\n",
      "Epoch:39/100 \t Train Loss:0.2551 Valid Loss:0.4328 \t Train Acc:91.01 %  Valid Acc:86.71 %\n",
      "Epoch:40/100 \t Train Loss:0.2570 Valid Loss:0.4500 \t Train Acc:90.93 %  Valid Acc:85.86 %\n",
      "Epoch:41/100 \t Train Loss:0.2218 Valid Loss:0.4365 \t Train Acc:92.25 %  Valid Acc:86.87 %\n",
      "Epoch:42/100 \t Train Loss:0.2172 Valid Loss:0.4351 \t Train Acc:92.29 %  Valid Acc:86.74 %\n",
      "Epoch:43/100 \t Train Loss:0.2132 Valid Loss:0.4379 \t Train Acc:92.54 %  Valid Acc:86.77 %\n",
      "Epoch:44/100 \t Train Loss:0.2102 Valid Loss:0.4418 \t Train Acc:92.47 %  Valid Acc:87.05 %\n",
      "Epoch:45/100 \t Train Loss:0.2058 Valid Loss:0.4353 \t Train Acc:92.61 %  Valid Acc:86.61 %\n",
      "Epoch:46/100 \t Train Loss:0.2051 Valid Loss:0.4444 \t Train Acc:92.65 %  Valid Acc:86.71 %\n",
      "Epoch:47/100 \t Train Loss:0.2059 Valid Loss:0.4564 \t Train Acc:92.70 %  Valid Acc:86.53 %\n",
      "Epoch:48/100 \t Train Loss:0.2037 Valid Loss:0.4431 \t Train Acc:92.88 %  Valid Acc:86.96 %\n",
      "Epoch:49/100 \t Train Loss:0.2046 Valid Loss:0.4424 \t Train Acc:92.81 %  Valid Acc:86.72 %\n",
      "Epoch:50/100 \t Train Loss:0.2002 Valid Loss:0.4512 \t Train Acc:92.91 %  Valid Acc:86.90 %\n",
      "Epoch:51/100 \t Train Loss:0.1997 Valid Loss:0.4522 \t Train Acc:92.92 %  Valid Acc:86.88 %\n",
      "Epoch:52/100 \t Train Loss:0.1969 Valid Loss:0.4536 \t Train Acc:92.98 %  Valid Acc:87.01 %\n",
      "Epoch:53/100 \t Train Loss:0.1967 Valid Loss:0.4547 \t Train Acc:93.08 %  Valid Acc:86.88 %\n",
      "Epoch:54/100 \t Train Loss:0.1971 Valid Loss:0.4627 \t Train Acc:93.03 %  Valid Acc:86.50 %\n",
      "Epoch:55/100 \t Train Loss:0.1943 Valid Loss:0.4514 \t Train Acc:93.09 %  Valid Acc:86.86 %\n",
      "Epoch:56/100 \t Train Loss:0.1904 Valid Loss:0.4565 \t Train Acc:93.32 %  Valid Acc:86.87 %\n",
      "Epoch:57/100 \t Train Loss:0.1920 Valid Loss:0.4534 \t Train Acc:93.25 %  Valid Acc:86.93 %\n",
      "Epoch:58/100 \t Train Loss:0.1910 Valid Loss:0.4654 \t Train Acc:93.18 %  Valid Acc:86.77 %\n",
      "Epoch:59/100 \t Train Loss:0.1878 Valid Loss:0.4507 \t Train Acc:93.28 %  Valid Acc:86.85 %\n",
      "Epoch:60/100 \t Train Loss:0.1861 Valid Loss:0.4572 \t Train Acc:93.36 %  Valid Acc:87.00 %\n",
      "Epoch:61/100 \t Train Loss:0.1759 Valid Loss:0.4626 \t Train Acc:93.75 %  Valid Acc:86.94 %\n",
      "Epoch:62/100 \t Train Loss:0.1756 Valid Loss:0.4613 \t Train Acc:93.85 %  Valid Acc:86.69 %\n",
      "Epoch:63/100 \t Train Loss:0.1722 Valid Loss:0.4614 \t Train Acc:94.02 %  Valid Acc:86.92 %\n",
      "Epoch:64/100 \t Train Loss:0.1701 Valid Loss:0.4642 \t Train Acc:94.09 %  Valid Acc:86.90 %\n",
      "Epoch:65/100 \t Train Loss:0.1703 Valid Loss:0.4644 \t Train Acc:93.93 %  Valid Acc:86.99 %\n",
      "Epoch:66/100 \t Train Loss:0.1724 Valid Loss:0.4661 \t Train Acc:93.98 %  Valid Acc:86.98 %\n",
      "Epoch:67/100 \t Train Loss:0.1744 Valid Loss:0.4649 \t Train Acc:93.83 %  Valid Acc:86.85 %\n",
      "Epoch:68/100 \t Train Loss:0.1724 Valid Loss:0.4602 \t Train Acc:93.86 %  Valid Acc:86.96 %\n",
      "Epoch:69/100 \t Train Loss:0.1685 Valid Loss:0.4659 \t Train Acc:94.12 %  Valid Acc:86.80 %\n",
      "Epoch:70/100 \t Train Loss:0.1701 Valid Loss:0.4633 \t Train Acc:93.98 %  Valid Acc:86.88 %\n",
      "Epoch:71/100 \t Train Loss:0.1704 Valid Loss:0.4648 \t Train Acc:93.91 %  Valid Acc:87.08 %\n",
      "Epoch:72/100 \t Train Loss:0.1678 Valid Loss:0.4657 \t Train Acc:94.01 %  Valid Acc:87.02 %\n",
      "Epoch:73/100 \t Train Loss:0.1696 Valid Loss:0.4651 \t Train Acc:93.97 %  Valid Acc:86.86 %\n",
      "Epoch:74/100 \t Train Loss:0.1661 Valid Loss:0.4690 \t Train Acc:94.01 %  Valid Acc:86.94 %\n",
      "Epoch:75/100 \t Train Loss:0.1652 Valid Loss:0.4663 \t Train Acc:94.07 %  Valid Acc:87.02 %\n",
      "Epoch:76/100 \t Train Loss:0.1650 Valid Loss:0.4706 \t Train Acc:94.12 %  Valid Acc:86.96 %\n",
      "Epoch:77/100 \t Train Loss:0.1643 Valid Loss:0.4672 \t Train Acc:94.23 %  Valid Acc:87.11 %\n",
      "Epoch:78/100 \t Train Loss:0.1652 Valid Loss:0.4683 \t Train Acc:94.13 %  Valid Acc:86.99 %\n",
      "Epoch:79/100 \t Train Loss:0.1658 Valid Loss:0.4736 \t Train Acc:94.15 %  Valid Acc:86.96 %\n",
      "Epoch:80/100 \t Train Loss:0.1637 Valid Loss:0.4704 \t Train Acc:94.23 %  Valid Acc:86.97 %\n",
      "Epoch:81/100 \t Train Loss:0.1619 Valid Loss:0.4667 \t Train Acc:94.24 %  Valid Acc:86.93 %\n",
      "Epoch:82/100 \t Train Loss:0.1599 Valid Loss:0.4678 \t Train Acc:94.41 %  Valid Acc:87.16 %\n",
      "Epoch:83/100 \t Train Loss:0.1621 Valid Loss:0.4684 \t Train Acc:94.33 %  Valid Acc:86.98 %\n",
      "Epoch:84/100 \t Train Loss:0.1555 Valid Loss:0.4722 \t Train Acc:94.54 %  Valid Acc:87.00 %\n",
      "Epoch:85/100 \t Train Loss:0.1578 Valid Loss:0.4720 \t Train Acc:94.38 %  Valid Acc:87.05 %\n",
      "Epoch:86/100 \t Train Loss:0.1563 Valid Loss:0.4732 \t Train Acc:94.48 %  Valid Acc:87.09 %\n",
      "Epoch:87/100 \t Train Loss:0.1582 Valid Loss:0.4742 \t Train Acc:94.49 %  Valid Acc:87.00 %\n",
      "Epoch:88/100 \t Train Loss:0.1580 Valid Loss:0.4695 \t Train Acc:94.40 %  Valid Acc:86.95 %\n",
      "Epoch:89/100 \t Train Loss:0.1582 Valid Loss:0.4716 \t Train Acc:94.35 %  Valid Acc:86.94 %\n",
      "Epoch:90/100 \t Train Loss:0.1562 Valid Loss:0.4728 \t Train Acc:94.60 %  Valid Acc:86.95 %\n",
      "Epoch:91/100 \t Train Loss:0.1564 Valid Loss:0.4721 \t Train Acc:94.35 %  Valid Acc:86.99 %\n",
      "Epoch:92/100 \t Train Loss:0.1555 Valid Loss:0.4749 \t Train Acc:94.46 %  Valid Acc:86.87 %\n",
      "Epoch:93/100 \t Train Loss:0.1594 Valid Loss:0.4722 \t Train Acc:94.42 %  Valid Acc:86.90 %\n",
      "Epoch:94/100 \t Train Loss:0.1590 Valid Loss:0.4715 \t Train Acc:94.27 %  Valid Acc:87.06 %\n",
      "Epoch:95/100 \t Train Loss:0.1592 Valid Loss:0.4741 \t Train Acc:94.31 %  Valid Acc:86.92 %\n",
      "Epoch:96/100 \t Train Loss:0.1566 Valid Loss:0.4758 \t Train Acc:94.51 %  Valid Acc:86.99 %\n",
      "Epoch:97/100 \t Train Loss:0.1540 Valid Loss:0.4752 \t Train Acc:94.56 %  Valid Acc:86.98 %\n",
      "Epoch:98/100 \t Train Loss:0.1570 Valid Loss:0.4743 \t Train Acc:94.43 %  Valid Acc:87.04 %\n",
      "Epoch:99/100 \t Train Loss:0.1598 Valid Loss:0.4758 \t Train Acc:94.36 %  Valid Acc:86.88 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 06:47:53,900] Trial 13 finished with value: 86.87 and parameters: {'sigma_1': 2.3994107295689187, 'sigma_2': 0.7372144086589018, 'sigma_3': 4.040517483582185, 'sigma_4': 1.2570861115622631, 'sigma_5': 4.143134397229131, 'sigma_6': 1.8114723337674072, 'sigma_7': 1.749233833685064, 'sigma_8': 2.8938506620891977, 'sigma_9': 1.2051231994267035, 'sigma_10': 2.1316336213552467, 'sigma_11': 4.907218483023147, 'sigma_12': 1.3979651436248233, 'sigma_13': 1.100386336559624}. Best is trial 5 with value: 87.35000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1546 Valid Loss:0.4744 \t Train Acc:94.46 %  Valid Acc:86.87 %\n",
      "Epoch:1/100 \t Train Loss:1.5123 Valid Loss:1.2084 \t Train Acc:43.95 %  Valid Acc:56.62 %\n",
      "Epoch:2/100 \t Train Loss:1.1275 Valid Loss:1.1858 \t Train Acc:59.44 %  Valid Acc:58.74 %\n",
      "Epoch:3/100 \t Train Loss:0.9749 Valid Loss:0.9136 \t Train Acc:65.18 %  Valid Acc:67.97 %\n",
      "Epoch:4/100 \t Train Loss:0.8812 Valid Loss:0.8859 \t Train Acc:68.82 %  Valid Acc:68.73 %\n",
      "Epoch:5/100 \t Train Loss:0.8029 Valid Loss:0.8029 \t Train Acc:71.59 %  Valid Acc:72.49 %\n",
      "Epoch:6/100 \t Train Loss:0.7415 Valid Loss:0.7366 \t Train Acc:73.83 %  Valid Acc:74.10 %\n",
      "Epoch:7/100 \t Train Loss:0.6844 Valid Loss:0.6675 \t Train Acc:75.99 %  Valid Acc:77.42 %\n",
      "Epoch:8/100 \t Train Loss:0.6395 Valid Loss:0.6213 \t Train Acc:77.75 %  Valid Acc:78.86 %\n",
      "Epoch:9/100 \t Train Loss:0.5941 Valid Loss:0.5838 \t Train Acc:79.27 %  Valid Acc:80.43 %\n",
      "Epoch:10/100 \t Train Loss:0.5646 Valid Loss:0.5728 \t Train Acc:80.45 %  Valid Acc:80.23 %\n",
      "Epoch:11/100 \t Train Loss:0.5402 Valid Loss:0.5997 \t Train Acc:81.23 %  Valid Acc:79.60 %\n",
      "Epoch:12/100 \t Train Loss:0.5193 Valid Loss:0.5984 \t Train Acc:81.99 %  Valid Acc:79.93 %\n",
      "Epoch:13/100 \t Train Loss:0.4986 Valid Loss:0.5347 \t Train Acc:82.55 %  Valid Acc:81.74 %\n",
      "Epoch:14/100 \t Train Loss:0.4811 Valid Loss:0.5430 \t Train Acc:83.41 %  Valid Acc:81.59 %\n",
      "Epoch:15/100 \t Train Loss:0.4658 Valid Loss:0.5511 \t Train Acc:83.86 %  Valid Acc:81.56 %\n",
      "Epoch:16/100 \t Train Loss:0.4548 Valid Loss:0.4966 \t Train Acc:84.23 %  Valid Acc:83.21 %\n",
      "Epoch:17/100 \t Train Loss:0.4388 Valid Loss:0.5091 \t Train Acc:84.64 %  Valid Acc:83.15 %\n",
      "Epoch:18/100 \t Train Loss:0.4274 Valid Loss:0.5215 \t Train Acc:85.14 %  Valid Acc:82.63 %\n",
      "Epoch:19/100 \t Train Loss:0.4148 Valid Loss:0.5072 \t Train Acc:85.47 %  Valid Acc:83.29 %\n",
      "Epoch:20/100 \t Train Loss:0.4097 Valid Loss:0.5091 \t Train Acc:85.58 %  Valid Acc:83.14 %\n",
      "Epoch:21/100 \t Train Loss:0.3278 Valid Loss:0.4465 \t Train Acc:88.51 %  Valid Acc:85.44 %\n",
      "Epoch:22/100 \t Train Loss:0.3078 Valid Loss:0.4441 \t Train Acc:89.22 %  Valid Acc:85.20 %\n",
      "Epoch:23/100 \t Train Loss:0.3026 Valid Loss:0.4475 \t Train Acc:89.47 %  Valid Acc:85.24 %\n",
      "Epoch:24/100 \t Train Loss:0.2929 Valid Loss:0.4491 \t Train Acc:89.89 %  Valid Acc:85.19 %\n",
      "Epoch:25/100 \t Train Loss:0.2877 Valid Loss:0.4592 \t Train Acc:89.90 %  Valid Acc:84.50 %\n",
      "Epoch:26/100 \t Train Loss:0.2830 Valid Loss:0.4471 \t Train Acc:90.14 %  Valid Acc:85.63 %\n",
      "Epoch:27/100 \t Train Loss:0.2774 Valid Loss:0.4390 \t Train Acc:90.27 %  Valid Acc:85.70 %\n",
      "Epoch:28/100 \t Train Loss:0.2715 Valid Loss:0.4485 \t Train Acc:90.43 %  Valid Acc:85.76 %\n",
      "Epoch:29/100 \t Train Loss:0.2708 Valid Loss:0.4466 \t Train Acc:90.51 %  Valid Acc:85.70 %\n",
      "Epoch:30/100 \t Train Loss:0.2623 Valid Loss:0.4424 \t Train Acc:90.77 %  Valid Acc:85.96 %\n",
      "Epoch:31/100 \t Train Loss:0.2595 Valid Loss:0.4384 \t Train Acc:90.79 %  Valid Acc:86.35 %\n",
      "Epoch:32/100 \t Train Loss:0.2568 Valid Loss:0.4530 \t Train Acc:91.02 %  Valid Acc:86.11 %\n",
      "Epoch:33/100 \t Train Loss:0.2541 Valid Loss:0.4554 \t Train Acc:90.95 %  Valid Acc:86.07 %\n",
      "Epoch:34/100 \t Train Loss:0.2507 Valid Loss:0.4460 \t Train Acc:91.09 %  Valid Acc:86.10 %\n",
      "Epoch:35/100 \t Train Loss:0.2453 Valid Loss:0.4541 \t Train Acc:91.36 %  Valid Acc:86.33 %\n",
      "Epoch:36/100 \t Train Loss:0.2444 Valid Loss:0.4504 \t Train Acc:91.46 %  Valid Acc:86.39 %\n",
      "Epoch:37/100 \t Train Loss:0.2413 Valid Loss:0.4683 \t Train Acc:91.44 %  Valid Acc:85.67 %\n",
      "Epoch:38/100 \t Train Loss:0.2383 Valid Loss:0.4575 \t Train Acc:91.51 %  Valid Acc:86.13 %\n",
      "Epoch:39/100 \t Train Loss:0.2351 Valid Loss:0.4345 \t Train Acc:91.68 %  Valid Acc:86.49 %\n",
      "Epoch:40/100 \t Train Loss:0.2328 Valid Loss:0.4468 \t Train Acc:91.75 %  Valid Acc:86.53 %\n",
      "Epoch:41/100 \t Train Loss:0.2027 Valid Loss:0.4347 \t Train Acc:92.93 %  Valid Acc:87.00 %\n",
      "Epoch:42/100 \t Train Loss:0.1952 Valid Loss:0.4336 \t Train Acc:93.18 %  Valid Acc:87.12 %\n",
      "Epoch:43/100 \t Train Loss:0.1922 Valid Loss:0.4420 \t Train Acc:93.23 %  Valid Acc:86.98 %\n",
      "Epoch:44/100 \t Train Loss:0.1883 Valid Loss:0.4397 \t Train Acc:93.40 %  Valid Acc:87.21 %\n",
      "Epoch:45/100 \t Train Loss:0.1881 Valid Loss:0.4486 \t Train Acc:93.31 %  Valid Acc:87.01 %\n",
      "Epoch:46/100 \t Train Loss:0.1876 Valid Loss:0.4401 \t Train Acc:93.35 %  Valid Acc:87.14 %\n",
      "Epoch:47/100 \t Train Loss:0.1835 Valid Loss:0.4401 \t Train Acc:93.46 %  Valid Acc:87.29 %\n",
      "Epoch:48/100 \t Train Loss:0.1842 Valid Loss:0.4478 \t Train Acc:93.41 %  Valid Acc:87.09 %\n",
      "Epoch:49/100 \t Train Loss:0.1838 Valid Loss:0.4475 \t Train Acc:93.30 %  Valid Acc:87.09 %\n",
      "Epoch:50/100 \t Train Loss:0.1791 Valid Loss:0.4439 \t Train Acc:93.60 %  Valid Acc:87.16 %\n",
      "Epoch:51/100 \t Train Loss:0.1786 Valid Loss:0.4480 \t Train Acc:93.62 %  Valid Acc:86.99 %\n",
      "Epoch:52/100 \t Train Loss:0.1764 Valid Loss:0.4494 \t Train Acc:93.72 %  Valid Acc:87.10 %\n",
      "Epoch:53/100 \t Train Loss:0.1766 Valid Loss:0.4479 \t Train Acc:93.64 %  Valid Acc:87.32 %\n",
      "Epoch:54/100 \t Train Loss:0.1743 Valid Loss:0.4611 \t Train Acc:93.82 %  Valid Acc:86.78 %\n",
      "Epoch:55/100 \t Train Loss:0.1733 Valid Loss:0.4605 \t Train Acc:93.78 %  Valid Acc:87.02 %\n",
      "Epoch:56/100 \t Train Loss:0.1709 Valid Loss:0.4567 \t Train Acc:93.91 %  Valid Acc:86.97 %\n",
      "Epoch:57/100 \t Train Loss:0.1712 Valid Loss:0.4559 \t Train Acc:93.98 %  Valid Acc:87.09 %\n",
      "Epoch:58/100 \t Train Loss:0.1700 Valid Loss:0.4543 \t Train Acc:93.97 %  Valid Acc:87.17 %\n",
      "Epoch:59/100 \t Train Loss:0.1673 Valid Loss:0.4634 \t Train Acc:93.89 %  Valid Acc:87.16 %\n",
      "Epoch:60/100 \t Train Loss:0.1668 Valid Loss:0.4633 \t Train Acc:94.02 %  Valid Acc:87.03 %\n",
      "Epoch:61/100 \t Train Loss:0.1579 Valid Loss:0.4568 \t Train Acc:94.36 %  Valid Acc:87.39 %\n",
      "Epoch:62/100 \t Train Loss:0.1547 Valid Loss:0.4611 \t Train Acc:94.50 %  Valid Acc:87.15 %\n",
      "Epoch:63/100 \t Train Loss:0.1553 Valid Loss:0.4634 \t Train Acc:94.46 %  Valid Acc:87.41 %\n",
      "Epoch:64/100 \t Train Loss:0.1561 Valid Loss:0.4639 \t Train Acc:94.41 %  Valid Acc:87.36 %\n",
      "Epoch:65/100 \t Train Loss:0.1546 Valid Loss:0.4629 \t Train Acc:94.38 %  Valid Acc:87.33 %\n",
      "Epoch:66/100 \t Train Loss:0.1519 Valid Loss:0.4695 \t Train Acc:94.53 %  Valid Acc:87.14 %\n",
      "Epoch:67/100 \t Train Loss:0.1513 Valid Loss:0.4646 \t Train Acc:94.63 %  Valid Acc:87.34 %\n",
      "Epoch:68/100 \t Train Loss:0.1502 Valid Loss:0.4661 \t Train Acc:94.58 %  Valid Acc:87.16 %\n",
      "Epoch:69/100 \t Train Loss:0.1483 Valid Loss:0.4653 \t Train Acc:94.67 %  Valid Acc:87.21 %\n",
      "Epoch:70/100 \t Train Loss:0.1518 Valid Loss:0.4643 \t Train Acc:94.55 %  Valid Acc:87.46 %\n",
      "Epoch:71/100 \t Train Loss:0.1491 Valid Loss:0.4725 \t Train Acc:94.67 %  Valid Acc:87.09 %\n",
      "Epoch:72/100 \t Train Loss:0.1450 Valid Loss:0.4762 \t Train Acc:94.90 %  Valid Acc:87.18 %\n",
      "Epoch:73/100 \t Train Loss:0.1489 Valid Loss:0.4751 \t Train Acc:94.66 %  Valid Acc:87.45 %\n",
      "Epoch:74/100 \t Train Loss:0.1488 Valid Loss:0.4687 \t Train Acc:94.66 %  Valid Acc:87.20 %\n",
      "Epoch:75/100 \t Train Loss:0.1469 Valid Loss:0.4715 \t Train Acc:94.79 %  Valid Acc:87.30 %\n",
      "Epoch:76/100 \t Train Loss:0.1480 Valid Loss:0.4732 \t Train Acc:94.76 %  Valid Acc:87.41 %\n",
      "Epoch:77/100 \t Train Loss:0.1463 Valid Loss:0.4755 \t Train Acc:94.81 %  Valid Acc:87.38 %\n",
      "Epoch:78/100 \t Train Loss:0.1460 Valid Loss:0.4770 \t Train Acc:94.81 %  Valid Acc:87.12 %\n",
      "Epoch:79/100 \t Train Loss:0.1461 Valid Loss:0.4734 \t Train Acc:94.79 %  Valid Acc:87.25 %\n",
      "Epoch:80/100 \t Train Loss:0.1455 Valid Loss:0.4802 \t Train Acc:94.80 %  Valid Acc:87.21 %\n",
      "Epoch:81/100 \t Train Loss:0.1419 Valid Loss:0.4725 \t Train Acc:95.01 %  Valid Acc:87.32 %\n",
      "Epoch:82/100 \t Train Loss:0.1417 Valid Loss:0.4750 \t Train Acc:94.92 %  Valid Acc:87.46 %\n",
      "Epoch:83/100 \t Train Loss:0.1391 Valid Loss:0.4740 \t Train Acc:95.14 %  Valid Acc:87.41 %\n",
      "Epoch:84/100 \t Train Loss:0.1400 Valid Loss:0.4727 \t Train Acc:95.01 %  Valid Acc:87.42 %\n",
      "Epoch:85/100 \t Train Loss:0.1403 Valid Loss:0.4753 \t Train Acc:94.98 %  Valid Acc:87.40 %\n",
      "Epoch:86/100 \t Train Loss:0.1419 Valid Loss:0.4750 \t Train Acc:94.89 %  Valid Acc:87.30 %\n",
      "Epoch:87/100 \t Train Loss:0.1389 Valid Loss:0.4746 \t Train Acc:95.04 %  Valid Acc:87.46 %\n",
      "Epoch:88/100 \t Train Loss:0.1389 Valid Loss:0.4737 \t Train Acc:95.12 %  Valid Acc:87.35 %\n",
      "Epoch:89/100 \t Train Loss:0.1388 Valid Loss:0.4763 \t Train Acc:95.13 %  Valid Acc:87.36 %\n",
      "Epoch:90/100 \t Train Loss:0.1390 Valid Loss:0.4739 \t Train Acc:95.07 %  Valid Acc:87.43 %\n",
      "Epoch:91/100 \t Train Loss:0.1398 Valid Loss:0.4771 \t Train Acc:95.00 %  Valid Acc:87.37 %\n",
      "Epoch:92/100 \t Train Loss:0.1371 Valid Loss:0.4786 \t Train Acc:95.07 %  Valid Acc:87.43 %\n",
      "Epoch:93/100 \t Train Loss:0.1403 Valid Loss:0.4773 \t Train Acc:94.78 %  Valid Acc:87.29 %\n",
      "Epoch:94/100 \t Train Loss:0.1377 Valid Loss:0.4808 \t Train Acc:95.11 %  Valid Acc:87.34 %\n",
      "Epoch:95/100 \t Train Loss:0.1392 Valid Loss:0.4775 \t Train Acc:95.08 %  Valid Acc:87.24 %\n",
      "Epoch:96/100 \t Train Loss:0.1389 Valid Loss:0.4807 \t Train Acc:95.07 %  Valid Acc:87.38 %\n",
      "Epoch:97/100 \t Train Loss:0.1378 Valid Loss:0.4785 \t Train Acc:95.06 %  Valid Acc:87.33 %\n",
      "Epoch:98/100 \t Train Loss:0.1384 Valid Loss:0.4801 \t Train Acc:95.05 %  Valid Acc:87.41 %\n",
      "Epoch:99/100 \t Train Loss:0.1397 Valid Loss:0.4747 \t Train Acc:95.02 %  Valid Acc:87.43 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 08:07:32,796] Trial 14 finished with value: 87.53 and parameters: {'sigma_1': 2.7710378333777306, 'sigma_2': 3.10956870691802, 'sigma_3': 4.452437301185996, 'sigma_4': 0.1602517871569942, 'sigma_5': 2.9819742646401113, 'sigma_6': 3.1962193834158907, 'sigma_7': 3.529916762665707, 'sigma_8': 4.411809158334843, 'sigma_9': 3.155470527187394, 'sigma_10': 1.2437140031305443, 'sigma_11': 3.1579504167411585, 'sigma_12': 2.983944389343507, 'sigma_13': 2.4247983318977}. Best is trial 14 with value: 87.53.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1409 Valid Loss:0.4778 \t Train Acc:94.94 %  Valid Acc:87.53 %\n",
      "Epoch:1/100 \t Train Loss:1.5188 Valid Loss:1.2821 \t Train Acc:43.96 %  Valid Acc:53.07 %\n",
      "Epoch:2/100 \t Train Loss:1.1638 Valid Loss:1.0067 \t Train Acc:58.18 %  Valid Acc:63.67 %\n",
      "Epoch:3/100 \t Train Loss:1.0098 Valid Loss:0.9041 \t Train Acc:64.10 %  Valid Acc:67.83 %\n",
      "Epoch:4/100 \t Train Loss:0.9044 Valid Loss:0.9074 \t Train Acc:67.92 %  Valid Acc:69.03 %\n",
      "Epoch:5/100 \t Train Loss:0.8211 Valid Loss:0.7628 \t Train Acc:71.00 %  Valid Acc:73.56 %\n",
      "Epoch:6/100 \t Train Loss:0.7485 Valid Loss:0.7557 \t Train Acc:73.79 %  Valid Acc:74.13 %\n",
      "Epoch:7/100 \t Train Loss:0.6900 Valid Loss:0.6858 \t Train Acc:75.93 %  Valid Acc:76.33 %\n",
      "Epoch:8/100 \t Train Loss:0.6477 Valid Loss:0.6795 \t Train Acc:77.61 %  Valid Acc:76.38 %\n",
      "Epoch:9/100 \t Train Loss:0.6202 Valid Loss:0.6366 \t Train Acc:78.61 %  Valid Acc:78.55 %\n",
      "Epoch:10/100 \t Train Loss:0.5884 Valid Loss:0.5927 \t Train Acc:79.54 %  Valid Acc:79.51 %\n",
      "Epoch:11/100 \t Train Loss:0.5641 Valid Loss:0.5810 \t Train Acc:80.47 %  Valid Acc:80.27 %\n",
      "Epoch:12/100 \t Train Loss:0.5451 Valid Loss:0.5707 \t Train Acc:81.14 %  Valid Acc:81.09 %\n",
      "Epoch:13/100 \t Train Loss:0.5223 Valid Loss:0.5992 \t Train Acc:81.91 %  Valid Acc:79.84 %\n",
      "Epoch:14/100 \t Train Loss:0.5024 Valid Loss:0.5431 \t Train Acc:82.68 %  Valid Acc:81.65 %\n",
      "Epoch:15/100 \t Train Loss:0.4898 Valid Loss:0.5535 \t Train Acc:83.15 %  Valid Acc:81.74 %\n",
      "Epoch:16/100 \t Train Loss:0.4725 Valid Loss:0.5248 \t Train Acc:83.62 %  Valid Acc:82.26 %\n",
      "Epoch:17/100 \t Train Loss:0.4602 Valid Loss:0.5750 \t Train Acc:83.96 %  Valid Acc:80.84 %\n",
      "Epoch:18/100 \t Train Loss:0.4517 Valid Loss:0.5184 \t Train Acc:84.28 %  Valid Acc:82.49 %\n",
      "Epoch:19/100 \t Train Loss:0.4439 Valid Loss:0.5185 \t Train Acc:84.49 %  Valid Acc:82.78 %\n",
      "Epoch:20/100 \t Train Loss:0.4310 Valid Loss:0.5104 \t Train Acc:85.12 %  Valid Acc:83.28 %\n",
      "Epoch:21/100 \t Train Loss:0.3519 Valid Loss:0.4727 \t Train Acc:87.76 %  Valid Acc:84.37 %\n",
      "Epoch:22/100 \t Train Loss:0.3290 Valid Loss:0.4565 \t Train Acc:88.63 %  Valid Acc:85.05 %\n",
      "Epoch:23/100 \t Train Loss:0.3197 Valid Loss:0.4642 \t Train Acc:88.81 %  Valid Acc:85.08 %\n",
      "Epoch:24/100 \t Train Loss:0.3145 Valid Loss:0.4497 \t Train Acc:88.99 %  Valid Acc:85.64 %\n",
      "Epoch:25/100 \t Train Loss:0.3094 Valid Loss:0.4608 \t Train Acc:89.10 %  Valid Acc:84.87 %\n",
      "Epoch:26/100 \t Train Loss:0.3023 Valid Loss:0.4501 \t Train Acc:89.49 %  Valid Acc:85.53 %\n",
      "Epoch:27/100 \t Train Loss:0.2979 Valid Loss:0.4540 \t Train Acc:89.72 %  Valid Acc:85.40 %\n",
      "Epoch:28/100 \t Train Loss:0.2928 Valid Loss:0.4527 \t Train Acc:89.65 %  Valid Acc:86.00 %\n",
      "Epoch:29/100 \t Train Loss:0.2891 Valid Loss:0.4686 \t Train Acc:89.85 %  Valid Acc:85.18 %\n",
      "Epoch:30/100 \t Train Loss:0.2842 Valid Loss:0.4444 \t Train Acc:90.06 %  Valid Acc:85.99 %\n",
      "Epoch:31/100 \t Train Loss:0.2813 Valid Loss:0.4314 \t Train Acc:90.12 %  Valid Acc:86.18 %\n",
      "Epoch:32/100 \t Train Loss:0.2754 Valid Loss:0.4633 \t Train Acc:90.22 %  Valid Acc:85.29 %\n",
      "Epoch:33/100 \t Train Loss:0.2699 Valid Loss:0.4493 \t Train Acc:90.38 %  Valid Acc:85.92 %\n",
      "Epoch:34/100 \t Train Loss:0.2699 Valid Loss:0.4556 \t Train Acc:90.64 %  Valid Acc:85.67 %\n",
      "Epoch:35/100 \t Train Loss:0.2646 Valid Loss:0.4596 \t Train Acc:90.69 %  Valid Acc:85.77 %\n",
      "Epoch:36/100 \t Train Loss:0.2623 Valid Loss:0.4573 \t Train Acc:90.77 %  Valid Acc:85.88 %\n",
      "Epoch:37/100 \t Train Loss:0.2570 Valid Loss:0.4630 \t Train Acc:90.91 %  Valid Acc:85.71 %\n",
      "Epoch:38/100 \t Train Loss:0.2547 Valid Loss:0.4571 \t Train Acc:91.07 %  Valid Acc:86.04 %\n",
      "Epoch:39/100 \t Train Loss:0.2563 Valid Loss:0.4702 \t Train Acc:90.91 %  Valid Acc:85.36 %\n",
      "Epoch:40/100 \t Train Loss:0.2509 Valid Loss:0.4705 \t Train Acc:91.09 %  Valid Acc:85.92 %\n",
      "Epoch:41/100 \t Train Loss:0.2163 Valid Loss:0.4450 \t Train Acc:92.45 %  Valid Acc:86.69 %\n",
      "Epoch:42/100 \t Train Loss:0.2107 Valid Loss:0.4384 \t Train Acc:92.60 %  Valid Acc:86.92 %\n",
      "Epoch:43/100 \t Train Loss:0.2113 Valid Loss:0.4403 \t Train Acc:92.67 %  Valid Acc:86.85 %\n",
      "Epoch:44/100 \t Train Loss:0.2112 Valid Loss:0.4435 \t Train Acc:92.57 %  Valid Acc:86.78 %\n",
      "Epoch:45/100 \t Train Loss:0.2044 Valid Loss:0.4483 \t Train Acc:92.86 %  Valid Acc:86.98 %\n",
      "Epoch:46/100 \t Train Loss:0.2035 Valid Loss:0.4536 \t Train Acc:92.90 %  Valid Acc:86.79 %\n",
      "Epoch:47/100 \t Train Loss:0.2009 Valid Loss:0.4468 \t Train Acc:92.86 %  Valid Acc:86.69 %\n",
      "Epoch:48/100 \t Train Loss:0.2024 Valid Loss:0.4606 \t Train Acc:92.83 %  Valid Acc:86.61 %\n",
      "Epoch:49/100 \t Train Loss:0.2003 Valid Loss:0.4509 \t Train Acc:92.94 %  Valid Acc:86.68 %\n",
      "Epoch:50/100 \t Train Loss:0.1986 Valid Loss:0.4519 \t Train Acc:93.02 %  Valid Acc:87.02 %\n",
      "Epoch:51/100 \t Train Loss:0.1947 Valid Loss:0.4572 \t Train Acc:93.12 %  Valid Acc:86.64 %\n",
      "Epoch:52/100 \t Train Loss:0.1937 Valid Loss:0.4584 \t Train Acc:93.08 %  Valid Acc:86.77 %\n",
      "Epoch:53/100 \t Train Loss:0.1924 Valid Loss:0.4578 \t Train Acc:93.14 %  Valid Acc:86.98 %\n",
      "Epoch:54/100 \t Train Loss:0.1912 Valid Loss:0.4655 \t Train Acc:93.35 %  Valid Acc:86.77 %\n",
      "Epoch:55/100 \t Train Loss:0.1884 Valid Loss:0.4692 \t Train Acc:93.39 %  Valid Acc:86.58 %\n",
      "Epoch:56/100 \t Train Loss:0.1904 Valid Loss:0.4597 \t Train Acc:93.36 %  Valid Acc:86.90 %\n",
      "Epoch:57/100 \t Train Loss:0.1881 Valid Loss:0.4738 \t Train Acc:93.35 %  Valid Acc:86.56 %\n",
      "Epoch:58/100 \t Train Loss:0.1878 Valid Loss:0.4657 \t Train Acc:93.26 %  Valid Acc:86.93 %\n",
      "Epoch:59/100 \t Train Loss:0.1857 Valid Loss:0.4705 \t Train Acc:93.52 %  Valid Acc:86.66 %\n",
      "Epoch:60/100 \t Train Loss:0.1843 Valid Loss:0.4797 \t Train Acc:93.40 %  Valid Acc:86.48 %\n",
      "Epoch:61/100 \t Train Loss:0.1745 Valid Loss:0.4701 \t Train Acc:93.83 %  Valid Acc:86.92 %\n",
      "Epoch:62/100 \t Train Loss:0.1709 Valid Loss:0.4650 \t Train Acc:94.04 %  Valid Acc:87.05 %\n",
      "Epoch:63/100 \t Train Loss:0.1736 Valid Loss:0.4636 \t Train Acc:93.82 %  Valid Acc:87.10 %\n",
      "Epoch:64/100 \t Train Loss:0.1724 Valid Loss:0.4646 \t Train Acc:93.88 %  Valid Acc:87.07 %\n",
      "Epoch:65/100 \t Train Loss:0.1708 Valid Loss:0.4664 \t Train Acc:94.01 %  Valid Acc:87.15 %\n",
      "Epoch:66/100 \t Train Loss:0.1671 Valid Loss:0.4701 \t Train Acc:94.05 %  Valid Acc:87.00 %\n",
      "Epoch:67/100 \t Train Loss:0.1670 Valid Loss:0.4696 \t Train Acc:94.12 %  Valid Acc:87.08 %\n",
      "Epoch:68/100 \t Train Loss:0.1664 Valid Loss:0.4716 \t Train Acc:94.08 %  Valid Acc:87.07 %\n",
      "Epoch:69/100 \t Train Loss:0.1660 Valid Loss:0.4697 \t Train Acc:94.11 %  Valid Acc:86.98 %\n",
      "Epoch:70/100 \t Train Loss:0.1666 Valid Loss:0.4721 \t Train Acc:94.10 %  Valid Acc:87.05 %\n",
      "Epoch:71/100 \t Train Loss:0.1651 Valid Loss:0.4699 \t Train Acc:94.20 %  Valid Acc:87.14 %\n",
      "Epoch:72/100 \t Train Loss:0.1630 Valid Loss:0.4755 \t Train Acc:94.28 %  Valid Acc:87.22 %\n",
      "Epoch:73/100 \t Train Loss:0.1644 Valid Loss:0.4714 \t Train Acc:94.14 %  Valid Acc:87.10 %\n",
      "Epoch:74/100 \t Train Loss:0.1665 Valid Loss:0.4697 \t Train Acc:93.98 %  Valid Acc:87.14 %\n",
      "Epoch:75/100 \t Train Loss:0.1628 Valid Loss:0.4742 \t Train Acc:94.20 %  Valid Acc:86.80 %\n",
      "Epoch:76/100 \t Train Loss:0.1623 Valid Loss:0.4731 \t Train Acc:94.28 %  Valid Acc:87.00 %\n",
      "Epoch:77/100 \t Train Loss:0.1633 Valid Loss:0.4761 \t Train Acc:94.20 %  Valid Acc:87.02 %\n",
      "Epoch:78/100 \t Train Loss:0.1612 Valid Loss:0.4778 \t Train Acc:94.30 %  Valid Acc:86.99 %\n",
      "Epoch:79/100 \t Train Loss:0.1613 Valid Loss:0.4790 \t Train Acc:94.18 %  Valid Acc:87.09 %\n",
      "Epoch:80/100 \t Train Loss:0.1616 Valid Loss:0.4775 \t Train Acc:94.29 %  Valid Acc:87.16 %\n",
      "Epoch:81/100 \t Train Loss:0.1556 Valid Loss:0.4793 \t Train Acc:94.64 %  Valid Acc:87.07 %\n",
      "Epoch:82/100 \t Train Loss:0.1600 Valid Loss:0.4763 \t Train Acc:94.25 %  Valid Acc:87.13 %\n",
      "Epoch:83/100 \t Train Loss:0.1544 Valid Loss:0.4780 \t Train Acc:94.52 %  Valid Acc:87.15 %\n",
      "Epoch:84/100 \t Train Loss:0.1591 Valid Loss:0.4780 \t Train Acc:94.31 %  Valid Acc:87.24 %\n",
      "Epoch:85/100 \t Train Loss:0.1569 Valid Loss:0.4806 \t Train Acc:94.48 %  Valid Acc:87.01 %\n",
      "Epoch:86/100 \t Train Loss:0.1563 Valid Loss:0.4794 \t Train Acc:94.50 %  Valid Acc:87.02 %\n",
      "Epoch:87/100 \t Train Loss:0.1558 Valid Loss:0.4789 \t Train Acc:94.42 %  Valid Acc:87.03 %\n",
      "Epoch:88/100 \t Train Loss:0.1569 Valid Loss:0.4793 \t Train Acc:94.40 %  Valid Acc:86.95 %\n",
      "Epoch:89/100 \t Train Loss:0.1558 Valid Loss:0.4807 \t Train Acc:94.51 %  Valid Acc:87.11 %\n",
      "Epoch:90/100 \t Train Loss:0.1526 Valid Loss:0.4807 \t Train Acc:94.60 %  Valid Acc:86.97 %\n",
      "Epoch:91/100 \t Train Loss:0.1559 Valid Loss:0.4791 \t Train Acc:94.46 %  Valid Acc:87.05 %\n",
      "Epoch:92/100 \t Train Loss:0.1565 Valid Loss:0.4777 \t Train Acc:94.44 %  Valid Acc:87.16 %\n",
      "Epoch:93/100 \t Train Loss:0.1545 Valid Loss:0.4801 \t Train Acc:94.45 %  Valid Acc:87.10 %\n",
      "Epoch:94/100 \t Train Loss:0.1547 Valid Loss:0.4803 \t Train Acc:94.39 %  Valid Acc:87.21 %\n",
      "Epoch:95/100 \t Train Loss:0.1534 Valid Loss:0.4833 \t Train Acc:94.51 %  Valid Acc:87.08 %\n",
      "Epoch:96/100 \t Train Loss:0.1574 Valid Loss:0.4823 \t Train Acc:94.32 %  Valid Acc:86.96 %\n",
      "Epoch:97/100 \t Train Loss:0.1554 Valid Loss:0.4809 \t Train Acc:94.46 %  Valid Acc:87.02 %\n",
      "Epoch:98/100 \t Train Loss:0.1546 Valid Loss:0.4838 \t Train Acc:94.49 %  Valid Acc:86.95 %\n",
      "Epoch:99/100 \t Train Loss:0.1566 Valid Loss:0.4865 \t Train Acc:94.45 %  Valid Acc:86.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 09:26:56,488] Trial 15 finished with value: 86.9 and parameters: {'sigma_1': 3.319375583975227, 'sigma_2': 3.07675917038456, 'sigma_3': 3.292327338773682, 'sigma_4': 1.695161105430996, 'sigma_5': 2.0129957805260354, 'sigma_6': 4.972982084216207, 'sigma_7': 3.6484602401166324, 'sigma_8': 4.237056255455503, 'sigma_9': 1.4741298716919837, 'sigma_10': 0.8704423384931304, 'sigma_11': 3.125608480870266, 'sigma_12': 3.0206025115709876, 'sigma_13': 2.493521091507873}. Best is trial 14 with value: 87.53.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1558 Valid Loss:0.4855 \t Train Acc:94.45 %  Valid Acc:86.90 %\n",
      "Epoch:1/100 \t Train Loss:1.4280 Valid Loss:1.2462 \t Train Acc:47.83 %  Valid Acc:54.83 %\n",
      "Epoch:2/100 \t Train Loss:1.1345 Valid Loss:1.0503 \t Train Acc:59.31 %  Valid Acc:62.07 %\n",
      "Epoch:3/100 \t Train Loss:0.9946 Valid Loss:0.9266 \t Train Acc:64.33 %  Valid Acc:66.87 %\n",
      "Epoch:4/100 \t Train Loss:0.9031 Valid Loss:0.8616 \t Train Acc:68.01 %  Valid Acc:69.56 %\n",
      "Epoch:5/100 \t Train Loss:0.8246 Valid Loss:0.8493 \t Train Acc:70.88 %  Valid Acc:70.89 %\n",
      "Epoch:6/100 \t Train Loss:0.7504 Valid Loss:0.7474 \t Train Acc:73.41 %  Valid Acc:73.99 %\n",
      "Epoch:7/100 \t Train Loss:0.6984 Valid Loss:0.6885 \t Train Acc:75.44 %  Valid Acc:75.78 %\n",
      "Epoch:8/100 \t Train Loss:0.6457 Valid Loss:0.7053 \t Train Acc:77.52 %  Valid Acc:76.11 %\n",
      "Epoch:9/100 \t Train Loss:0.6081 Valid Loss:0.6316 \t Train Acc:78.90 %  Valid Acc:78.04 %\n",
      "Epoch:10/100 \t Train Loss:0.5775 Valid Loss:0.5918 \t Train Acc:79.90 %  Valid Acc:79.85 %\n",
      "Epoch:11/100 \t Train Loss:0.5480 Valid Loss:0.5851 \t Train Acc:80.98 %  Valid Acc:80.29 %\n",
      "Epoch:12/100 \t Train Loss:0.5254 Valid Loss:0.5353 \t Train Acc:81.90 %  Valid Acc:81.94 %\n",
      "Epoch:13/100 \t Train Loss:0.5036 Valid Loss:0.5551 \t Train Acc:82.57 %  Valid Acc:81.34 %\n",
      "Epoch:14/100 \t Train Loss:0.4872 Valid Loss:0.5240 \t Train Acc:83.05 %  Valid Acc:82.40 %\n",
      "Epoch:15/100 \t Train Loss:0.4685 Valid Loss:0.5335 \t Train Acc:83.72 %  Valid Acc:82.43 %\n",
      "Epoch:16/100 \t Train Loss:0.4560 Valid Loss:0.5182 \t Train Acc:84.07 %  Valid Acc:82.77 %\n",
      "Epoch:17/100 \t Train Loss:0.4465 Valid Loss:0.5117 \t Train Acc:84.55 %  Valid Acc:82.53 %\n",
      "Epoch:18/100 \t Train Loss:0.4295 Valid Loss:0.4810 \t Train Acc:84.99 %  Valid Acc:83.81 %\n",
      "Epoch:19/100 \t Train Loss:0.4178 Valid Loss:0.4938 \t Train Acc:85.50 %  Valid Acc:83.72 %\n",
      "Epoch:20/100 \t Train Loss:0.4131 Valid Loss:0.4862 \t Train Acc:85.54 %  Valid Acc:83.97 %\n",
      "Epoch:21/100 \t Train Loss:0.3294 Valid Loss:0.4212 \t Train Acc:88.49 %  Valid Acc:86.19 %\n",
      "Epoch:22/100 \t Train Loss:0.3155 Valid Loss:0.4334 \t Train Acc:88.99 %  Valid Acc:85.86 %\n",
      "Epoch:23/100 \t Train Loss:0.3015 Valid Loss:0.4257 \t Train Acc:89.39 %  Valid Acc:86.07 %\n",
      "Epoch:24/100 \t Train Loss:0.2952 Valid Loss:0.4301 \t Train Acc:89.64 %  Valid Acc:86.01 %\n",
      "Epoch:25/100 \t Train Loss:0.2897 Valid Loss:0.4329 \t Train Acc:89.78 %  Valid Acc:86.32 %\n",
      "Epoch:26/100 \t Train Loss:0.2867 Valid Loss:0.4236 \t Train Acc:89.81 %  Valid Acc:86.15 %\n",
      "Epoch:27/100 \t Train Loss:0.2818 Valid Loss:0.4396 \t Train Acc:90.11 %  Valid Acc:86.03 %\n",
      "Epoch:28/100 \t Train Loss:0.2759 Valid Loss:0.4448 \t Train Acc:90.23 %  Valid Acc:86.22 %\n",
      "Epoch:29/100 \t Train Loss:0.2698 Valid Loss:0.4238 \t Train Acc:90.38 %  Valid Acc:86.61 %\n",
      "Epoch:30/100 \t Train Loss:0.2680 Valid Loss:0.4194 \t Train Acc:90.61 %  Valid Acc:86.60 %\n",
      "Epoch:31/100 \t Train Loss:0.2650 Valid Loss:0.4184 \t Train Acc:90.77 %  Valid Acc:86.70 %\n",
      "Epoch:32/100 \t Train Loss:0.2599 Valid Loss:0.4361 \t Train Acc:90.81 %  Valid Acc:86.46 %\n",
      "Epoch:33/100 \t Train Loss:0.2558 Valid Loss:0.4435 \t Train Acc:90.94 %  Valid Acc:86.29 %\n",
      "Epoch:34/100 \t Train Loss:0.2548 Valid Loss:0.4260 \t Train Acc:90.96 %  Valid Acc:86.92 %\n",
      "Epoch:35/100 \t Train Loss:0.2477 Valid Loss:0.4343 \t Train Acc:91.24 %  Valid Acc:86.44 %\n",
      "Epoch:36/100 \t Train Loss:0.2468 Valid Loss:0.4194 \t Train Acc:91.12 %  Valid Acc:86.89 %\n",
      "Epoch:37/100 \t Train Loss:0.2456 Valid Loss:0.4625 \t Train Acc:91.24 %  Valid Acc:85.87 %\n",
      "Epoch:38/100 \t Train Loss:0.2412 Valid Loss:0.4464 \t Train Acc:91.61 %  Valid Acc:86.23 %\n",
      "Epoch:39/100 \t Train Loss:0.2356 Valid Loss:0.4426 \t Train Acc:91.65 %  Valid Acc:86.56 %\n",
      "Epoch:40/100 \t Train Loss:0.2372 Valid Loss:0.4394 \t Train Acc:91.53 %  Valid Acc:86.78 %\n",
      "Epoch:41/100 \t Train Loss:0.2068 Valid Loss:0.4168 \t Train Acc:92.61 %  Valid Acc:87.33 %\n",
      "Epoch:42/100 \t Train Loss:0.2018 Valid Loss:0.4224 \t Train Acc:93.02 %  Valid Acc:87.19 %\n",
      "Epoch:43/100 \t Train Loss:0.1969 Valid Loss:0.4208 \t Train Acc:93.01 %  Valid Acc:87.41 %\n",
      "Epoch:44/100 \t Train Loss:0.1927 Valid Loss:0.4350 \t Train Acc:93.14 %  Valid Acc:87.28 %\n",
      "Epoch:45/100 \t Train Loss:0.1922 Valid Loss:0.4296 \t Train Acc:93.07 %  Valid Acc:87.47 %\n",
      "Epoch:46/100 \t Train Loss:0.1881 Valid Loss:0.4258 \t Train Acc:93.51 %  Valid Acc:87.40 %\n",
      "Epoch:47/100 \t Train Loss:0.1897 Valid Loss:0.4250 \t Train Acc:93.21 %  Valid Acc:87.37 %\n",
      "Epoch:48/100 \t Train Loss:0.1884 Valid Loss:0.4293 \t Train Acc:93.35 %  Valid Acc:87.39 %\n",
      "Epoch:49/100 \t Train Loss:0.1844 Valid Loss:0.4383 \t Train Acc:93.40 %  Valid Acc:87.13 %\n",
      "Epoch:50/100 \t Train Loss:0.1817 Valid Loss:0.4420 \t Train Acc:93.57 %  Valid Acc:87.25 %\n",
      "Epoch:51/100 \t Train Loss:0.1835 Valid Loss:0.4367 \t Train Acc:93.43 %  Valid Acc:87.41 %\n",
      "Epoch:52/100 \t Train Loss:0.1841 Valid Loss:0.4419 \t Train Acc:93.45 %  Valid Acc:87.48 %\n",
      "Epoch:53/100 \t Train Loss:0.1818 Valid Loss:0.4497 \t Train Acc:93.46 %  Valid Acc:87.01 %\n",
      "Epoch:54/100 \t Train Loss:0.1782 Valid Loss:0.4406 \t Train Acc:93.65 %  Valid Acc:87.23 %\n",
      "Epoch:55/100 \t Train Loss:0.1765 Valid Loss:0.4473 \t Train Acc:93.73 %  Valid Acc:87.38 %\n",
      "Epoch:56/100 \t Train Loss:0.1733 Valid Loss:0.4425 \t Train Acc:93.76 %  Valid Acc:87.50 %\n",
      "Epoch:57/100 \t Train Loss:0.1744 Valid Loss:0.4437 \t Train Acc:93.91 %  Valid Acc:87.40 %\n",
      "Epoch:58/100 \t Train Loss:0.1745 Valid Loss:0.4425 \t Train Acc:93.74 %  Valid Acc:87.37 %\n",
      "Epoch:59/100 \t Train Loss:0.1724 Valid Loss:0.4443 \t Train Acc:93.80 %  Valid Acc:87.63 %\n",
      "Epoch:60/100 \t Train Loss:0.1705 Valid Loss:0.4512 \t Train Acc:93.80 %  Valid Acc:87.47 %\n",
      "Epoch:61/100 \t Train Loss:0.1620 Valid Loss:0.4470 \t Train Acc:94.18 %  Valid Acc:87.75 %\n",
      "Epoch:62/100 \t Train Loss:0.1596 Valid Loss:0.4471 \t Train Acc:94.38 %  Valid Acc:87.83 %\n",
      "Epoch:63/100 \t Train Loss:0.1584 Valid Loss:0.4455 \t Train Acc:94.29 %  Valid Acc:87.75 %\n",
      "Epoch:64/100 \t Train Loss:0.1591 Valid Loss:0.4513 \t Train Acc:94.28 %  Valid Acc:87.75 %\n",
      "Epoch:65/100 \t Train Loss:0.1543 Valid Loss:0.4479 \t Train Acc:94.47 %  Valid Acc:87.68 %\n",
      "Epoch:66/100 \t Train Loss:0.1554 Valid Loss:0.4494 \t Train Acc:94.50 %  Valid Acc:87.74 %\n",
      "Epoch:67/100 \t Train Loss:0.1574 Valid Loss:0.4494 \t Train Acc:94.42 %  Valid Acc:87.75 %\n",
      "Epoch:68/100 \t Train Loss:0.1544 Valid Loss:0.4527 \t Train Acc:94.46 %  Valid Acc:87.48 %\n",
      "Epoch:69/100 \t Train Loss:0.1547 Valid Loss:0.4572 \t Train Acc:94.50 %  Valid Acc:87.68 %\n",
      "Epoch:70/100 \t Train Loss:0.1534 Valid Loss:0.4560 \t Train Acc:94.55 %  Valid Acc:87.61 %\n",
      "Epoch:71/100 \t Train Loss:0.1550 Valid Loss:0.4594 \t Train Acc:94.60 %  Valid Acc:87.65 %\n",
      "Epoch:72/100 \t Train Loss:0.1528 Valid Loss:0.4552 \t Train Acc:94.57 %  Valid Acc:87.78 %\n",
      "Epoch:73/100 \t Train Loss:0.1519 Valid Loss:0.4638 \t Train Acc:94.52 %  Valid Acc:87.61 %\n",
      "Epoch:74/100 \t Train Loss:0.1513 Valid Loss:0.4623 \t Train Acc:94.66 %  Valid Acc:87.65 %\n",
      "Epoch:75/100 \t Train Loss:0.1538 Valid Loss:0.4568 \t Train Acc:94.44 %  Valid Acc:87.68 %\n",
      "Epoch:76/100 \t Train Loss:0.1499 Valid Loss:0.4658 \t Train Acc:94.61 %  Valid Acc:87.59 %\n",
      "Epoch:77/100 \t Train Loss:0.1509 Valid Loss:0.4603 \t Train Acc:94.58 %  Valid Acc:87.63 %\n",
      "Epoch:78/100 \t Train Loss:0.1519 Valid Loss:0.4612 \t Train Acc:94.54 %  Valid Acc:87.55 %\n",
      "Epoch:79/100 \t Train Loss:0.1488 Valid Loss:0.4630 \t Train Acc:94.68 %  Valid Acc:87.64 %\n",
      "Epoch:80/100 \t Train Loss:0.1474 Valid Loss:0.4621 \t Train Acc:94.75 %  Valid Acc:87.45 %\n",
      "Epoch:81/100 \t Train Loss:0.1461 Valid Loss:0.4629 \t Train Acc:94.80 %  Valid Acc:87.56 %\n",
      "Epoch:82/100 \t Train Loss:0.1441 Valid Loss:0.4621 \t Train Acc:94.95 %  Valid Acc:87.57 %\n",
      "Epoch:83/100 \t Train Loss:0.1449 Valid Loss:0.4608 \t Train Acc:94.84 %  Valid Acc:87.53 %\n",
      "Epoch:84/100 \t Train Loss:0.1429 Valid Loss:0.4645 \t Train Acc:94.84 %  Valid Acc:87.60 %\n",
      "Epoch:85/100 \t Train Loss:0.1440 Valid Loss:0.4637 \t Train Acc:94.84 %  Valid Acc:87.54 %\n",
      "Epoch:86/100 \t Train Loss:0.1436 Valid Loss:0.4654 \t Train Acc:94.87 %  Valid Acc:87.60 %\n",
      "Epoch:87/100 \t Train Loss:0.1456 Valid Loss:0.4662 \t Train Acc:94.79 %  Valid Acc:87.59 %\n",
      "Epoch:88/100 \t Train Loss:0.1434 Valid Loss:0.4639 \t Train Acc:94.85 %  Valid Acc:87.57 %\n",
      "Epoch:89/100 \t Train Loss:0.1423 Valid Loss:0.4639 \t Train Acc:94.95 %  Valid Acc:87.68 %\n",
      "Epoch:90/100 \t Train Loss:0.1447 Valid Loss:0.4640 \t Train Acc:94.86 %  Valid Acc:87.71 %\n",
      "Epoch:91/100 \t Train Loss:0.1449 Valid Loss:0.4655 \t Train Acc:94.70 %  Valid Acc:87.66 %\n",
      "Epoch:92/100 \t Train Loss:0.1412 Valid Loss:0.4654 \t Train Acc:94.93 %  Valid Acc:87.61 %\n",
      "Epoch:93/100 \t Train Loss:0.1426 Valid Loss:0.4665 \t Train Acc:94.86 %  Valid Acc:87.65 %\n",
      "Epoch:94/100 \t Train Loss:0.1454 Valid Loss:0.4657 \t Train Acc:94.76 %  Valid Acc:87.62 %\n",
      "Epoch:95/100 \t Train Loss:0.1435 Valid Loss:0.4717 \t Train Acc:94.91 %  Valid Acc:87.55 %\n",
      "Epoch:96/100 \t Train Loss:0.1425 Valid Loss:0.4666 \t Train Acc:94.89 %  Valid Acc:87.68 %\n",
      "Epoch:97/100 \t Train Loss:0.1449 Valid Loss:0.4687 \t Train Acc:94.80 %  Valid Acc:87.63 %\n",
      "Epoch:98/100 \t Train Loss:0.1419 Valid Loss:0.4676 \t Train Acc:95.00 %  Valid Acc:87.60 %\n",
      "Epoch:99/100 \t Train Loss:0.1457 Valid Loss:0.4706 \t Train Acc:94.77 %  Valid Acc:87.58 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 10:45:54,301] Trial 16 finished with value: 87.64 and parameters: {'sigma_1': 2.552892614417707, 'sigma_2': 3.4882592168857727, 'sigma_3': 4.352113072004928, 'sigma_4': 0.738816595610332, 'sigma_5': 0.1056008808873683, 'sigma_6': 3.587607017492251, 'sigma_7': 3.4530867515762034, 'sigma_8': 2.8790174876906804, 'sigma_9': 3.1238297211006296, 'sigma_10': 0.12856715281533626, 'sigma_11': 3.217293494647598, 'sigma_12': 2.7807219332711726, 'sigma_13': 1.1450978029061871}. Best is trial 16 with value: 87.64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1394 Valid Loss:0.4679 \t Train Acc:95.01 %  Valid Acc:87.64 %\n",
      "Epoch:1/100 \t Train Loss:1.3975 Valid Loss:1.1530 \t Train Acc:49.09 %  Valid Acc:59.26 %\n",
      "Epoch:2/100 \t Train Loss:1.1011 Valid Loss:0.9716 \t Train Acc:60.49 %  Valid Acc:65.41 %\n",
      "Epoch:3/100 \t Train Loss:0.9843 Valid Loss:0.8994 \t Train Acc:65.03 %  Valid Acc:68.14 %\n",
      "Epoch:4/100 \t Train Loss:0.8777 Valid Loss:0.8442 \t Train Acc:69.14 %  Valid Acc:70.71 %\n",
      "Epoch:5/100 \t Train Loss:0.7799 Valid Loss:0.7708 \t Train Acc:72.55 %  Valid Acc:73.07 %\n",
      "Epoch:6/100 \t Train Loss:0.7182 Valid Loss:0.7278 \t Train Acc:75.01 %  Valid Acc:75.05 %\n",
      "Epoch:7/100 \t Train Loss:0.6725 Valid Loss:0.6751 \t Train Acc:76.46 %  Valid Acc:76.90 %\n",
      "Epoch:8/100 \t Train Loss:0.6371 Valid Loss:0.6853 \t Train Acc:77.85 %  Valid Acc:77.12 %\n",
      "Epoch:9/100 \t Train Loss:0.5931 Valid Loss:0.6229 \t Train Acc:79.40 %  Valid Acc:79.17 %\n",
      "Epoch:10/100 \t Train Loss:0.5707 Valid Loss:0.6282 \t Train Acc:80.15 %  Valid Acc:78.68 %\n",
      "Epoch:11/100 \t Train Loss:0.5496 Valid Loss:0.5463 \t Train Acc:80.92 %  Valid Acc:81.19 %\n",
      "Epoch:12/100 \t Train Loss:0.5262 Valid Loss:0.6022 \t Train Acc:81.70 %  Valid Acc:79.73 %\n",
      "Epoch:13/100 \t Train Loss:0.5027 Valid Loss:0.6172 \t Train Acc:82.65 %  Valid Acc:80.14 %\n",
      "Epoch:14/100 \t Train Loss:0.4904 Valid Loss:0.5830 \t Train Acc:83.14 %  Valid Acc:80.57 %\n",
      "Epoch:15/100 \t Train Loss:0.4707 Valid Loss:0.4972 \t Train Acc:83.61 %  Valid Acc:83.30 %\n",
      "Epoch:16/100 \t Train Loss:0.4591 Valid Loss:0.5278 \t Train Acc:83.95 %  Valid Acc:82.55 %\n",
      "Epoch:17/100 \t Train Loss:0.4459 Valid Loss:0.5061 \t Train Acc:84.25 %  Valid Acc:82.76 %\n",
      "Epoch:18/100 \t Train Loss:0.4358 Valid Loss:0.4937 \t Train Acc:84.88 %  Valid Acc:83.56 %\n",
      "Epoch:19/100 \t Train Loss:0.4247 Valid Loss:0.4954 \t Train Acc:85.23 %  Valid Acc:83.49 %\n",
      "Epoch:20/100 \t Train Loss:0.4158 Valid Loss:0.5179 \t Train Acc:85.58 %  Valid Acc:82.97 %\n",
      "Epoch:21/100 \t Train Loss:0.3358 Valid Loss:0.4491 \t Train Acc:88.27 %  Valid Acc:85.58 %\n",
      "Epoch:22/100 \t Train Loss:0.3160 Valid Loss:0.4320 \t Train Acc:88.90 %  Valid Acc:86.00 %\n",
      "Epoch:23/100 \t Train Loss:0.3099 Valid Loss:0.4472 \t Train Acc:89.23 %  Valid Acc:86.03 %\n",
      "Epoch:24/100 \t Train Loss:0.2981 Valid Loss:0.4322 \t Train Acc:89.63 %  Valid Acc:86.41 %\n",
      "Epoch:25/100 \t Train Loss:0.2937 Valid Loss:0.4382 \t Train Acc:89.69 %  Valid Acc:86.13 %\n",
      "Epoch:26/100 \t Train Loss:0.2864 Valid Loss:0.4321 \t Train Acc:89.93 %  Valid Acc:86.37 %\n",
      "Epoch:27/100 \t Train Loss:0.2826 Valid Loss:0.4500 \t Train Acc:90.17 %  Valid Acc:85.65 %\n",
      "Epoch:28/100 \t Train Loss:0.2791 Valid Loss:0.4362 \t Train Acc:90.09 %  Valid Acc:86.39 %\n",
      "Epoch:29/100 \t Train Loss:0.2740 Valid Loss:0.4218 \t Train Acc:90.36 %  Valid Acc:86.66 %\n",
      "Epoch:30/100 \t Train Loss:0.2693 Valid Loss:0.4327 \t Train Acc:90.36 %  Valid Acc:86.37 %\n",
      "Epoch:31/100 \t Train Loss:0.2684 Valid Loss:0.4679 \t Train Acc:90.59 %  Valid Acc:85.89 %\n",
      "Epoch:32/100 \t Train Loss:0.2612 Valid Loss:0.4478 \t Train Acc:90.72 %  Valid Acc:86.04 %\n",
      "Epoch:33/100 \t Train Loss:0.2588 Valid Loss:0.4378 \t Train Acc:90.92 %  Valid Acc:86.51 %\n",
      "Epoch:34/100 \t Train Loss:0.2529 Valid Loss:0.4479 \t Train Acc:91.06 %  Valid Acc:86.39 %\n",
      "Epoch:35/100 \t Train Loss:0.2498 Valid Loss:0.4457 \t Train Acc:91.40 %  Valid Acc:86.76 %\n",
      "Epoch:36/100 \t Train Loss:0.2513 Valid Loss:0.4471 \t Train Acc:90.95 %  Valid Acc:86.35 %\n",
      "Epoch:37/100 \t Train Loss:0.2436 Valid Loss:0.4392 \t Train Acc:91.34 %  Valid Acc:86.53 %\n",
      "Epoch:38/100 \t Train Loss:0.2416 Valid Loss:0.4531 \t Train Acc:91.44 %  Valid Acc:86.64 %\n",
      "Epoch:39/100 \t Train Loss:0.2392 Valid Loss:0.4488 \t Train Acc:91.54 %  Valid Acc:86.38 %\n",
      "Epoch:40/100 \t Train Loss:0.2400 Valid Loss:0.4494 \t Train Acc:91.61 %  Valid Acc:86.35 %\n",
      "Epoch:41/100 \t Train Loss:0.2049 Valid Loss:0.4400 \t Train Acc:92.85 %  Valid Acc:87.20 %\n",
      "Epoch:42/100 \t Train Loss:0.2009 Valid Loss:0.4355 \t Train Acc:92.96 %  Valid Acc:87.27 %\n",
      "Epoch:43/100 \t Train Loss:0.1981 Valid Loss:0.4403 \t Train Acc:93.04 %  Valid Acc:87.29 %\n",
      "Epoch:44/100 \t Train Loss:0.1934 Valid Loss:0.4452 \t Train Acc:93.17 %  Valid Acc:87.20 %\n",
      "Epoch:45/100 \t Train Loss:0.1922 Valid Loss:0.4393 \t Train Acc:93.17 %  Valid Acc:87.28 %\n",
      "Epoch:46/100 \t Train Loss:0.1930 Valid Loss:0.4435 \t Train Acc:93.09 %  Valid Acc:87.13 %\n",
      "Epoch:47/100 \t Train Loss:0.1934 Valid Loss:0.4423 \t Train Acc:93.19 %  Valid Acc:87.32 %\n",
      "Epoch:48/100 \t Train Loss:0.1900 Valid Loss:0.4453 \t Train Acc:93.28 %  Valid Acc:87.27 %\n",
      "Epoch:49/100 \t Train Loss:0.1908 Valid Loss:0.4515 \t Train Acc:93.21 %  Valid Acc:87.39 %\n",
      "Epoch:50/100 \t Train Loss:0.1851 Valid Loss:0.4441 \t Train Acc:93.44 %  Valid Acc:87.36 %\n",
      "Epoch:51/100 \t Train Loss:0.1838 Valid Loss:0.4458 \t Train Acc:93.49 %  Valid Acc:87.38 %\n",
      "Epoch:52/100 \t Train Loss:0.1836 Valid Loss:0.4549 \t Train Acc:93.48 %  Valid Acc:87.29 %\n",
      "Epoch:53/100 \t Train Loss:0.1836 Valid Loss:0.4510 \t Train Acc:93.45 %  Valid Acc:87.10 %\n",
      "Epoch:54/100 \t Train Loss:0.1815 Valid Loss:0.4531 \t Train Acc:93.50 %  Valid Acc:87.32 %\n",
      "Epoch:55/100 \t Train Loss:0.1797 Valid Loss:0.4557 \t Train Acc:93.63 %  Valid Acc:87.05 %\n",
      "Epoch:56/100 \t Train Loss:0.1796 Valid Loss:0.4540 \t Train Acc:93.51 %  Valid Acc:87.23 %\n",
      "Epoch:57/100 \t Train Loss:0.1766 Valid Loss:0.4560 \t Train Acc:93.65 %  Valid Acc:87.43 %\n",
      "Epoch:58/100 \t Train Loss:0.1747 Valid Loss:0.4639 \t Train Acc:93.73 %  Valid Acc:86.94 %\n",
      "Epoch:59/100 \t Train Loss:0.1726 Valid Loss:0.4661 \t Train Acc:93.77 %  Valid Acc:87.39 %\n",
      "Epoch:60/100 \t Train Loss:0.1759 Valid Loss:0.4667 \t Train Acc:93.75 %  Valid Acc:86.96 %\n",
      "Epoch:61/100 \t Train Loss:0.1637 Valid Loss:0.4561 \t Train Acc:94.25 %  Valid Acc:87.36 %\n",
      "Epoch:62/100 \t Train Loss:0.1622 Valid Loss:0.4542 \t Train Acc:94.31 %  Valid Acc:87.24 %\n",
      "Epoch:63/100 \t Train Loss:0.1623 Valid Loss:0.4568 \t Train Acc:94.22 %  Valid Acc:87.44 %\n",
      "Epoch:64/100 \t Train Loss:0.1588 Valid Loss:0.4570 \t Train Acc:94.36 %  Valid Acc:87.48 %\n",
      "Epoch:65/100 \t Train Loss:0.1597 Valid Loss:0.4581 \t Train Acc:94.31 %  Valid Acc:87.52 %\n",
      "Epoch:66/100 \t Train Loss:0.1585 Valid Loss:0.4599 \t Train Acc:94.35 %  Valid Acc:87.43 %\n",
      "Epoch:67/100 \t Train Loss:0.1591 Valid Loss:0.4627 \t Train Acc:94.26 %  Valid Acc:87.29 %\n",
      "Epoch:68/100 \t Train Loss:0.1563 Valid Loss:0.4623 \t Train Acc:94.45 %  Valid Acc:87.31 %\n",
      "Epoch:69/100 \t Train Loss:0.1555 Valid Loss:0.4672 \t Train Acc:94.42 %  Valid Acc:87.29 %\n",
      "Epoch:70/100 \t Train Loss:0.1577 Valid Loss:0.4654 \t Train Acc:94.28 %  Valid Acc:87.49 %\n",
      "Epoch:71/100 \t Train Loss:0.1597 Valid Loss:0.4647 \t Train Acc:94.32 %  Valid Acc:87.50 %\n",
      "Epoch:72/100 \t Train Loss:0.1520 Valid Loss:0.4657 \t Train Acc:94.59 %  Valid Acc:87.37 %\n",
      "Epoch:73/100 \t Train Loss:0.1550 Valid Loss:0.4652 \t Train Acc:94.56 %  Valid Acc:87.27 %\n",
      "Epoch:74/100 \t Train Loss:0.1531 Valid Loss:0.4658 \t Train Acc:94.53 %  Valid Acc:87.37 %\n",
      "Epoch:75/100 \t Train Loss:0.1544 Valid Loss:0.4664 \t Train Acc:94.61 %  Valid Acc:87.42 %\n",
      "Epoch:76/100 \t Train Loss:0.1544 Valid Loss:0.4711 \t Train Acc:94.51 %  Valid Acc:87.23 %\n",
      "Epoch:77/100 \t Train Loss:0.1540 Valid Loss:0.4662 \t Train Acc:94.42 %  Valid Acc:87.45 %\n",
      "Epoch:78/100 \t Train Loss:0.1525 Valid Loss:0.4676 \t Train Acc:94.51 %  Valid Acc:87.37 %\n",
      "Epoch:79/100 \t Train Loss:0.1520 Valid Loss:0.4722 \t Train Acc:94.59 %  Valid Acc:87.24 %\n",
      "Epoch:80/100 \t Train Loss:0.1494 Valid Loss:0.4726 \t Train Acc:94.77 %  Valid Acc:87.24 %\n",
      "Epoch:81/100 \t Train Loss:0.1512 Valid Loss:0.4682 \t Train Acc:94.69 %  Valid Acc:87.40 %\n",
      "Epoch:82/100 \t Train Loss:0.1474 Valid Loss:0.4707 \t Train Acc:94.77 %  Valid Acc:87.37 %\n",
      "Epoch:83/100 \t Train Loss:0.1463 Valid Loss:0.4715 \t Train Acc:94.83 %  Valid Acc:87.47 %\n",
      "Epoch:84/100 \t Train Loss:0.1490 Valid Loss:0.4705 \t Train Acc:94.69 %  Valid Acc:87.56 %\n",
      "Epoch:85/100 \t Train Loss:0.1485 Valid Loss:0.4690 \t Train Acc:94.65 %  Valid Acc:87.47 %\n",
      "Epoch:86/100 \t Train Loss:0.1455 Valid Loss:0.4690 \t Train Acc:94.79 %  Valid Acc:87.49 %\n",
      "Epoch:87/100 \t Train Loss:0.1476 Valid Loss:0.4709 \t Train Acc:94.73 %  Valid Acc:87.39 %\n",
      "Epoch:88/100 \t Train Loss:0.1505 Valid Loss:0.4693 \t Train Acc:94.63 %  Valid Acc:87.39 %\n",
      "Epoch:89/100 \t Train Loss:0.1445 Valid Loss:0.4702 \t Train Acc:94.78 %  Valid Acc:87.43 %\n",
      "Epoch:90/100 \t Train Loss:0.1483 Valid Loss:0.4730 \t Train Acc:94.73 %  Valid Acc:87.44 %\n",
      "Epoch:91/100 \t Train Loss:0.1461 Valid Loss:0.4685 \t Train Acc:94.95 %  Valid Acc:87.40 %\n",
      "Epoch:92/100 \t Train Loss:0.1474 Valid Loss:0.4726 \t Train Acc:94.78 %  Valid Acc:87.46 %\n",
      "Epoch:93/100 \t Train Loss:0.1453 Valid Loss:0.4713 \t Train Acc:94.71 %  Valid Acc:87.31 %\n",
      "Epoch:94/100 \t Train Loss:0.1445 Valid Loss:0.4708 \t Train Acc:94.80 %  Valid Acc:87.38 %\n",
      "Epoch:95/100 \t Train Loss:0.1447 Valid Loss:0.4726 \t Train Acc:94.89 %  Valid Acc:87.48 %\n",
      "Epoch:96/100 \t Train Loss:0.1455 Valid Loss:0.4743 \t Train Acc:94.79 %  Valid Acc:87.36 %\n",
      "Epoch:97/100 \t Train Loss:0.1465 Valid Loss:0.4742 \t Train Acc:94.77 %  Valid Acc:87.40 %\n",
      "Epoch:98/100 \t Train Loss:0.1440 Valid Loss:0.4755 \t Train Acc:94.87 %  Valid Acc:87.29 %\n",
      "Epoch:99/100 \t Train Loss:0.1445 Valid Loss:0.4763 \t Train Acc:94.85 %  Valid Acc:87.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 12:04:43,405] Trial 17 finished with value: 87.37 and parameters: {'sigma_1': 2.626044487717572, 'sigma_2': 3.238226035024801, 'sigma_3': 4.22071827079075, 'sigma_4': 0.1264545490086569, 'sigma_5': 0.18330192682061286, 'sigma_6': 3.422046909955416, 'sigma_7': 4.9957083788676035, 'sigma_8': 2.5872621751660505, 'sigma_9': 4.914985561697237, 'sigma_10': 0.13355375569485162, 'sigma_11': 1.7022467563977164, 'sigma_12': 2.8722467099380102, 'sigma_13': 2.378898647545772}. Best is trial 16 with value: 87.64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1446 Valid Loss:0.4766 \t Train Acc:94.80 %  Valid Acc:87.37 %\n",
      "Epoch:1/100 \t Train Loss:1.4858 Valid Loss:1.2230 \t Train Acc:45.28 %  Valid Acc:55.80 %\n",
      "Epoch:2/100 \t Train Loss:1.1330 Valid Loss:1.0171 \t Train Acc:59.07 %  Valid Acc:63.48 %\n",
      "Epoch:3/100 \t Train Loss:0.9950 Valid Loss:0.9477 \t Train Acc:64.56 %  Valid Acc:66.22 %\n",
      "Epoch:4/100 \t Train Loss:0.9072 Valid Loss:0.8739 \t Train Acc:67.76 %  Valid Acc:69.16 %\n",
      "Epoch:5/100 \t Train Loss:0.8194 Valid Loss:0.7939 \t Train Acc:70.97 %  Valid Acc:71.21 %\n",
      "Epoch:6/100 \t Train Loss:0.7620 Valid Loss:0.7307 \t Train Acc:73.01 %  Valid Acc:75.04 %\n",
      "Epoch:7/100 \t Train Loss:0.7029 Valid Loss:0.7332 \t Train Acc:75.25 %  Valid Acc:74.49 %\n",
      "Epoch:8/100 \t Train Loss:0.6553 Valid Loss:0.6371 \t Train Acc:76.91 %  Valid Acc:78.01 %\n",
      "Epoch:9/100 \t Train Loss:0.6140 Valid Loss:0.6182 \t Train Acc:78.34 %  Valid Acc:78.87 %\n",
      "Epoch:10/100 \t Train Loss:0.5752 Valid Loss:0.6459 \t Train Acc:79.94 %  Valid Acc:78.46 %\n",
      "Epoch:11/100 \t Train Loss:0.5536 Valid Loss:0.5926 \t Train Acc:80.89 %  Valid Acc:80.12 %\n",
      "Epoch:12/100 \t Train Loss:0.5252 Valid Loss:0.6187 \t Train Acc:81.63 %  Valid Acc:79.57 %\n",
      "Epoch:13/100 \t Train Loss:0.5104 Valid Loss:0.5380 \t Train Acc:82.12 %  Valid Acc:82.05 %\n",
      "Epoch:14/100 \t Train Loss:0.4914 Valid Loss:0.5564 \t Train Acc:82.82 %  Valid Acc:81.46 %\n",
      "Epoch:15/100 \t Train Loss:0.4809 Valid Loss:0.5366 \t Train Acc:83.28 %  Valid Acc:81.70 %\n",
      "Epoch:16/100 \t Train Loss:0.4649 Valid Loss:0.5725 \t Train Acc:83.84 %  Valid Acc:80.59 %\n",
      "Epoch:17/100 \t Train Loss:0.4483 Valid Loss:0.4997 \t Train Acc:84.33 %  Valid Acc:82.91 %\n",
      "Epoch:18/100 \t Train Loss:0.4376 Valid Loss:0.5012 \t Train Acc:84.78 %  Valid Acc:83.07 %\n",
      "Epoch:19/100 \t Train Loss:0.4264 Valid Loss:0.5035 \t Train Acc:85.07 %  Valid Acc:83.16 %\n",
      "Epoch:20/100 \t Train Loss:0.4170 Valid Loss:0.5130 \t Train Acc:85.25 %  Valid Acc:83.12 %\n",
      "Epoch:21/100 \t Train Loss:0.3368 Valid Loss:0.4476 \t Train Acc:88.24 %  Valid Acc:85.14 %\n",
      "Epoch:22/100 \t Train Loss:0.3171 Valid Loss:0.4472 \t Train Acc:88.86 %  Valid Acc:85.51 %\n",
      "Epoch:23/100 \t Train Loss:0.3126 Valid Loss:0.4456 \t Train Acc:89.14 %  Valid Acc:85.53 %\n",
      "Epoch:24/100 \t Train Loss:0.3044 Valid Loss:0.4514 \t Train Acc:89.17 %  Valid Acc:85.67 %\n",
      "Epoch:25/100 \t Train Loss:0.2998 Valid Loss:0.4316 \t Train Acc:89.27 %  Valid Acc:85.91 %\n",
      "Epoch:26/100 \t Train Loss:0.2910 Valid Loss:0.4419 \t Train Acc:89.75 %  Valid Acc:85.87 %\n",
      "Epoch:27/100 \t Train Loss:0.2869 Valid Loss:0.4342 \t Train Acc:89.92 %  Valid Acc:85.95 %\n",
      "Epoch:28/100 \t Train Loss:0.2844 Valid Loss:0.4430 \t Train Acc:89.96 %  Valid Acc:85.98 %\n",
      "Epoch:29/100 \t Train Loss:0.2753 Valid Loss:0.4394 \t Train Acc:90.25 %  Valid Acc:86.15 %\n",
      "Epoch:30/100 \t Train Loss:0.2723 Valid Loss:0.4444 \t Train Acc:90.44 %  Valid Acc:86.59 %\n",
      "Epoch:31/100 \t Train Loss:0.2716 Valid Loss:0.4361 \t Train Acc:90.40 %  Valid Acc:86.55 %\n",
      "Epoch:32/100 \t Train Loss:0.2680 Valid Loss:0.4462 \t Train Acc:90.44 %  Valid Acc:85.92 %\n",
      "Epoch:33/100 \t Train Loss:0.2632 Valid Loss:0.4402 \t Train Acc:90.62 %  Valid Acc:85.96 %\n",
      "Epoch:34/100 \t Train Loss:0.2571 Valid Loss:0.4396 \t Train Acc:90.89 %  Valid Acc:86.40 %\n",
      "Epoch:35/100 \t Train Loss:0.2524 Valid Loss:0.4354 \t Train Acc:91.04 %  Valid Acc:86.42 %\n",
      "Epoch:36/100 \t Train Loss:0.2503 Valid Loss:0.4488 \t Train Acc:90.91 %  Valid Acc:86.27 %\n",
      "Epoch:37/100 \t Train Loss:0.2444 Valid Loss:0.4322 \t Train Acc:91.44 %  Valid Acc:86.70 %\n",
      "Epoch:38/100 \t Train Loss:0.2457 Valid Loss:0.4322 \t Train Acc:91.17 %  Valid Acc:86.48 %\n",
      "Epoch:39/100 \t Train Loss:0.2425 Valid Loss:0.4307 \t Train Acc:91.30 %  Valid Acc:86.49 %\n",
      "Epoch:40/100 \t Train Loss:0.2356 Valid Loss:0.4317 \t Train Acc:91.74 %  Valid Acc:86.36 %\n",
      "Epoch:41/100 \t Train Loss:0.2103 Valid Loss:0.4294 \t Train Acc:92.62 %  Valid Acc:86.91 %\n",
      "Epoch:42/100 \t Train Loss:0.2015 Valid Loss:0.4288 \t Train Acc:92.88 %  Valid Acc:86.98 %\n",
      "Epoch:43/100 \t Train Loss:0.2009 Valid Loss:0.4330 \t Train Acc:92.97 %  Valid Acc:87.00 %\n",
      "Epoch:44/100 \t Train Loss:0.1991 Valid Loss:0.4299 \t Train Acc:92.94 %  Valid Acc:87.00 %\n",
      "Epoch:45/100 \t Train Loss:0.1961 Valid Loss:0.4356 \t Train Acc:93.06 %  Valid Acc:87.08 %\n",
      "Epoch:46/100 \t Train Loss:0.1939 Valid Loss:0.4378 \t Train Acc:93.08 %  Valid Acc:86.98 %\n",
      "Epoch:47/100 \t Train Loss:0.1923 Valid Loss:0.4358 \t Train Acc:93.10 %  Valid Acc:87.11 %\n",
      "Epoch:48/100 \t Train Loss:0.1932 Valid Loss:0.4434 \t Train Acc:93.14 %  Valid Acc:87.11 %\n",
      "Epoch:49/100 \t Train Loss:0.1898 Valid Loss:0.4408 \t Train Acc:93.27 %  Valid Acc:87.26 %\n",
      "Epoch:50/100 \t Train Loss:0.1894 Valid Loss:0.4344 \t Train Acc:93.12 %  Valid Acc:87.46 %\n",
      "Epoch:51/100 \t Train Loss:0.1870 Valid Loss:0.4417 \t Train Acc:93.26 %  Valid Acc:87.28 %\n",
      "Epoch:52/100 \t Train Loss:0.1833 Valid Loss:0.4382 \t Train Acc:93.43 %  Valid Acc:87.44 %\n",
      "Epoch:53/100 \t Train Loss:0.1828 Valid Loss:0.4474 \t Train Acc:93.54 %  Valid Acc:86.79 %\n",
      "Epoch:54/100 \t Train Loss:0.1823 Valid Loss:0.4465 \t Train Acc:93.45 %  Valid Acc:86.94 %\n",
      "Epoch:55/100 \t Train Loss:0.1795 Valid Loss:0.4481 \t Train Acc:93.65 %  Valid Acc:87.11 %\n",
      "Epoch:56/100 \t Train Loss:0.1786 Valid Loss:0.4459 \t Train Acc:93.63 %  Valid Acc:87.00 %\n",
      "Epoch:57/100 \t Train Loss:0.1772 Valid Loss:0.4504 \t Train Acc:93.67 %  Valid Acc:86.97 %\n",
      "Epoch:58/100 \t Train Loss:0.1748 Valid Loss:0.4494 \t Train Acc:93.67 %  Valid Acc:87.11 %\n",
      "Epoch:59/100 \t Train Loss:0.1764 Valid Loss:0.4616 \t Train Acc:93.67 %  Valid Acc:87.13 %\n",
      "Epoch:60/100 \t Train Loss:0.1766 Valid Loss:0.4555 \t Train Acc:93.65 %  Valid Acc:87.05 %\n",
      "Epoch:61/100 \t Train Loss:0.1672 Valid Loss:0.4508 \t Train Acc:94.12 %  Valid Acc:87.32 %\n",
      "Epoch:62/100 \t Train Loss:0.1624 Valid Loss:0.4519 \t Train Acc:94.15 %  Valid Acc:87.42 %\n",
      "Epoch:63/100 \t Train Loss:0.1640 Valid Loss:0.4569 \t Train Acc:94.12 %  Valid Acc:87.25 %\n",
      "Epoch:64/100 \t Train Loss:0.1637 Valid Loss:0.4562 \t Train Acc:94.24 %  Valid Acc:87.10 %\n",
      "Epoch:65/100 \t Train Loss:0.1629 Valid Loss:0.4510 \t Train Acc:94.16 %  Valid Acc:87.35 %\n",
      "Epoch:66/100 \t Train Loss:0.1610 Valid Loss:0.4565 \t Train Acc:94.35 %  Valid Acc:87.21 %\n",
      "Epoch:67/100 \t Train Loss:0.1588 Valid Loss:0.4582 \t Train Acc:94.24 %  Valid Acc:87.15 %\n",
      "Epoch:68/100 \t Train Loss:0.1584 Valid Loss:0.4575 \t Train Acc:94.41 %  Valid Acc:87.40 %\n",
      "Epoch:69/100 \t Train Loss:0.1610 Valid Loss:0.4571 \t Train Acc:94.27 %  Valid Acc:87.36 %\n",
      "Epoch:70/100 \t Train Loss:0.1595 Valid Loss:0.4578 \t Train Acc:94.38 %  Valid Acc:87.38 %\n",
      "Epoch:71/100 \t Train Loss:0.1606 Valid Loss:0.4579 \t Train Acc:94.27 %  Valid Acc:87.22 %\n",
      "Epoch:72/100 \t Train Loss:0.1551 Valid Loss:0.4602 \t Train Acc:94.49 %  Valid Acc:87.27 %\n",
      "Epoch:73/100 \t Train Loss:0.1595 Valid Loss:0.4639 \t Train Acc:94.25 %  Valid Acc:87.34 %\n",
      "Epoch:74/100 \t Train Loss:0.1555 Valid Loss:0.4581 \t Train Acc:94.43 %  Valid Acc:87.29 %\n",
      "Epoch:75/100 \t Train Loss:0.1565 Valid Loss:0.4618 \t Train Acc:94.37 %  Valid Acc:87.27 %\n",
      "Epoch:76/100 \t Train Loss:0.1553 Valid Loss:0.4598 \t Train Acc:94.35 %  Valid Acc:87.31 %\n",
      "Epoch:77/100 \t Train Loss:0.1552 Valid Loss:0.4591 \t Train Acc:94.42 %  Valid Acc:87.41 %\n",
      "Epoch:78/100 \t Train Loss:0.1521 Valid Loss:0.4663 \t Train Acc:94.59 %  Valid Acc:87.15 %\n",
      "Epoch:79/100 \t Train Loss:0.1558 Valid Loss:0.4601 \t Train Acc:94.45 %  Valid Acc:87.34 %\n",
      "Epoch:80/100 \t Train Loss:0.1509 Valid Loss:0.4663 \t Train Acc:94.64 %  Valid Acc:87.19 %\n",
      "Epoch:81/100 \t Train Loss:0.1506 Valid Loss:0.4633 \t Train Acc:94.73 %  Valid Acc:87.27 %\n",
      "Epoch:82/100 \t Train Loss:0.1515 Valid Loss:0.4642 \t Train Acc:94.56 %  Valid Acc:87.22 %\n",
      "Epoch:83/100 \t Train Loss:0.1485 Valid Loss:0.4639 \t Train Acc:94.71 %  Valid Acc:87.41 %\n",
      "Epoch:84/100 \t Train Loss:0.1495 Valid Loss:0.4634 \t Train Acc:94.65 %  Valid Acc:87.34 %\n",
      "Epoch:85/100 \t Train Loss:0.1489 Valid Loss:0.4654 \t Train Acc:94.78 %  Valid Acc:87.28 %\n",
      "Epoch:86/100 \t Train Loss:0.1487 Valid Loss:0.4630 \t Train Acc:94.70 %  Valid Acc:87.46 %\n",
      "Epoch:87/100 \t Train Loss:0.1496 Valid Loss:0.4641 \t Train Acc:94.74 %  Valid Acc:87.25 %\n",
      "Epoch:88/100 \t Train Loss:0.1487 Valid Loss:0.4629 \t Train Acc:94.72 %  Valid Acc:87.30 %\n",
      "Epoch:89/100 \t Train Loss:0.1480 Valid Loss:0.4648 \t Train Acc:94.72 %  Valid Acc:87.29 %\n",
      "Epoch:90/100 \t Train Loss:0.1463 Valid Loss:0.4665 \t Train Acc:94.80 %  Valid Acc:87.26 %\n",
      "Epoch:91/100 \t Train Loss:0.1448 Valid Loss:0.4675 \t Train Acc:94.85 %  Valid Acc:87.25 %\n",
      "Epoch:92/100 \t Train Loss:0.1479 Valid Loss:0.4695 \t Train Acc:94.68 %  Valid Acc:87.32 %\n",
      "Epoch:93/100 \t Train Loss:0.1474 Valid Loss:0.4673 \t Train Acc:94.64 %  Valid Acc:87.26 %\n",
      "Epoch:94/100 \t Train Loss:0.1495 Valid Loss:0.4649 \t Train Acc:94.70 %  Valid Acc:87.26 %\n",
      "Epoch:95/100 \t Train Loss:0.1435 Valid Loss:0.4697 \t Train Acc:94.78 %  Valid Acc:87.15 %\n",
      "Epoch:96/100 \t Train Loss:0.1468 Valid Loss:0.4668 \t Train Acc:94.77 %  Valid Acc:87.21 %\n",
      "Epoch:97/100 \t Train Loss:0.1471 Valid Loss:0.4697 \t Train Acc:94.76 %  Valid Acc:87.16 %\n",
      "Epoch:98/100 \t Train Loss:0.1473 Valid Loss:0.4690 \t Train Acc:94.70 %  Valid Acc:87.31 %\n",
      "Epoch:99/100 \t Train Loss:0.1471 Valid Loss:0.4660 \t Train Acc:94.69 %  Valid Acc:87.39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 13:24:24,837] Trial 18 finished with value: 87.33999999999999 and parameters: {'sigma_1': 2.7024356361231927, 'sigma_2': 3.9679345761297053, 'sigma_3': 3.4105596936675955, 'sigma_4': 1.6812633123351326, 'sigma_5': 0.7211859155353433, 'sigma_6': 3.3831713546077644, 'sigma_7': 3.331247144811644, 'sigma_8': 3.025150310748803, 'sigma_9': 3.1695391281493617, 'sigma_10': 0.654886961988781, 'sigma_11': 3.0469020180884554, 'sigma_12': 3.7067735456569433, 'sigma_13': 1.0558307429209117}. Best is trial 16 with value: 87.64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1464 Valid Loss:0.4666 \t Train Acc:94.76 %  Valid Acc:87.34 %\n",
      "Epoch:1/100 \t Train Loss:1.5069 Valid Loss:1.3054 \t Train Acc:44.28 %  Valid Acc:52.95 %\n",
      "Epoch:2/100 \t Train Loss:1.1344 Valid Loss:1.0242 \t Train Acc:59.01 %  Valid Acc:63.44 %\n",
      "Epoch:3/100 \t Train Loss:0.9736 Valid Loss:0.9358 \t Train Acc:65.13 %  Valid Acc:67.18 %\n",
      "Epoch:4/100 \t Train Loss:0.8719 Valid Loss:0.8092 \t Train Acc:68.87 %  Valid Acc:71.16 %\n",
      "Epoch:5/100 \t Train Loss:0.7886 Valid Loss:0.7844 \t Train Acc:72.45 %  Valid Acc:72.69 %\n",
      "Epoch:6/100 \t Train Loss:0.7258 Valid Loss:0.7279 \t Train Acc:74.44 %  Valid Acc:75.06 %\n",
      "Epoch:7/100 \t Train Loss:0.6739 Valid Loss:0.6824 \t Train Acc:76.54 %  Valid Acc:77.05 %\n",
      "Epoch:8/100 \t Train Loss:0.6317 Valid Loss:0.7362 \t Train Acc:78.09 %  Valid Acc:74.99 %\n",
      "Epoch:9/100 \t Train Loss:0.5969 Valid Loss:0.6703 \t Train Acc:79.24 %  Valid Acc:76.94 %\n",
      "Epoch:10/100 \t Train Loss:0.5688 Valid Loss:0.5644 \t Train Acc:80.20 %  Valid Acc:80.50 %\n",
      "Epoch:11/100 \t Train Loss:0.5370 Valid Loss:0.6064 \t Train Acc:81.36 %  Valid Acc:79.46 %\n",
      "Epoch:12/100 \t Train Loss:0.5302 Valid Loss:0.5933 \t Train Acc:81.41 %  Valid Acc:79.62 %\n",
      "Epoch:13/100 \t Train Loss:0.5055 Valid Loss:0.5384 \t Train Acc:82.31 %  Valid Acc:81.69 %\n",
      "Epoch:14/100 \t Train Loss:0.4908 Valid Loss:0.5480 \t Train Acc:83.09 %  Valid Acc:81.48 %\n",
      "Epoch:15/100 \t Train Loss:0.4677 Valid Loss:0.5480 \t Train Acc:83.71 %  Valid Acc:81.48 %\n",
      "Epoch:16/100 \t Train Loss:0.4620 Valid Loss:0.5454 \t Train Acc:83.89 %  Valid Acc:81.61 %\n",
      "Epoch:17/100 \t Train Loss:0.4441 Valid Loss:0.5439 \t Train Acc:84.50 %  Valid Acc:82.28 %\n",
      "Epoch:18/100 \t Train Loss:0.4348 Valid Loss:0.4994 \t Train Acc:84.77 %  Valid Acc:83.51 %\n",
      "Epoch:19/100 \t Train Loss:0.4220 Valid Loss:0.5088 \t Train Acc:85.23 %  Valid Acc:83.29 %\n",
      "Epoch:20/100 \t Train Loss:0.4133 Valid Loss:0.5162 \t Train Acc:85.61 %  Valid Acc:82.70 %\n",
      "Epoch:21/100 \t Train Loss:0.3366 Valid Loss:0.4416 \t Train Acc:88.20 %  Valid Acc:85.19 %\n",
      "Epoch:22/100 \t Train Loss:0.3215 Valid Loss:0.4683 \t Train Acc:88.80 %  Valid Acc:85.13 %\n",
      "Epoch:23/100 \t Train Loss:0.3116 Valid Loss:0.4355 \t Train Acc:89.08 %  Valid Acc:85.87 %\n",
      "Epoch:24/100 \t Train Loss:0.3041 Valid Loss:0.4365 \t Train Acc:89.43 %  Valid Acc:85.65 %\n",
      "Epoch:25/100 \t Train Loss:0.2983 Valid Loss:0.4538 \t Train Acc:89.52 %  Valid Acc:85.32 %\n",
      "Epoch:26/100 \t Train Loss:0.2888 Valid Loss:0.4578 \t Train Acc:89.82 %  Valid Acc:85.08 %\n",
      "Epoch:27/100 \t Train Loss:0.2846 Valid Loss:0.4391 \t Train Acc:89.99 %  Valid Acc:85.84 %\n",
      "Epoch:28/100 \t Train Loss:0.2822 Valid Loss:0.4330 \t Train Acc:90.06 %  Valid Acc:85.96 %\n",
      "Epoch:29/100 \t Train Loss:0.2776 Valid Loss:0.4611 \t Train Acc:90.13 %  Valid Acc:85.56 %\n",
      "Epoch:30/100 \t Train Loss:0.2755 Valid Loss:0.4470 \t Train Acc:90.35 %  Valid Acc:85.77 %\n",
      "Epoch:31/100 \t Train Loss:0.2701 Valid Loss:0.4452 \t Train Acc:90.35 %  Valid Acc:85.73 %\n",
      "Epoch:32/100 \t Train Loss:0.2687 Valid Loss:0.4666 \t Train Acc:90.53 %  Valid Acc:84.95 %\n",
      "Epoch:33/100 \t Train Loss:0.2635 Valid Loss:0.4373 \t Train Acc:90.81 %  Valid Acc:86.07 %\n",
      "Epoch:34/100 \t Train Loss:0.2616 Valid Loss:0.4416 \t Train Acc:90.84 %  Valid Acc:85.99 %\n",
      "Epoch:35/100 \t Train Loss:0.2579 Valid Loss:0.4477 \t Train Acc:91.00 %  Valid Acc:85.79 %\n",
      "Epoch:36/100 \t Train Loss:0.2514 Valid Loss:0.4570 \t Train Acc:91.17 %  Valid Acc:86.00 %\n",
      "Epoch:37/100 \t Train Loss:0.2505 Valid Loss:0.4518 \t Train Acc:91.16 %  Valid Acc:85.87 %\n",
      "Epoch:38/100 \t Train Loss:0.2477 Valid Loss:0.4454 \t Train Acc:91.37 %  Valid Acc:86.26 %\n",
      "Epoch:39/100 \t Train Loss:0.2446 Valid Loss:0.4506 \t Train Acc:91.36 %  Valid Acc:86.11 %\n",
      "Epoch:40/100 \t Train Loss:0.2432 Valid Loss:0.4702 \t Train Acc:91.31 %  Valid Acc:85.56 %\n",
      "Epoch:41/100 \t Train Loss:0.2111 Valid Loss:0.4419 \t Train Acc:92.56 %  Valid Acc:86.52 %\n",
      "Epoch:42/100 \t Train Loss:0.2070 Valid Loss:0.4379 \t Train Acc:92.62 %  Valid Acc:86.74 %\n",
      "Epoch:43/100 \t Train Loss:0.2016 Valid Loss:0.4461 \t Train Acc:92.67 %  Valid Acc:86.65 %\n",
      "Epoch:44/100 \t Train Loss:0.2023 Valid Loss:0.4386 \t Train Acc:92.79 %  Valid Acc:86.70 %\n",
      "Epoch:45/100 \t Train Loss:0.1987 Valid Loss:0.4509 \t Train Acc:93.03 %  Valid Acc:86.56 %\n",
      "Epoch:46/100 \t Train Loss:0.1954 Valid Loss:0.4522 \t Train Acc:93.04 %  Valid Acc:86.51 %\n",
      "Epoch:47/100 \t Train Loss:0.1976 Valid Loss:0.4461 \t Train Acc:92.86 %  Valid Acc:86.60 %\n",
      "Epoch:48/100 \t Train Loss:0.1921 Valid Loss:0.4617 \t Train Acc:93.09 %  Valid Acc:86.52 %\n",
      "Epoch:49/100 \t Train Loss:0.1908 Valid Loss:0.4646 \t Train Acc:93.16 %  Valid Acc:86.52 %\n",
      "Epoch:50/100 \t Train Loss:0.1900 Valid Loss:0.4553 \t Train Acc:93.20 %  Valid Acc:86.83 %\n",
      "Epoch:51/100 \t Train Loss:0.1912 Valid Loss:0.4394 \t Train Acc:93.17 %  Valid Acc:86.88 %\n",
      "Epoch:52/100 \t Train Loss:0.1883 Valid Loss:0.4536 \t Train Acc:93.31 %  Valid Acc:86.79 %\n",
      "Epoch:53/100 \t Train Loss:0.1864 Valid Loss:0.4570 \t Train Acc:93.30 %  Valid Acc:86.48 %\n",
      "Epoch:54/100 \t Train Loss:0.1883 Valid Loss:0.4651 \t Train Acc:93.31 %  Valid Acc:86.59 %\n",
      "Epoch:55/100 \t Train Loss:0.1835 Valid Loss:0.4556 \t Train Acc:93.35 %  Valid Acc:86.57 %\n",
      "Epoch:56/100 \t Train Loss:0.1821 Valid Loss:0.4710 \t Train Acc:93.51 %  Valid Acc:86.78 %\n",
      "Epoch:57/100 \t Train Loss:0.1790 Valid Loss:0.4590 \t Train Acc:93.62 %  Valid Acc:86.79 %\n",
      "Epoch:58/100 \t Train Loss:0.1809 Valid Loss:0.4742 \t Train Acc:93.62 %  Valid Acc:86.57 %\n",
      "Epoch:59/100 \t Train Loss:0.1797 Valid Loss:0.4709 \t Train Acc:93.52 %  Valid Acc:86.32 %\n",
      "Epoch:60/100 \t Train Loss:0.1770 Valid Loss:0.4657 \t Train Acc:93.68 %  Valid Acc:86.79 %\n",
      "Epoch:61/100 \t Train Loss:0.1702 Valid Loss:0.4650 \t Train Acc:94.01 %  Valid Acc:87.03 %\n",
      "Epoch:62/100 \t Train Loss:0.1694 Valid Loss:0.4630 \t Train Acc:93.86 %  Valid Acc:87.01 %\n",
      "Epoch:63/100 \t Train Loss:0.1651 Valid Loss:0.4646 \t Train Acc:94.12 %  Valid Acc:87.03 %\n",
      "Epoch:64/100 \t Train Loss:0.1643 Valid Loss:0.4737 \t Train Acc:94.18 %  Valid Acc:87.02 %\n",
      "Epoch:65/100 \t Train Loss:0.1651 Valid Loss:0.4715 \t Train Acc:93.92 %  Valid Acc:86.81 %\n",
      "Epoch:66/100 \t Train Loss:0.1634 Valid Loss:0.4665 \t Train Acc:94.14 %  Valid Acc:87.00 %\n",
      "Epoch:67/100 \t Train Loss:0.1608 Valid Loss:0.4712 \t Train Acc:94.25 %  Valid Acc:86.85 %\n",
      "Epoch:68/100 \t Train Loss:0.1611 Valid Loss:0.4702 \t Train Acc:94.16 %  Valid Acc:86.94 %\n",
      "Epoch:69/100 \t Train Loss:0.1639 Valid Loss:0.4677 \t Train Acc:94.10 %  Valid Acc:86.89 %\n",
      "Epoch:70/100 \t Train Loss:0.1617 Valid Loss:0.4635 \t Train Acc:94.20 %  Valid Acc:87.12 %\n",
      "Epoch:71/100 \t Train Loss:0.1608 Valid Loss:0.4657 \t Train Acc:94.38 %  Valid Acc:87.04 %\n",
      "Epoch:72/100 \t Train Loss:0.1614 Valid Loss:0.4668 \t Train Acc:94.21 %  Valid Acc:87.02 %\n",
      "Epoch:73/100 \t Train Loss:0.1592 Valid Loss:0.4737 \t Train Acc:94.41 %  Valid Acc:86.83 %\n",
      "Epoch:74/100 \t Train Loss:0.1620 Valid Loss:0.4698 \t Train Acc:94.19 %  Valid Acc:87.07 %\n",
      "Epoch:75/100 \t Train Loss:0.1572 Valid Loss:0.4712 \t Train Acc:94.37 %  Valid Acc:86.83 %\n",
      "Epoch:76/100 \t Train Loss:0.1581 Valid Loss:0.4755 \t Train Acc:94.26 %  Valid Acc:86.85 %\n",
      "Epoch:77/100 \t Train Loss:0.1604 Valid Loss:0.4763 \t Train Acc:94.14 %  Valid Acc:86.91 %\n",
      "Epoch:78/100 \t Train Loss:0.1584 Valid Loss:0.4780 \t Train Acc:94.32 %  Valid Acc:86.89 %\n",
      "Epoch:79/100 \t Train Loss:0.1575 Valid Loss:0.4800 \t Train Acc:94.32 %  Valid Acc:87.06 %\n",
      "Epoch:80/100 \t Train Loss:0.1568 Valid Loss:0.4744 \t Train Acc:94.34 %  Valid Acc:86.98 %\n",
      "Epoch:81/100 \t Train Loss:0.1560 Valid Loss:0.4747 \t Train Acc:94.44 %  Valid Acc:87.12 %\n",
      "Epoch:82/100 \t Train Loss:0.1517 Valid Loss:0.4755 \t Train Acc:94.62 %  Valid Acc:87.05 %\n",
      "Epoch:83/100 \t Train Loss:0.1545 Valid Loss:0.4765 \t Train Acc:94.52 %  Valid Acc:87.09 %\n",
      "Epoch:84/100 \t Train Loss:0.1494 Valid Loss:0.4780 \t Train Acc:94.67 %  Valid Acc:87.12 %\n",
      "Epoch:85/100 \t Train Loss:0.1509 Valid Loss:0.4777 \t Train Acc:94.66 %  Valid Acc:87.11 %\n",
      "Epoch:86/100 \t Train Loss:0.1493 Valid Loss:0.4778 \t Train Acc:94.66 %  Valid Acc:87.14 %\n",
      "Epoch:87/100 \t Train Loss:0.1528 Valid Loss:0.4794 \t Train Acc:94.53 %  Valid Acc:87.05 %\n",
      "Epoch:88/100 \t Train Loss:0.1481 Valid Loss:0.4816 \t Train Acc:94.73 %  Valid Acc:87.01 %\n",
      "Epoch:89/100 \t Train Loss:0.1528 Valid Loss:0.4825 \t Train Acc:94.55 %  Valid Acc:87.01 %\n",
      "Epoch:90/100 \t Train Loss:0.1504 Valid Loss:0.4796 \t Train Acc:94.58 %  Valid Acc:87.20 %\n",
      "Epoch:91/100 \t Train Loss:0.1532 Valid Loss:0.4810 \t Train Acc:94.48 %  Valid Acc:87.00 %\n",
      "Epoch:92/100 \t Train Loss:0.1505 Valid Loss:0.4803 \t Train Acc:94.55 %  Valid Acc:87.07 %\n",
      "Epoch:93/100 \t Train Loss:0.1479 Valid Loss:0.4806 \t Train Acc:94.82 %  Valid Acc:87.09 %\n",
      "Epoch:94/100 \t Train Loss:0.1524 Valid Loss:0.4816 \t Train Acc:94.47 %  Valid Acc:87.07 %\n",
      "Epoch:95/100 \t Train Loss:0.1477 Valid Loss:0.4837 \t Train Acc:94.71 %  Valid Acc:86.96 %\n",
      "Epoch:96/100 \t Train Loss:0.1514 Valid Loss:0.4802 \t Train Acc:94.63 %  Valid Acc:87.13 %\n",
      "Epoch:97/100 \t Train Loss:0.1505 Valid Loss:0.4826 \t Train Acc:94.54 %  Valid Acc:87.06 %\n",
      "Epoch:98/100 \t Train Loss:0.1512 Valid Loss:0.4821 \t Train Acc:94.60 %  Valid Acc:87.10 %\n",
      "Epoch:99/100 \t Train Loss:0.1484 Valid Loss:0.4845 \t Train Acc:94.68 %  Valid Acc:87.10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 14:23:13,059] Trial 19 finished with value: 87.11 and parameters: {'sigma_1': 2.372211917995976, 'sigma_2': 4.696423499963366, 'sigma_3': 4.328879601640268, 'sigma_4': 0.6471922939677988, 'sigma_5': 1.7514318969792253, 'sigma_6': 2.3662396501741343, 'sigma_7': 3.068965447439853, 'sigma_8': 2.094138834469828, 'sigma_9': 3.929064548616785, 'sigma_10': 1.2050553466740448, 'sigma_11': 1.7274097849914685, 'sigma_12': 4.890422164869193, 'sigma_13': 1.5680232782184458}. Best is trial 16 with value: 87.64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100/100 \t Train Loss:0.1481 Valid Loss:0.4838 \t Train Acc:94.79 %  Valid Acc:87.11 %\n",
      "Best trial:\n",
      "  Value:  87.64\n",
      "  Params: \n",
      "    sigma_1: 2.552892614417707\n",
      "    sigma_2: 3.4882592168857727\n",
      "    sigma_3: 4.352113072004928\n",
      "    sigma_4: 0.738816595610332\n",
      "    sigma_5: 0.1056008808873683\n",
      "    sigma_6: 3.587607017492251\n",
      "    sigma_7: 3.4530867515762034\n",
      "    sigma_8: 2.8790174876906804\n",
      "    sigma_9: 3.1238297211006296\n",
      "    sigma_10: 0.12856715281533626\n",
      "    sigma_11: 3.217293494647598\n",
      "    sigma_12: 2.7807219332711726\n",
      "    sigma_13: 1.1450978029061871\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:34:35.889029Z",
     "start_time": "2024-10-07T02:34:24.150897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna  #载入optuna优化包\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)"
   ],
   "id": "6e323ae1ea3257c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T03:51:20.059315Z",
     "start_time": "2024-10-07T02:40:18.269237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##看看其他激活函数，比如RayLU\n",
    "class Raylu(nn.Module):  #带参数的gelu激活函数\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sigma = nn.Parameter(2 * torch.randn(1))  #可学习参数 sigma\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.where(input >= 0, input, input * torch.exp(-input ** 2 / self.sigma ** 2 / 2))\n",
    "        return x\n",
    "\n",
    "\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        #self.relu = nn.ReLU()\n",
    "        self.Raylu1 = Raylu()\n",
    "        self.Raylu2 = Raylu()\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        #out = self.relu(out)\n",
    "        out = self.Raylu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.Raylu2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        #self.relu = nn.ReLU()\n",
    "        self.Raylu3 = Raylu()\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        #out = self.relu(out)\n",
    "        out = self.Raylu3(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#model1 = ResidualBlock()\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate=0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#各个含有GELU的激活函数赋初值\n",
    "z = model.Raylu3.sigma\n",
    "nn.init.constant_(z, 6)\n",
    "z101 = model.layer1[0].Raylu1.sigma\n",
    "nn.init.constant_(z101, 4)\n",
    "z102 = model.layer1[0].Raylu2.sigma\n",
    "nn.init.constant_(z102, 4)\n",
    "z111 = model.layer1[1].Raylu1.sigma\n",
    "nn.init.constant_(z111, 3)\n",
    "z112 = model.layer1[1].Raylu2.sigma\n",
    "nn.init.constant_(z112, 3)\n",
    "z201 = model.layer2[0].Raylu1.sigma\n",
    "nn.init.constant_(z201, 5)\n",
    "z202 = model.layer2[0].Raylu2.sigma\n",
    "nn.init.constant_(z202, 5)\n",
    "z211 = model.layer2[1].Raylu1.sigma\n",
    "nn.init.constant_(z211, 5)\n",
    "z212 = model.layer2[1].Raylu2.sigma\n",
    "nn.init.constant_(z212, 5)\n",
    "z301 = model.layer3[0].Raylu1.sigma\n",
    "nn.init.constant_(z301, 2)\n",
    "z302 = model.layer3[0].Raylu2.sigma\n",
    "nn.init.constant_(z302, 4)\n",
    "z311 = model.layer3[1].Raylu1.sigma\n",
    "nn.init.constant_(z311, 2)\n",
    "z312 = model.layer3[1].Raylu2.sigma\n",
    "nn.init.constant_(z312, 3)\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "curr_lr = learning_rate\n",
    "\n",
    "historycifaRaylu = {'Raylu_train_loss': [], 'Raylu_valid_loss': [], 'Raylu_train_acc': [], 'Raylu_valid_acc': []}\n",
    "num_epochs = 80\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    Raylu_train_loss, Raylu_train_correct = 0.0, 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Raylu_train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(outputs.data, 1)  #最大化输出得到标签0-9\n",
    "        Raylu_train_correct += (predictions == labels).sum().item()  #对比标签得到正确的标签个数   \n",
    "\n",
    "    # Decay learning rate\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "    Raylu_valid_loss, Raylu_val_correct = 0.0, 0\n",
    "    model.eval()  #评估模式,非训练模式,batch normalization 和 dropout关闭\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        Raylu_valid_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(outputs.data, 1)  #最大化输出得到标签0-9\n",
    "        Raylu_val_correct += (predictions == labels).sum().item()  #对比标签得到正确的标签个数\n",
    "\n",
    "    Raylu_train_loss = Raylu_train_loss / len(train_loader.sampler)  #除以48000\n",
    "    Raylu_train_acc = Raylu_train_correct / len(train_loader.sampler) * 100\n",
    "    Raylu_valid_loss = Raylu_valid_loss / len(test_loader.sampler)  #除以12000\n",
    "    Raylu_valid_acc = Raylu_val_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "    print(\"Epoch:{}/{} \\t AVERAGE TL:{:.4f} AVERAGE VL:{:.4f} \\t AVERAGE TA:{:.2f} %  AVERAGE VA:{:.2f} %\".format(\n",
    "        epoch + 1, num_epochs,\n",
    "        Raylu_train_loss,\n",
    "        Raylu_valid_loss,\n",
    "        Raylu_train_acc,\n",
    "        Raylu_valid_acc))\n",
    "    historycifaRaylu['Raylu_train_loss'].append(Raylu_train_loss)  #每次训练和验证记录下来，后面画图   \n",
    "    historycifaRaylu['Raylu_valid_loss'].append(Raylu_valid_loss)\n",
    "    historycifaRaylu['Raylu_train_acc'].append(Raylu_train_acc)\n",
    "    historycifaRaylu['Raylu_valid_acc'].append(Raylu_valid_acc) "
   ],
   "id": "577bfebbba3e1bc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/80 \t AVERAGE TL:1.6360 AVERAGE VL:1.5498 \t AVERAGE TA:39.24 %  AVERAGE VA:44.04 %\n",
      "Epoch:2/80 \t AVERAGE TL:1.2425 AVERAGE VL:1.0412 \t AVERAGE TA:55.47 %  AVERAGE VA:62.48 %\n",
      "Epoch:3/80 \t AVERAGE TL:1.0140 AVERAGE VL:0.9309 \t AVERAGE TA:63.95 %  AVERAGE VA:66.75 %\n",
      "Epoch:4/80 \t AVERAGE TL:0.8664 AVERAGE VL:0.8680 \t AVERAGE TA:69.17 %  AVERAGE VA:69.56 %\n",
      "Epoch:5/80 \t AVERAGE TL:0.7861 AVERAGE VL:0.7686 \t AVERAGE TA:72.15 %  AVERAGE VA:73.09 %\n",
      "Epoch:6/80 \t AVERAGE TL:0.7069 AVERAGE VL:0.7657 \t AVERAGE TA:75.13 %  AVERAGE VA:73.74 %\n",
      "Epoch:7/80 \t AVERAGE TL:0.6527 AVERAGE VL:0.6688 \t AVERAGE TA:77.09 %  AVERAGE VA:76.68 %\n",
      "Epoch:8/80 \t AVERAGE TL:0.5998 AVERAGE VL:0.6221 \t AVERAGE TA:79.08 %  AVERAGE VA:79.01 %\n",
      "Epoch:9/80 \t AVERAGE TL:0.5619 AVERAGE VL:0.5747 \t AVERAGE TA:80.22 %  AVERAGE VA:80.03 %\n",
      "Epoch:10/80 \t AVERAGE TL:0.5191 AVERAGE VL:0.5607 \t AVERAGE TA:81.96 %  AVERAGE VA:80.89 %\n",
      "Epoch:11/80 \t AVERAGE TL:0.4952 AVERAGE VL:0.5721 \t AVERAGE TA:82.87 %  AVERAGE VA:80.85 %\n",
      "Epoch:12/80 \t AVERAGE TL:0.4729 AVERAGE VL:0.5421 \t AVERAGE TA:83.57 %  AVERAGE VA:81.50 %\n",
      "Epoch:13/80 \t AVERAGE TL:0.4543 AVERAGE VL:0.5039 \t AVERAGE TA:84.09 %  AVERAGE VA:82.94 %\n",
      "Epoch:14/80 \t AVERAGE TL:0.4346 AVERAGE VL:0.4906 \t AVERAGE TA:84.90 %  AVERAGE VA:83.47 %\n",
      "Epoch:15/80 \t AVERAGE TL:0.4211 AVERAGE VL:0.4857 \t AVERAGE TA:85.31 %  AVERAGE VA:83.79 %\n",
      "Epoch:16/80 \t AVERAGE TL:0.4058 AVERAGE VL:0.4909 \t AVERAGE TA:85.82 %  AVERAGE VA:83.47 %\n",
      "Epoch:17/80 \t AVERAGE TL:0.3875 AVERAGE VL:0.4739 \t AVERAGE TA:86.41 %  AVERAGE VA:84.17 %\n",
      "Epoch:18/80 \t AVERAGE TL:0.3773 AVERAGE VL:0.4785 \t AVERAGE TA:86.71 %  AVERAGE VA:83.75 %\n",
      "Epoch:19/80 \t AVERAGE TL:0.3632 AVERAGE VL:0.4449 \t AVERAGE TA:87.36 %  AVERAGE VA:85.15 %\n",
      "Epoch:20/80 \t AVERAGE TL:0.3590 AVERAGE VL:0.4427 \t AVERAGE TA:87.48 %  AVERAGE VA:85.59 %\n",
      "Epoch:21/80 \t AVERAGE TL:0.2786 AVERAGE VL:0.4219 \t AVERAGE TA:90.28 %  AVERAGE VA:86.32 %\n",
      "Epoch:22/80 \t AVERAGE TL:0.2567 AVERAGE VL:0.4306 \t AVERAGE TA:90.84 %  AVERAGE VA:85.98 %\n",
      "Epoch:23/80 \t AVERAGE TL:0.2511 AVERAGE VL:0.4190 \t AVERAGE TA:91.19 %  AVERAGE VA:86.67 %\n",
      "Epoch:24/80 \t AVERAGE TL:0.2445 AVERAGE VL:0.4247 \t AVERAGE TA:91.35 %  AVERAGE VA:86.47 %\n",
      "Epoch:25/80 \t AVERAGE TL:0.2380 AVERAGE VL:0.4347 \t AVERAGE TA:91.48 %  AVERAGE VA:86.17 %\n",
      "Epoch:26/80 \t AVERAGE TL:0.2323 AVERAGE VL:0.4211 \t AVERAGE TA:91.80 %  AVERAGE VA:86.88 %\n",
      "Epoch:27/80 \t AVERAGE TL:0.2280 AVERAGE VL:0.4168 \t AVERAGE TA:92.00 %  AVERAGE VA:86.97 %\n",
      "Epoch:28/80 \t AVERAGE TL:0.2233 AVERAGE VL:0.4323 \t AVERAGE TA:92.14 %  AVERAGE VA:86.65 %\n",
      "Epoch:29/80 \t AVERAGE TL:0.2156 AVERAGE VL:0.4324 \t AVERAGE TA:92.53 %  AVERAGE VA:86.64 %\n",
      "Epoch:30/80 \t AVERAGE TL:0.2170 AVERAGE VL:0.4281 \t AVERAGE TA:92.23 %  AVERAGE VA:86.93 %\n",
      "Epoch:31/80 \t AVERAGE TL:0.2116 AVERAGE VL:0.4352 \t AVERAGE TA:92.54 %  AVERAGE VA:86.65 %\n",
      "Epoch:32/80 \t AVERAGE TL:0.2102 AVERAGE VL:0.4341 \t AVERAGE TA:92.55 %  AVERAGE VA:86.58 %\n",
      "Epoch:33/80 \t AVERAGE TL:0.2024 AVERAGE VL:0.4337 \t AVERAGE TA:92.81 %  AVERAGE VA:86.98 %\n",
      "Epoch:34/80 \t AVERAGE TL:0.2014 AVERAGE VL:0.4390 \t AVERAGE TA:92.82 %  AVERAGE VA:86.67 %\n",
      "Epoch:35/80 \t AVERAGE TL:0.1970 AVERAGE VL:0.4366 \t AVERAGE TA:92.98 %  AVERAGE VA:86.90 %\n",
      "Epoch:36/80 \t AVERAGE TL:0.1933 AVERAGE VL:0.4304 \t AVERAGE TA:93.20 %  AVERAGE VA:86.99 %\n",
      "Epoch:37/80 \t AVERAGE TL:0.1864 AVERAGE VL:0.4532 \t AVERAGE TA:93.35 %  AVERAGE VA:86.59 %\n",
      "Epoch:38/80 \t AVERAGE TL:0.1855 AVERAGE VL:0.4785 \t AVERAGE TA:93.36 %  AVERAGE VA:86.37 %\n",
      "Epoch:39/80 \t AVERAGE TL:0.1853 AVERAGE VL:0.4467 \t AVERAGE TA:93.40 %  AVERAGE VA:86.57 %\n",
      "Epoch:40/80 \t AVERAGE TL:0.1777 AVERAGE VL:0.4470 \t AVERAGE TA:93.68 %  AVERAGE VA:86.69 %\n",
      "Epoch:41/80 \t AVERAGE TL:0.1530 AVERAGE VL:0.4279 \t AVERAGE TA:94.72 %  AVERAGE VA:87.31 %\n",
      "Epoch:42/80 \t AVERAGE TL:0.1475 AVERAGE VL:0.4336 \t AVERAGE TA:94.77 %  AVERAGE VA:87.21 %\n",
      "Epoch:43/80 \t AVERAGE TL:0.1421 AVERAGE VL:0.4393 \t AVERAGE TA:94.91 %  AVERAGE VA:87.56 %\n",
      "Epoch:44/80 \t AVERAGE TL:0.1407 AVERAGE VL:0.4434 \t AVERAGE TA:95.00 %  AVERAGE VA:87.43 %\n",
      "Epoch:45/80 \t AVERAGE TL:0.1361 AVERAGE VL:0.4473 \t AVERAGE TA:95.24 %  AVERAGE VA:87.23 %\n",
      "Epoch:46/80 \t AVERAGE TL:0.1371 AVERAGE VL:0.4413 \t AVERAGE TA:95.10 %  AVERAGE VA:87.28 %\n",
      "Epoch:47/80 \t AVERAGE TL:0.1340 AVERAGE VL:0.4517 \t AVERAGE TA:95.20 %  AVERAGE VA:87.47 %\n",
      "Epoch:48/80 \t AVERAGE TL:0.1362 AVERAGE VL:0.4500 \t AVERAGE TA:95.15 %  AVERAGE VA:87.34 %\n",
      "Epoch:49/80 \t AVERAGE TL:0.1349 AVERAGE VL:0.4503 \t AVERAGE TA:95.12 %  AVERAGE VA:87.24 %\n",
      "Epoch:50/80 \t AVERAGE TL:0.1320 AVERAGE VL:0.4532 \t AVERAGE TA:95.25 %  AVERAGE VA:87.21 %\n",
      "Epoch:51/80 \t AVERAGE TL:0.1286 AVERAGE VL:0.4517 \t AVERAGE TA:95.44 %  AVERAGE VA:87.19 %\n",
      "Epoch:52/80 \t AVERAGE TL:0.1307 AVERAGE VL:0.4571 \t AVERAGE TA:95.35 %  AVERAGE VA:87.30 %\n",
      "Epoch:53/80 \t AVERAGE TL:0.1265 AVERAGE VL:0.4595 \t AVERAGE TA:95.46 %  AVERAGE VA:87.47 %\n",
      "Epoch:54/80 \t AVERAGE TL:0.1266 AVERAGE VL:0.4634 \t AVERAGE TA:95.47 %  AVERAGE VA:87.33 %\n",
      "Epoch:55/80 \t AVERAGE TL:0.1249 AVERAGE VL:0.4759 \t AVERAGE TA:95.55 %  AVERAGE VA:87.31 %\n",
      "Epoch:56/80 \t AVERAGE TL:0.1242 AVERAGE VL:0.4761 \t AVERAGE TA:95.54 %  AVERAGE VA:87.14 %\n",
      "Epoch:57/80 \t AVERAGE TL:0.1230 AVERAGE VL:0.4684 \t AVERAGE TA:95.63 %  AVERAGE VA:87.57 %\n",
      "Epoch:58/80 \t AVERAGE TL:0.1206 AVERAGE VL:0.4727 \t AVERAGE TA:95.63 %  AVERAGE VA:87.30 %\n",
      "Epoch:59/80 \t AVERAGE TL:0.1191 AVERAGE VL:0.4795 \t AVERAGE TA:95.64 %  AVERAGE VA:87.44 %\n",
      "Epoch:60/80 \t AVERAGE TL:0.1169 AVERAGE VL:0.4764 \t AVERAGE TA:95.77 %  AVERAGE VA:87.36 %\n",
      "Epoch:61/80 \t AVERAGE TL:0.1122 AVERAGE VL:0.4712 \t AVERAGE TA:96.01 %  AVERAGE VA:87.47 %\n",
      "Epoch:62/80 \t AVERAGE TL:0.1058 AVERAGE VL:0.4773 \t AVERAGE TA:96.25 %  AVERAGE VA:87.44 %\n",
      "Epoch:63/80 \t AVERAGE TL:0.1070 AVERAGE VL:0.4732 \t AVERAGE TA:96.19 %  AVERAGE VA:87.43 %\n",
      "Epoch:64/80 \t AVERAGE TL:0.1049 AVERAGE VL:0.4755 \t AVERAGE TA:96.25 %  AVERAGE VA:87.55 %\n",
      "Epoch:65/80 \t AVERAGE TL:0.1049 AVERAGE VL:0.4734 \t AVERAGE TA:96.34 %  AVERAGE VA:87.38 %\n",
      "Epoch:66/80 \t AVERAGE TL:0.1040 AVERAGE VL:0.4770 \t AVERAGE TA:96.33 %  AVERAGE VA:87.45 %\n",
      "Epoch:67/80 \t AVERAGE TL:0.1030 AVERAGE VL:0.4761 \t AVERAGE TA:96.32 %  AVERAGE VA:87.46 %\n",
      "Epoch:68/80 \t AVERAGE TL:0.1052 AVERAGE VL:0.4800 \t AVERAGE TA:96.22 %  AVERAGE VA:87.38 %\n",
      "Epoch:69/80 \t AVERAGE TL:0.1037 AVERAGE VL:0.4818 \t AVERAGE TA:96.33 %  AVERAGE VA:87.36 %\n",
      "Epoch:70/80 \t AVERAGE TL:0.1018 AVERAGE VL:0.4832 \t AVERAGE TA:96.43 %  AVERAGE VA:87.33 %\n",
      "Epoch:71/80 \t AVERAGE TL:0.1016 AVERAGE VL:0.4864 \t AVERAGE TA:96.43 %  AVERAGE VA:87.16 %\n",
      "Epoch:72/80 \t AVERAGE TL:0.1027 AVERAGE VL:0.4862 \t AVERAGE TA:96.42 %  AVERAGE VA:87.39 %\n",
      "Epoch:73/80 \t AVERAGE TL:0.1003 AVERAGE VL:0.4859 \t AVERAGE TA:96.42 %  AVERAGE VA:87.34 %\n",
      "Epoch:74/80 \t AVERAGE TL:0.1007 AVERAGE VL:0.4861 \t AVERAGE TA:96.45 %  AVERAGE VA:87.32 %\n",
      "Epoch:75/80 \t AVERAGE TL:0.1024 AVERAGE VL:0.4879 \t AVERAGE TA:96.30 %  AVERAGE VA:87.32 %\n",
      "Epoch:76/80 \t AVERAGE TL:0.1012 AVERAGE VL:0.4898 \t AVERAGE TA:96.45 %  AVERAGE VA:87.20 %\n",
      "Epoch:77/80 \t AVERAGE TL:0.0976 AVERAGE VL:0.4938 \t AVERAGE TA:96.51 %  AVERAGE VA:87.27 %\n",
      "Epoch:78/80 \t AVERAGE TL:0.0977 AVERAGE VL:0.4901 \t AVERAGE TA:96.58 %  AVERAGE VA:87.17 %\n",
      "Epoch:79/80 \t AVERAGE TL:0.1007 AVERAGE VL:0.4911 \t AVERAGE TA:96.36 %  AVERAGE VA:87.19 %\n",
      "Epoch:80/80 \t AVERAGE TL:0.0986 AVERAGE VL:0.4943 \t AVERAGE TA:96.54 %  AVERAGE VA:87.29 %\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "11c90969843e9327"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
